[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "PSTAT 5A: Understanding Data",
    "section": "",
    "text": "Welcome to the official course site for PSTAT 5A (titled Understanding Data) at the University of California, Santa Barbara! Please note that this is the site for Lecture Section 200 of the Spring 2023 iteration of the course, with Ethan Marzban. (Lecture Section 100 will be utilizing Canvas.)\n\nAll relevant information for the course can be found on this site, with the (perhaps crucial) exception of quizzes, which will take place on the course Canvas site."
  },
  {
    "objectID": "Pages/Labs/Lab03/lab03.html#comparisons",
    "href": "Pages/Labs/Lab03/lab03.html#comparisons",
    "title": "Lab03",
    "section": "Comparisons",
    "text": "Comparisons\nHere’s a question: is 2 less than 3? Well, yes it is! If we wanted to confirm this, we could simply ask Python whether 2 is less than 3 by running\n\n2 < 3\n\nTrue\n\n\nNotice, however, how Python answered this question: it simply returned True. Let’s see what the data type of True is:\n\ntype(True)\n\nbool\n\n\nTrue is of the type bool, which is short for boolean. There are only two boolean quantities in Python: True and False. Let’s see how we can generate a False value:\n\n3 < 2\n\nFalse\n\n\nHere is a list of comparison operators, taken from the Inferential Thinking textbook:\n\n\n\nComparison\nOperator\nTrue Example\nFalse Example\n\n\n\n\nLess than\n<\n2 < 3\n2 < 2\n\n\nGreater than\n>\n3 < 2\n3 > 3\n\n\nLess than or equal\n<=\n2 <= 2\n3 <= 2\n\n\nGreater than or equal\n>=\n3 >= 3\n2 >= 3\n\n\nEqual\n==\n3 == 3\n3 == 2\n\n\nNot equal\n!=\n3 != 2\n2 != 2\n\n\n\nOne nice thing about Python is that it allows for multiple simultaneous comparisons. For example,\n\n2 < 3 < 4\n\nTrue\n\n\n\n\n\n\n\n\nImportant\n\n\n\nIn a multiple comparison, Python will only return True when all of the included comparisons are true.\n\n\nFor instance, 2 < 3 < 1 would return False, because even though 2 is less than 3 it is not true that 3 is less than 1.\n\nBelieve it or not, you can compare strings as well! Python compares strings alphabetically; that is, letters at the beginning of the alphabet are considered to have smaller ordinal value than letters at the end of the alphabet. For example:\n\n\"apple\" < \"banana\"\n\nTrue\n\n\n\n\"zebra\" < \"zanzibar\"\n\nFalse\n\n\n\n\"cat\" <= \"catenary\"\n\nTrue\n\n\n\n\n\n\n\n\nTask 1\n\n\n\nCheck how \"statistics\" and \"Statistics\" (note the capitalization!) compare. Use this to answer the question: when Python is comparing strings, does it give precedence to capital letters or not?\n\n\nFinally, we discuss how comparisons work in the context of lists and arrays. The way Python compares lists is by what is known as lexicographical order. From the official Python help documentation, this means\n\nfirst the first two items are compared, and if they differ this determines the outcome of the comparison; if they are equal, the next two items are compared, and so on, until either sequence is exhausted.\n\nFor instance, [1, 2, 3] < [2, 1, 1] would return True since 1 (the first element of the first list) is less than 2 (the first element of the second list).\n\nThe comparison of arrays is a little more straightforward, except\n\n\n\n\n\n\nImportant\n\n\n\nWhen comparing two arrays, the arrays must be of the same length.\n\n\nTo see exactly how comparison of arrays works, let’s work through a Task:\n\n\n\n\n\n\nTask 2\n\n\n\nMake an array with the elements 1, 2, and 3, and call this x. Make another array with the elements 2, 3, 1, and call this y. Run x < y, and comment on the result.\n\n\nWhat the previous task illustrates is that Python compares arrays element-wise."
  },
  {
    "objectID": "Pages/Labs/Lab03/lab03.html#conditionals",
    "href": "Pages/Labs/Lab03/lab03.html#conditionals",
    "title": "Lab03",
    "section": "Conditionals",
    "text": "Conditionals\nNow, we can use comparisons for much more than verifying simple arithmetic relationships. One of the main areas in which comparisons arise is the area of conditional expressions.\n\nSimply put, conditional expressions are how we can convey a set of choices to Python. As an example, let’s consider finding someone’s city based on their zip code. To simplify, let’s assume the only zip codes we consider are 9311, 93120, and 93150. From postal data, we know that:\n\na zip code of 93117 corresponds to Goleta\na zip code of 93120 corresponds to Santa Barbara\na zip code of 93150 corresponds to Montecito\n\nWe can rephrase this information in terms of “if” statements:\n\nIf a person has a zip code of 93117, then they are in Goleta\nOtherwise, if they have a zip code of 93120, then they are in Santa Barbara\nOtherwise, if they have a zip code of 93150, then they are in Montecito\n\nThis is precisely the syntax we would use when translating this experiment into Python syntax:\n\nif zip_code == 93117:\n  location = \"Goleta\"\nelif zip_code == 93120:\n  location = \"Santa Barbara\"\nelif zip_code == 93150:\n  location = \"Montecito\"\n\nBy the way: elif is an abbreviation for else if, which itself can be thought of as equivalent to otherwise, if.\n\nHere’s the general syntax of a conditional expression in Python:\n\nif <condition 1>:\n  <task 1>\nelif <condition 2>:\n  <task 2>\n...\nelse:\n  <final task>\n\nWhen executing the above conditional statement, Python first checks whether <condition 1> returns a value of True or False. If it returns a value of True, then <task 1> is executed and the statement ends. Otherwise, Python checks whether <task 2> is True or False; if it is True then <condition 2> is executed, etc.\n\n\n\n\n\n\n\nImportant\n\n\n\nIn the example code above: if <condition 1> is True, then no tasks beyond <task 1> are evaluated. If <condition 2> is True, then no tasks beyond <task 2> are evaluated. And so on and so forth.\n\n\n\n\n\n\n\n\nTask 3\n\n\n\nConsider the code:\n\nx = 2\n\nif x < 2:\n    x = \"hello\"\nelif x < 3:\n    x = \"goodbye\"\nelse:\n    x = \"take care\"\n\nBefore running any code, write down what you think the result of executing x would be. Then, run the loop, execute x, and check whether your answer was correct or not.\n\n\n\n\n\n\n\n\nCaution\n\n\n\nIndentation is very important in Python.\n\n\nFor example, if instead of the conditional expression in Task 3 we had instead put\n\nx = 2\n\nif x < 2:\nx = \"hello\"\nelif x < 3:\nx = \"goodbye\"\nelse:\nx = \"take care\"\n\nthen we would have received an error!"
  },
  {
    "objectID": "Pages/Labs/Lab03/lab03.html#functions",
    "href": "Pages/Labs/Lab03/lab03.html#functions",
    "title": "Lab03",
    "section": "Functions",
    "text": "Functions\nFinally, let’s quickly discuss Python functions. We’ve already been using quite a few functions:\n\n\n\n\n\n\nTask 4\n\n\n\nIn a Markdown cell, write down three functions we’ve used in the previous labs.\n\n\nIf you recall, the general syntax for calling a function is:\n\n<function name>(<arg1>, <arg2>, ... )\n\nwhere <function name> denotes the function name and <arg1>, <arg2>, etc. denote the arguments of the function.\n\nCreating your own function in Python is actually fairly simple! Here is the syntax we use:\n\ndef <function name>(<list out the argument names>):\n  \"\"\"include a 'docstring' here\"\"\"\n  <body of the function>\n  return <what you want the function to output>\n\nFor example,\n\ndef f(x, y):\n  \"\"\"returns x^2 + y^2\"\"\"\n  return x**2 + y**2\n\ncreates a function f that can be called on two arguments, x and y, and returns the sum of squares of the arguments; e.g.\n\nf(3, 4)  # should return 3^2 + 4^2 = 25\n\n25\n\n\nBy the way, the docstring referenced above is a verbal description of what the function does. (Recall from Lab01 that it is just a multi-line comment, since it is enclosed in triple quotation marks!). All functions should include a docstring to convey to the user what the function does.\n\n\n\n\n\n\nImportant\n\n\n\nIf you don’t include a return statement in the definition of a function, then your function will never return anything.\n\n\nFor instance,\n\ndef g(x, y):\n  \"\"\"should return x^2 + y^2\"\"\"\n  x**2 + y**2\n\ng(3, 4)\n\n\n\n\n\n\n\nTask 5\n\n\n\nWrite a function called cent_to_far() which takes in a single temperature c as measured in degrees Centigrade and returns the corresponding temperature in degrees Farenheit. Check that cent_to_far(0) correctly returns 0 and cent_to_far(68) correctly returns 69.7777. As a reminder: \\[ {}^{\\circ}\\mathrm{F} = \\frac{5}{9} ({}^{\\circ}\\mathrm{C}) + 32 \\]\n\n\nFinally, let’s combine some things by way of a concluding Task:\n\n\n\n\n\n\nTask 6\n\n\n\nWrite a function called parity() that returns the parity (i.e. whether a number is even or odd) of an input x. Call your parity() function on 2 and then 3 to make sure your function behaves as expected. Some hints:\n\nRecall that % is the modulus operator in Python. Specifically, x % y returns the remainder of performing y divided by x.\nRecall that even numbers are divisible by 2 (so what does this mean about the remainder of dividing x by 2 if x is even?)"
  },
  {
    "objectID": "Pages/Labs/Lab04/lab04.html",
    "href": "Pages/Labs/Lab04/lab04.html",
    "title": "Lab04",
    "section": "",
    "text": "It’s finally time for us to revisit our notions of descriptive statistics (from Week 1 of the course), now in the context of Python!"
  },
  {
    "objectID": "Pages/Labs/Lab04/lab04.html#modules-revisited",
    "href": "Pages/Labs/Lab04/lab04.html#modules-revisited",
    "title": "Lab04",
    "section": "Modules, Revisited",
    "text": "Modules, Revisited\nBefore we talk about plotting, we will need to quickly talk about modules again. Recall from Lab01 that modules are Python files containing definitions for functions and classes. Up until now, we’ve been importing all functions and classes from a module using the command\n\nfrom <module name> import *\n\nThere is another way to import modules, which is the following:\n\nimport <module name> as <abbreviation>\n\nFor example,\n\nimport numpy np\n\nnot only imports the numpy module but imports it with the abbreviation (i.e. nickname) np so that we can simply write np in place of numpy.\n\nThe reason this is particularly useful is because module names can sometimes be quite long, so being able to refer to the module with a shortened nickname will save a lot of time!\n\nIn general, if we import a module using\n\nimport <module name> as <abbreviation>\n\nwe reference functions from <module name> using the syntax\n\n<abbreviation>.<function name>()\n\nFor example, after having imported the numpy module with the nickname np, we access the sin() function contained in the numpy module by calling\n\nnp.sin()\n\n\n\n\n\n\n\nTask 1\n\n\n\n\nImport the numpy module as np, and check that np.sin(0) returns a value of 0.\nImport the datascience module as ds, and check that\n\n\nds.Table().with_columns(\n  \"Col1\", [1, 2, 3],\n  \"Col2\", [2, 3, 4]\n)\n\ncorrectly displays as\n\n\n\n\n    \n        \n            Col1 Col2\n        \n    \n    \n        \n            1    2   \n        \n        \n            2    3   \n        \n        \n            3    4   \n        \n    \n\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nIf you import a module with an abbreviation <abbreviation>, you must always use the abbreviation when referencing the module; not the original module name.\n\n\nFor example, after importing numpy as np, running numpy.sin() would return an error."
  },
  {
    "objectID": "Pages/Labs/Lab04/lab04.html#numerical-summaries",
    "href": "Pages/Labs/Lab04/lab04.html#numerical-summaries",
    "title": "Lab04",
    "section": "Numerical Summaries",
    "text": "Numerical Summaries\n\nMeasures of Central Tendency\nRecall that for a list of numbers \\(X = \\{x_i\\}_{i=1}^{n}\\), the mean is defined to be \\[ \\overline{x} = \\frac{1}{n} \\sum_{i=1}^{n} x_i = \\frac{1}{n} (x_1 + \\cdots + x_n) \\] Computing the mean of a list or array of numbers in Python is relatively simple, using the np.mean() function [recall that we imported the numpy module with the abbreviation np, meaning np.mean() is a shorthand for numpy.mean()]. Similarly, to compute the median of a list or array we can use np.median().\n\n\n\n\n\n\nTask 2\n\n\n\nLet x_list be a list containing the elements 1, 2, and 3, and let x_array be an array containing the elements 1, 2, and 3. Compute the mean and median of x_list and x_array using the appropriate functions from the numpy module.\n\n\n\n\nMeasures of Spread\nRecall that we also discussed several measures of spread:\n\nStandard deviation\nIQR (Interquartile Range)\nRange\n\nSure enough, the numpy module contains several functions which help us compute these measures. Let’s examine each separately.\n\n\n\n\n\n\nTask 3\n\n\n\n\nLook up the help file on the function np.ptp(), and describe what it does. Also, answer the question: what does ptp actually stand for?\nNow, apply the np.ptp() function on your x_list and x_array variables from Task 1 above and check that it functions like you expect.\n\n\n\nNext, we tackle a slightly peculiar function: np.std(). We expect this to compute the standard deviation of a list/array, but…\n\n\n\n\n\n\nTask 4\n\n\n\n\nCompute the standard deviation of the x_list variable from Task 1 by hand, and write down the answer using a comment or Markdown cell.\nNow, run np.std(x_list). Does this answer agree with what you found in part (a) above?\nNow, recompute the standard deviation of x_list by hand but this time use \\((1/n)\\) instead of \\((1 / n - 1)\\) in the formula. How does this answer compare with the result of np.std(x_list)?\n\n\n\nThe result of the previous Task is the following: given a list x = [x1, x2, ..., xn], running np.std(x) actually computes \\[ \\sqrt{ \\frac{1}{n} \\sum_{i=1}^{n} (x_i - \\overline{x})^2 } \\] as opposed to our usual definition of standard deviation \\[ s_X = \\sqrt{ \\frac{1}{n - 1} \\sum_{i=1}^{n} (x_i - \\overline{x})^2} \\] We can actually fix this issue by passing in an additional argument to the np.std() function:\n\n\n\n\n\n\nTask 4 (cont’d)\n\n\n\n\nRun np.std(x_list, ddof = 1) and check whether this matches the result of part (a) above.\n\n\n\n\n\n\n\n\n\nResult\n\n\n\nTo compute the standard deviation of a list x, we run np.std(x, ddof = 1).\n\n\nFinally, we turn to the IQR: to compute the IQR of a list/array x, we use (after importing numpy as np)\n\nnp.diff(np.percentile(x, [25,75]))[0]"
  },
  {
    "objectID": "Pages/Labs/Lab04/lab04.html#visualizations",
    "href": "Pages/Labs/Lab04/lab04.html#visualizations",
    "title": "Lab04",
    "section": "Visualizations",
    "text": "Visualizations\nIt’s finally time to make pretty pictures! The module we will use to generate visualizations in this class is the matplotlib module (though there are quite a few other modules that work for visualizations as well). The official website for matplotlib can be found at https://matplotlib.org/.\n\nBefore we generate any plots, we will need to run the following code once:\n\n%matplotlib inline\nimport matplotlib\nimport matplotlib.pyplot as plt\nplt.style.use('seaborn-v0_8-whitegrid')\n\nHere’s what these lines of code are doing:\n\n%matplotlib inline tells Jupyter to actually display our plots in our notebook (if we didn’t include this line, our plots wouldn’t display)\nimport matplotlib imports the matplotlib module\nimport matplotlib.pyplot as plt imports the pyplot submodule (a submodule is just a module contained within another larger module) with the abbreviation plt.\nplt.style.use('seaborn-v0_8-whitegrid') tells Jupyter to use a specific theme (called seaborn-v0_8-whitegrid) when generating plots.\n\nAgain, notice the beauty of the import <module> as <abbreviation> syntax- after running the third line above, we no longer need to write matplotlib.pyplot, just plt! Also, there are lots of other themes you can use when generating your plots: after completing this lab, I encourage you to consult this reference guide for a list of a few other pyplot themes.\n\nBoxplots and Histograms\nNow, let’s proceed on to make some plots. The first two types of plots we will look at are the two we used to describe numerical data: namely, boxplots and histograms. The functions we will use are the plt.boxplot() and plt.his() functions, respectively.\n\n\n\n\n\n\nTask 5\n\n\n\n\nMake a list called y that contains the following elements: [1, 2, 3, 4, 5, 4, 3, 5, 4, 1, 2].\nRun plt.boxplot(y); (be sure to include the semicolon!). With any luck, your plot should look like:\n\n\n\n\n\n\n\nLet’s make our boxplot horizontal, as opposed to vertical. Consult the help file on the matplotlib.pyplot.boxplot() function here and figure out how to position your boxplot horizontally. Your new plot should look like:\n\n\n\n\n\n\n\nNext, let’s add some color to our plot. Within your call to plt.boxplot(), add the following: patch_artist=True, boxprops = dict(facecolor = \"aquamarine\") (don’t worry too much about what exactly this code is doing). Your boxplot should now look like this:\n\n\n\n\n\n\n\nFinally, let’s add a Title! Right below your call to plt.boxplot(), add the following: plt.title(\"My First Python Boxplot\"); (again, note the semicolons). Your final plot should look like this:\n\n\n\n\n\n\n\nTime for a review: based on the boxplot we just generated, what is the IQR of y? Write your answer in a Markdown cell. Then, use the syntax discussed in the previous section of this Lab to use Python to compute the IQR of y, and comment on the result.\n\n\n\nOf course, boxplots are not the only way to summarize numerical variables: we also have histograms!\n\n\n\n\n\n\nTask 6\n\n\n\nCall the plt.hist() function on the y list defined in Task 3, and use the help file to add arguments to your call to plt.hist() function to generate the following plot:\n\n\n\n\n\nPay attention to the number of bins!\n\n\n\n\nScatterplots\nWe should also quickly discuss how to generate scatterplots in Python.\n\n\n\n\n\n\nTask 7\n\n\n\n\nCopy-paste the following code into a code cell, and then run that cell (don’t worry about what this code is doing- we’ll discuss that in a future lab).\n\n\nnp.random.seed(5)\n\nx1 = np.random.normal(0, 1, 100)\nx2 = x1 + np.random.normal(0, 1, 100)\n\nplt.scatter(x1, x2);\n\nYour plot should look like this:\n\n\n\n\n\n\nAdd an x-axis label that says \"x1\" and a y-axis label that says \"x2\". Your final plot should look like:\n\n\n\n\n\n\n\nDoes there appear to be an association between the variables x1 and x2? If so, is the association positive or negative? Linear or nonlinear? Answer using a comment or a Markdown Cell."
  },
  {
    "objectID": "Pages/Labs/Lab04/lab04.html#plotting-a-function",
    "href": "Pages/Labs/Lab04/lab04.html#plotting-a-function",
    "title": "Lab04",
    "section": "Plotting a Function",
    "text": "Plotting a Function\nFinally, I’d like to take a quick detour from descriptive statistics and talk about how to plot a function using Python. As a concrete example, let’s try and plot a sine curve from \\(0\\) to \\(2\\pi\\).\nIf you recall, on Lab01 we used the sin() function from the math module- it turns out that the numpy module (which, recall, we have imported as np) also has a sin() function, so let’s use that one today:\n\nnp.sin()\n\nNext, we create a set of finely-spaced points between our two desired endpoints (in this case, \\(0\\) and \\(2\\pi\\), respectively). We will do so using the np.linspace() function, which works as follows:\n\nnp.linspace(start, stop, num)\n\ncreates a set of num evenly-spaced values between start and stop, respectively. For instance:\n\nnp.linspace(0, 1, 10)\n\narray([ 0.        ,  0.11111111,  0.22222222,  0.33333333,  0.44444444,\n        0.55555556,  0.66666667,  0.77777778,  0.88888889,  1.        ])\n\n\nIn the context of plotting, the more points we generate the smoother our plot will seem (you will see what this means in a minute). As such, let’s start with 150 points between 0 and 2 * pi:\n\nx = np.linspace(0, 2 * np.pi, 150)\n\nFinally, we call the plt.plot() function on x and np.sin(x) to generate our plot:\n\nplt.figure(figsize=(4.5, 2.25))\nplt.plot(x, np.sin(x))\n\n\n\n\nLet’s see what would have happened if we used fewer values in our np.linspace() call:\n\nxnew = np.linspace(0, 2 * np.pi, 10)\nplt.plot(xnew, np.sin(xnew))\n\n\n\n\n\n\nSo, the more points we include in our call to np.linspace(), the smoother our final function will look!\n\nSo, to summarize, here is the general “recipe” to plot a function f() between two values a and b in Python:\n\nLet x = np.linspace(a, b, <some large value>)\nCall plt.plot(x, f(x))\nAdd labels/titles as necessary\n\n\n\n\n\n\n\nTask 8\n\n\n\nGenerate a plot of the function \\(f(x) = x - x^2 \\sin(x)\\) between \\(x = -10\\) and \\(x = 10\\). Experiment around with the number of values generated by np.linspace() to ensure your plot is relatively smooth. Be sure to include axis labels; also, change the color of the graph to red. Your final plot should look something like this:"
  },
  {
    "objectID": "Pages/Labs/Lab04/lab04.html#note-on-submission",
    "href": "Pages/Labs/Lab04/lab04.html#note-on-submission",
    "title": "Lab04",
    "section": "Note on Submission",
    "text": "Note on Submission\nPlease note- from here on out, we will expect you to modify your notebook metadata to include your name and NetID (not your Perm Number!). For a refresher on how to do that, please consult Lab01."
  },
  {
    "objectID": "Pages/Labs/Lab05/lab05.html#random-number-generation",
    "href": "Pages/Labs/Lab05/lab05.html#random-number-generation",
    "title": "Lab05",
    "section": "Random Number Generation",
    "text": "Random Number Generation\nAs data scientists, it will be useful for us to know how to generate random numbers using Python. There are several different modules that contain functions for random number generation; the one we will use first is the numpy.random module:\n\nimport numpy.random as npr\n\nThe first function we will explore today is the npr.randint() function. This function enables us to select a random integer from the set of integers between two specified values: for example, to generate a single number from the set of integers in the set \\([a, b)\\) we would run\n\nnpr.randint(a, b)\n\nNote that the b value is not included as a value that can be selected; for instance, npr.randint(1, 5) generates a random number from the set \\(\\{1, 2, 3, 4\\}\\).\n\n\n\n\n\n\nTask 1\n\n\n\n\nWrite code to simulate rolling a fair six-sided die 5 times. Think about how this might be translated to a context involving generating random numbers; also, you may need to consult the help file on the npr.random() function.\nUse your code from part (a) to answer the following question: when using npr.randint() to generate multiple random numbers, in what data class is the result stored?\n\n\n\nNow, when it comes to random number generation, there is a very important concept known as setting a seed.\n\n\n\n\n\n\nTask 2\n\n\n\n\nWrite npr.randint(1, 7) in a code cell, and run it three times. In a Markdown cell just below this cell, answer the following question: did you get the same result each time you ran the code cell?\nIn a new code cell write\n\n\nnpr.seed(15)\nnpr.randint(1, 7)\n\nRun this new cell three times and again answer the question: did you get the same result each time you ran the code cell?\n\nNow, turn to your neighbor and check whether you both got the same result as each other when completing task (b) above?\n\n\n\nAs you can see, setting a seed, in a sense, removes a certain amount of randomness in Python. After you set a seed, your random number generator will generate the same number (or set of numbers) every time you run it. Though it may seem unclear as to why we would want this, you may be able to imagine that setting the seed is extremely important when it comes to replicability, a concept we will return to later in the course."
  },
  {
    "objectID": "Pages/Labs/Lab05/lab05.html#distributions-in-python",
    "href": "Pages/Labs/Lab05/lab05.html#distributions-in-python",
    "title": "Lab05",
    "section": "Distributions in Python",
    "text": "Distributions in Python\nIf you recall, one of the first things we did in Lab (back in Week 1!) was to use Python as a calculator. At the time, we only used Python to compute relatively simple quantities. Now that we’ve talked a bit about distributions, you can see how Python might be able to simpliy our lives greatly!\nFor instance, take the probability mass function (p.m.f.) of the \\(\\mathrm{Bin}(n, p)\\) distribution: if \\(X \\sim \\mathrm{Bin}(n, p)\\), then \\[ \\mathbb{P}(X = k) = \\binom{n}{k} \\cdot p^k \\cdot (1 - p)^{n - k} \\] Can we get Python to compute this for us? Or, remember how when we want to find areas under a normal density curve we have to use tables- can we perhaps compute these areas using Python?\nThe answer to both of these questions is, naturally, “yes”! Specifically, we will make use of the scipy.stats module which contains a plethora of functions relating to the distributions we learned in this class (as well as other distributions we won’t have time to cover).\n\nimport scipy.stats as sps\n\nLet’s tackle the Binomial distribution first. The function sps.binom.pmf() allows us to compute the p.m.f. of the Binomial distribution (with specified parameters) at a particular point.\n\n\n\n\n\n\nTask 3\n\n\n\nLet \\(X \\sim \\mathrm{Bin}(143, 0.153)\\). Compute the following using the sps.binom.pmf() function:\n\n\\(\\mathbb{P}(X = 20)\\)\n\\(\\mathbb{P}(X = 40)\\) [make sure you understand the output of this; feel free to ask your TA if you are confused!]\n\n\n\nNow, let’s talk about areas under the normal curve. If we want to find the following area:\n\nwe would run the following code:\n\nsps.norm.cdf(t, mu, sigma)\n\n\n\n\n\n\n\nTask 4\n\n\n\n\nIf \\(X \\sim \\mathcal{N}(3, 0.5)\\), compute \\(\\mathbb{P}(X \\leq 2)\\).\nIf \\(X \\sim \\mathcal{N}(-2, \\ 1)\\), compute \\(\\mathbb{P}(X \\geq 1)\\).\nIf \\(X \\sim \\mathcal{N}(0, 1)\\), compute \\(\\mathbb{P}(-1 \\leq X \\leq 1)\\).\n\n\n\nRecall that we talked about the uniform distribution; you’ll work with the Python functions that deal with the uniform distribution on the upcoming Homework."
  },
  {
    "objectID": "Pages/Labs/Lab05/lab05.html#simulation",
    "href": "Pages/Labs/Lab05/lab05.html#simulation",
    "title": "Lab05",
    "section": "Simulation",
    "text": "Simulation\nNow, let’s tie things together slightly. As data scientists, we obviously love to use data! However, sometimes data can be too time-consuming, costly, or otherwise unfeasible to collect in large quantities. In certain situations, simulations can help address these issues.\nWhen asked to define a “simulation” in the context of data science, ChatGPT returned the following:\n\n[…] a simulation is a computational model or program that is used to replicate real-world scenarios or systems in order to analyze their behavior, predict outcomes, or test hypotheses.\n\nThis is actually a great definition: simulations are designed to simulate (i.e. mimic) real-world situations to generate new observations/outcomes that (we hope) closely resemble the real-world outcomes.\nFor example, suppose we believe that weights of rats in a particular situation are normally distributed with mean 3.8oz and a standard deviation of 0.5oz. Instead of actually going out and collecting the weights of, say, 10 different rats and recording them, we could simulate collecting these weights by generating a series of random numbers that follow the \\(\\mathcal{N}(3.8, \\ 0.5)\\) distribution:\n\n\narray([2.58114574, 3.41892117, 3.8877664 , 3.15243359, 3.19045344,\n       3.81599745, 3.45664048, 3.39428931, 3.51931328, 3.96196977])\n\n\nThere are (once again) several modules that contain functions designed to simulate draws from different distributions: for now, we’ll stick with the scipy.stats module.\nTo simulate n draws from a \\(\\mathcal{N}(\\)mu, sigma\\()\\) distribution we use the code\n\nsps.norm.rvs(mu, sigma, n)\n\n(note that, by default, the sample size comes at the end!) To simulate n draws from a \\(\\mathrm{Unif}(\\)a, b\\()\\) distribution we use the code\n\nsps.uniform.rvs(a, b, n)\n\n\n\n\n\n\n\nTask 5\n\n\n\n\nThe time spent waiting in line at Romaine’s is uniformly distributed between 2 mins and 10 mins. Simulate the process of waiting in line at Romaine’s one hundred times; store your result in a variable called x and display only the first 10 elements of x. (Hint: Remember how to index variables!)\nThe temperature of a healthy adult is normally distributed with mean 98.2 degrees Fahrenheit and standard deviation 2.4 degrees Fahrenheit. Simulate the process of selecting 150 healthy adults and recording their temperatures (in degrees Fahrenheit); store your result in a variable called y and display only the first 10 elements of y. (Hint: Remember how to index variables!)\n\n\n\nIt turns out you can use simulations to approximate probabilities that would otherwise be very difficult to compute by hand. You will explore this topic further on the upcoming Homework assignment."
  },
  {
    "objectID": "Pages/Labs/Lab02/lab02.html#data-classes",
    "href": "Pages/Labs/Lab02/lab02.html#data-classes",
    "title": "Lab02",
    "section": "Data Classes",
    "text": "Data Classes\nLast week, we were introduced to the notion of data types. Recall that “data type” can be thought of as the category (or type) of data- i.e. integer, float, character, etc.\n\nIn Python, however, we often need to aggregate data into larger structures, often referred to as data classes.\n\nLists\nPerhaps the most fundamental data structure in Python is that of a list. Just like lists in real life or in mathematics, Python lists are just collections of items enclosed in square brackets:\n\n[<item 1>, <item 2>, ..., <item n>]\n\nAgain, the items in a list can be of any data type; we can even mix and match data types!\n\n\n\n\n\n\nTask 1\n\n\n\nCreate a list containing the elements 1, \"hi\", 3.4, and \"PSTAT 5A\". Assign this list to a variable called list1.\n\n\nJust as we were able to use a Python function (type()) to check the type of a particular piece of data, we can also use Python to check the structure or class of a piece of data. It turns out that we use the same function as before- namely, type()!\n\n\n\n\n\n\nTask 2\n\n\n\nRun the code type(list1)."
  },
  {
    "objectID": "Pages/Labs/Lab02/lab02.html#indexing",
    "href": "Pages/Labs/Lab02/lab02.html#indexing",
    "title": "Lab02",
    "section": "Indexing",
    "text": "Indexing\nAlright, now that we can store data in lists, how can we access elements in a list? The answer is to use what is known as indexing.\n\nGiven a list x, we access the ith element using the code\n\nx[i]\n\nThe reason we call this “indexing” is because the number that goes between the brackets is the index of the element that we want.\n\n\n\n\n\n\nCaution\n\n\n\nPython begins indexing at 0.\n\n\nWhat does this mean? Well, let’s see by way of an example.\n\n\n\n\n\n\nTask 3\n\n\n\n\nCreate a list with the numbers 1 through 10, inclusive.\nRun the code x[1].\nRun the code x[0].\n\n\n\nSo, what we would colloquially call the first element of a list, Python calls the zeroeth element.\n\n\nAlright, let’s put together some of the concepts we just learned.\n\n\n\n\n\n\nTask 4\n\n\n\nCreate a list called x that contains the elements 1, \"two\", 3.5, \"four\", and \"five five\". Answer the following questions WITHOUT running any code, writing your answers as a comment in a code cell:\n\nWhat would be the output of type(x)?\nWhat would be the output of type(x[1])?\nWhat would be the output of x[0]?\n\nNow, run code to verify your answers to the above three questions."
  },
  {
    "objectID": "Pages/Labs/Lab02/lab02.html#tables",
    "href": "Pages/Labs/Lab02/lab02.html#tables",
    "title": "Lab02",
    "section": "Tables",
    "text": "Tables\nAnother very useful data structure in Python is that of a table. Python tables behave pretty much the same as the tables we’ve used in, say, math- they are a grid of values arranged sequentially.\n\nTables can be created using the Table() function in Python, which itself comes from the datascience module. The general syntax of creating a table with the Table() function is:\n\nTable().with_columns(\n  \"<col 1 name>\", [<col 1, val 1>, <col 1, val 2>, ... ],\n  \"<col 2 name>\", [<col 2, val 1>, <col 2, val 2>, ... ],\n  ...\n)\n\nFor example,\n\nTable().with_columns(\n  \"Name\", [\"Ethan\", \"Morgan\", \"Amy\"],\n  \"ID\", [12345, 10394, 20343],\n  \"Office\", [\"South Hall\", \"South Hall\", \"North Hall\"]\n)\n\n\n\n    \n        \n            Name ID Office\n        \n    \n    \n        \n            Ethan  12345 South Hall\n        \n        \n            Morgan 10394 South Hall\n        \n        \n            Amy    20343 North Hall\n        \n    \n\n\n\nThere is nothing stopping us from assigning a table to a variable! For example, after running\n\ntable1 = Table().with_columns(\n  \"Name\", [\"Ethan\", \"Morgan\", \"Amy\"],\n  \"ID\", [12345, 10394, 20343],\n  \"Fav_Drink\", [\"Iced Tea\", \"Coffee\", \"Sprite\"]\n)\n\nthe variable table1 is equivalent to the table displayed above:\n\ntable1\n\n\n\n    \n        \n            Name ID Fav_Drink\n        \n    \n    \n        \n            Ethan  12345 Iced Tea \n        \n        \n            Morgan 10394 Coffee   \n        \n        \n            Amy    20343 Sprite   \n        \n    \n\n\n\n\n\n\n\n\n\nTerminology\n\n\n\nSometimes in Python we will encounter expressions of the form\n\n<object type>.<function name>()\n\nIn this syntax, the function <function name> is said to be a method. For example, the function with_columns() is a method for the Table object.\n\n\nThe datascience module contains a plethora of methods we can use to manage tables. For example, the select() method can be used to select columns by name:\n\ntable1.select(\"ID\")\n\n\n\n    \n        \n            ID\n        \n    \n    \n        \n            12345\n        \n        \n            10394\n        \n        \n            20343\n        \n    \n\n\n\n\n\n\n\n\n\nSyntax\n\n\n\nMethods are always appended to either a function that creates a blank object type (like Table()) or a variable of the correct type.\n\n\n\n\n\n\n\n\nTask 5\n\n\n\nRead the list of methods for Table objects at http://data8.org/datascience/tables.html, and write down (in a code cell, using comments) at least three different methods, including a short description of what each method does. For example:\n\n# .with_columns(): adds specified columns to a table.\n\n\n\n\n\n\n\n\n\nTask 6\n\n\n\n\nCreate the following table, and assign it to a variable called profs:\n\n\n\n\n\n    \n        \n            Professor Office Course\n        \n    \n    \n        \n            Dr. Swenson    South Hall PSTAT 130 \n        \n        \n            Dr. Wainwright Old Gym    PSTAT 120A\n        \n        \n            Dr. Mouti      Old Gym    PSTAT 126 \n        \n    \n\n\n\nRun a cell containing only the code profs to make sure (visually) that your table looks correct.\n\nSelect the column called Course from profs.\nAppend (i.e. add) a new row to the profs table, containing the following information:\n\n\n\n\n\n    \n        \n            Professor Office Course\n        \n    \n    \n        \n            Dr. Ravat South Hall PSTAT 120B\n        \n    \n\n\n\nRun a cell containing only the code profs to make sure (visually) that the appending was successful.\n\n\nSuppose we want to select rows of a table that satisfy a given condition. For example, if we wanted to find the information of only people who like Sprite in the table1 table above, we would call\n\ntable1.where(\"Fav_Drink\", \"Sprite\")\n\n\n\n    \n        \n            Name ID Fav_Drink\n        \n    \n    \n        \n            Amy  20343 Sprite   \n        \n    \n\n\n\nWhat would happen if we tried to select the rows of table1 with Coke in the Fav_Drink column? Well, since there is nobody in table1 that has coke as their favorite drink, we should hope that Python returns an empty table.\n\ntable1.where(\"Fav_Drink\", \"Coke\")\n\n\n\n    \n        \n            Name ID Fav_Drink\n        \n    \n    \n    \n\n\n\nSure enough, Python has returned an empty table!"
  },
  {
    "objectID": "Pages/Labs/Lab02/lab02.html#arrays",
    "href": "Pages/Labs/Lab02/lab02.html#arrays",
    "title": "Lab02",
    "section": "Arrays",
    "text": "Arrays\nThe final Data Structure we will examine in this class is that of an array. Arrays behave very similarly to Tables, with a few differences. For one, the syntax used to create an array is slightly different:\n\nmake_array(<item 1>, <item 2>, <item 3>, ...)\n\nFor example,\n\nmake_array(\"Spring\", \"Summer\", \"Autumn\", \"Winter\")\n\narray(['Spring', 'Summer', 'Autumn', 'Winter'],\n      dtype='<U6')\n\n\nYou may ask- what’s that dtype='<U6' symbol at the end of the output? For now, don’t worry about it, as we will revisit this later."
  },
  {
    "objectID": "Pages/Labs/Lab02/lab02.html#lists-vs.-arrays",
    "href": "Pages/Labs/Lab02/lab02.html#lists-vs.-arrays",
    "title": "Lab02",
    "section": "Lists vs. Arrays",
    "text": "Lists vs. Arrays\nSo, we now know about three different data classes in Python: lists, tables, and arrays. At first glance, lists and arrays may seem somewhat similar. However, there are a few key differences between them:\n\n\n\n\n\n\nTask 7\n\n\n\nMake a list called my_list containing the elements 1, 2, and 3, and make an array called my_array also containing the elements 1, 2, and 3. Run the following commands in separate code cells:\n\nsum(my_list)\nsum(my_array)\nmy_list + 2\nmy_array + 2\n\n\n\nWhat the previous Task illustrates is the fact that arrays lend themselves to element-wise operations, whereas lists do not. One important limitation about arrays, though, is that the elements in an array must all be of the same data type. If you try to make an array consisting of elements that are different data types Python will still run, however it will not run in the way you expect it to!"
  },
  {
    "objectID": "Pages/Labs/Lab01/lab01.html",
    "href": "Pages/Labs/Lab01/lab01.html",
    "title": "Lab01",
    "section": "",
    "text": "This page will be updated soon with the first Lab."
  },
  {
    "objectID": "Pages/Labs/Lab01_v2/lab01_v2.html",
    "href": "Pages/Labs/Lab01_v2/lab01_v2.html",
    "title": "Lab01",
    "section": "",
    "text": "Welcome to the first PSTAT 5A Computing Lab! As we will soon learn, computing software provides an incredibly useful tool in Statistical analyses. Each software comes with its own unique programming language- in this class, we will use the language known as Python, though many other programming languages exist."
  },
  {
    "objectID": "Pages/Labs/Lab01_v2/lab01_v2.html#structure-of-labs",
    "href": "Pages/Labs/Lab01_v2/lab01_v2.html#structure-of-labs",
    "title": "Lab01",
    "section": "Structure of Labs",
    "text": "Structure of Labs\nEvery week we (the course staff) will publish a lab document, which is intended to be completed during your Lab Section (i.e. your section Section) of the week.\n\nEach lab document will consist of a combination of text, tips, and the occasional task for you to complete based on the text provided. Your TA will cover exactly what you need to turn in at the end of each lab in order to receive credit, but you should read all lab material carefully and thoroughly as content from labs will appear on quizzes and exams."
  },
  {
    "objectID": "Pages/Labs/Lab01_v2/lab01_v2.html#what-is-programming",
    "href": "Pages/Labs/Lab01_v2/lab01_v2.html#what-is-programming",
    "title": "Lab01",
    "section": "What Is Programming?",
    "text": "What Is Programming?\nComputers, though incredibly useful, are fairly complex machines. To communicate with them, we need to use a specific language, known as a Programming Language. There are a number of programming languages currently in use, with names such as R, Julia, MatLab, and - the language we will use for this course - Python.\n\nPython programs can be written in a number of different environments, such as a text editor (e.g. Notepad, VS Code, etc.) or a Terminal window. For this class, we will use Jupyter Notebook (where Jupyter is pronounced like the planet), an interactive environment that has the added benefit of being hosted online, meaning you do not have to download anything onto your personal machines in order to run Python code!"
  },
  {
    "objectID": "Pages/Labs/Lab01_v2/lab01_v2.html#getting-started",
    "href": "Pages/Labs/Lab01_v2/lab01_v2.html#getting-started",
    "title": "Lab01",
    "section": "Getting Started",
    "text": "Getting Started\n\nNavigate to https://pstat5a.lsit.ucsb.edu\nClick the “Sign in with your UCSB NetID” button, and sign in.\nUnder “Notebook”, click “Python 3 (ipykernel)” (see below).\n\n\nCongratulations- you have just made your first Jupyter notebook! Now, it’s time for our first task:\n\n\n\n\n\n\nTask 1\n\n\n\nChange the name of your notebook to “Lab01” using the following steps:\n\nIn the lefthand menu bar, find the notebook you just created (by default this will be something like “Untitled” or “Untitled1”), and right-click and click “Rename” (see picture below)\n\n\n\nRename your file to “Lab01”, and then hit the return (enter) key on your keyboard. You should see the filename in the menubar update:\n\n\n\n\n\nJupyterHub Environment\nLet’s take a minute to familiarize ourselves with the JupyterHub environment. Every Jupyter notebook is comprised of what are known as cells; these are the shaded grey rectangles that appear in a Jupyter notebook.\n\nIf your cell has a grey background (like in the image above), it is inactive. To activate a cell, place your cursor inside it, and click:\n\nmeans it is selected and active, and ready to be populated with text and/or code.\n\n\n\n\n\n\nImportant\n\n\n\nWhen you run code using the “Run” button at the top of your environment, only the active cell will be executed.\n\n\n\n\nCells\nThere are two main types of cells we will be using in this class: Markdown cells (which include text/descriptions, but no code) and code cells (which contain code that needs to be run). We’ll be talking a bit more about Markdown cells in a few weeks.\n\n\n\n\n\n\nTask 2\n\n\n\n\nIf you haven’t already, click into the code cell that was automatically created when you created your document to activate it.\nClick on the dropdown menu that currently says “code” (near the center of the top of your interface), and select “Markdown”\n\n\n\nClick back into the cell, copy-paste the text [including the hashtag!] # Task 2, and then run the cell by clicking on the button that looks like a “play” symbol at the top of your window:\n\n\n\nNote that after running your cell from step 3 above, Jupyter automatically created a new code cell. Click into this code cell and run the code 2 + 2.\n\nWhen you are done, your notebook should look something like this:\n\n\n\nNotice that after running a cell, Jupyter automatically adds a new cell right after it!\n\n\n\n\n\n\nTip\n\n\n\nTo run a cell and automatically create a new cell underneath it, use the keyboard shortcut SHIFT + ENTER.\n\n\nBy the way, do you notice the little In [1]: at the left of our first cell? This is Jupyter’s way of letting us know the order in which the code cells have been executed. The 1 in our cell from Task 2 above corresponds to the fact that this was the 1st code cell we executed in our document."
  },
  {
    "objectID": "Pages/Labs/Lab01_v2/lab01_v2.html#coding-with-python",
    "href": "Pages/Labs/Lab01_v2/lab01_v2.html#coding-with-python",
    "title": "Lab01",
    "section": "Coding with Python",
    "text": "Coding with Python\nThere is a reason we use the word “language” to describe programming languages- that is because they function quite like a human language. This means that they each have their own syntax (i.e. set of grammar rules). It is precisely the Syntax of the Python language that we will be learning over the course of these Computing Labs!\n\nPrograms are made up of expressions, like 2 + 2. We evaluate expressions by running (or executing) them in a programming language. Expressions are like the sentences of programming- they contain complex pieces of information that are conveyed between the user and the computer.\n\nMuch like sentences in other languages, expressions must obey a rigid syntax. For example, when we want to perform addition in Python we must use the + symbol; we can’t, for example, say 2 plus 2.\n\nWhat happens when we violate a syntax rule? Well…\n\n\n\n\n\n\nTask 3\n\n\n\n\nCreate a mardown cell and write # Task 3\nCreate a code cell, and run 2 plus 2. (You should get an error!)\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nFor this class, we expect you to precede each code cell from a particular task with a markdown cell that says # Task X (where X is the number of the task).\n\nWe will stop explicitly writing this step in the tasks below, but you are still expected to include a labeling cell!\n\n\nWell, what is this error saying? Let’s examine it more closely.\n\n  File \"<ipython-input-2-5196071441ec>\", line 1\n    2 plus 2\n      ^\nSyntaxError: invalid syntax\n\nIndeed, Python is telling us exactly what went wrong- the SyntaxError part of the error message tells us that we violated one of the syntax rules of Python, and the ^ pointing to the p in plus is telling us that the exact syntax error occurred when we tried to use the word plus.\n\n\n\n\n\n\nTip\n\n\n\nAlways read error messages!\n\n\nThe messages that Python displays when we get an error are Python’s way of trying to communicate with us what is going wrong!"
  },
  {
    "objectID": "Pages/Labs/Lab01_v2/lab01_v2.html#python-as-a-calculator",
    "href": "Pages/Labs/Lab01_v2/lab01_v2.html#python-as-a-calculator",
    "title": "Lab01",
    "section": "Python as a Calculator",
    "text": "Python as a Calculator\nAlright, let’s get our hands dirty with some real programming! One of the many uses of Python is to help us compute arithmetic quantities very quickly. As a rule-of-thumb, Python adheres to the order of operations:\n\nParentheses\nExponents\nMultiplication\nDivision\nAddition\nSubtraction\n\nHere is a list of mathematical operators and their corresponding Python syntax:\n\n\n\nOperation\nPython Operator\nExample\nResult\n\n\n\n\nAddition\n+\n2 + 2\n4\n\n\nSubtraction\n-\n2 - 2\n0\n\n\nMultiplication\n*\n2 * 2\n4\n\n\nDivision\n/\n2 / 2\n1\n\n\nExponentiation\n**\n2 ** 2\n4\n\n\n\n\n\n\n\n\n\nTask 4\n\n\n\nCompute the following:\n\n\\(\\displaystyle \\frac{2 + 3}{4 + 5^6}\\)\n\\(\\displaystyle (1 - 3 \\cdot 4^5)^{6}\\)\n\n\n\nNaturally, Python is capable of much more than just basic arithmetic!\n\n\n\n\n\n\nTask 5\n\n\n\nCreate a code chunk and run sin(1) to compute the sine of 1.\n\n\nUh-oh- looks like we’ve encountered another error! Indeed, even the most experience coder will often run up against errors like this, and need to subsequently enter the stage of debugging their code.\n\nWe’re now getting a new error: this time, it’s a NameError. As the name suggests, this is Python’s way of telling us that it doesn’t recognize the name of something we’ve written. In fact, it’s explicitly saying:\n\nNameError: name 'sin' is not defined,\n\nThis is Python’s way of telling us that it (somehow) doesn’t know what sin means.\n\nTo answer the question of why this is, we need to take a bit of a detour into the world of modules."
  },
  {
    "objectID": "Pages/Labs/Lab01_v2/lab01_v2.html#python-modules",
    "href": "Pages/Labs/Lab01_v2/lab01_v2.html#python-modules",
    "title": "Lab01",
    "section": "Python Modules",
    "text": "Python Modules\nIt is important to note that all Python objects take up space in the form of memory (i.e. storage space on your computer). Nowadays, with the recent innovations in computers, this is not so much of an issue but historically, when many of these programming languages were first being created, optimizing space was of the utmost concern. (Even today, efficiency is a guiding tenet of most programmers!)\n\nThink of it this way- if you are doing work on code that doesn’t involve much trigonometry, there isn’t a whole lot of need to have the sin function readily available. The idea programmers had was to compartmentalize, and store certain functions in what are known as modules.\n\nModules are Python files containing definitions for functions and classes (we’ll talk about classes a little later). While data types and built-in functions in the Python standard library are available for immediate use, modules need to be imported first.\n\nThe syntax for importing all functions from a module is:\n\nfrom <module name> import *\n\nSometimes, we may not want to import the entirety of a module and instead import only a couple of functions from that module. In that case, we would use the syntax:\n\nfrom <module name> import <function name>\n\nWe’ll talk a bit more about modules in a future lab. For now, let’s return to our task of computing \\(\\sin(1)\\).\n\n\n\n\n\n\nTask 5 (cont’d)\n\n\n\nIt turns out that the sin() function is located in the math module Load all functions from the math module, and then try re-running sin(1)."
  },
  {
    "objectID": "Pages/Labs/Lab01_v2/lab01_v2.html#functions",
    "href": "Pages/Labs/Lab01_v2/lab01_v2.html#functions",
    "title": "Lab01",
    "section": "Functions",
    "text": "Functions\nWe will talk extensively about Python functions in a few weeks. For now, suffice it to say that Python functions work just like mathematical functions: for example, note how we used the sin() function in the previous task. One piece of terminology that is somewhat specific to programming is the notion of calling- when we say to call a function on an argument, we mean to pass that argument through the function. So, for example, in Task 5 we called the sin() function on the argument 1."
  },
  {
    "objectID": "Pages/Labs/Lab01_v2/lab01_v2.html#variable-assignment",
    "href": "Pages/Labs/Lab01_v2/lab01_v2.html#variable-assignment",
    "title": "Lab01",
    "section": "Variable Assignment",
    "text": "Variable Assignment\nLet’s talk a bit about variables. Just like in math, variables in a programming language refer to a placeholder name for a particular piece of information (be it a function, value, etc.) The act of storing information in a variable is called assignment, and in Python variable assignment is performed using the = symbol.\n\n<variable name> = <what you want to associate with the variable>\n\nFor example, after running\n\nx = 2\n\nthe quantity x will always be synonymous with the quantity 2, and running x + 2 will return a value of 4 (as 2 + 2 = 4).\n\nPython affords a lot of flexibility when it comes to variable names- that is, we can pick almost anything we want to be a variable name! There are, however, some exceptions:\n\nVariable names cannot start with a number\nVariable names cannot include a space\n\n\n\n\n\n\n\nTip\n\n\n\nIt is a good programming practice to give your variables names that are descriptive, but not overly long.\n\n\nIf we want to view the value stored in a variable, we have two options: we could simply type the name of the variable, and run the cell:\n\nx\n\n2\n\n\nor we could pass the variable name into a call to the print() function:\n\nprint(x)\n\n2\n\n\n\n\n\n\n\n\nTask 6\n\n\n\n(a) Define a variable called my_variable, and assign it the value 5.\n(b) Now, run the command print(My_variable) (note the capitalization!)\n\n\n\n\n\n\n\n\nTip\n\n\n\nPython is case-sensitive.\n\n\nSometimes it will be necessary to update or re-assign a new value to an existing variable. For example, let’s examine the structure of the following code:\n\nx = 2\nx = x + 3\n\nWhat do you think running x will return? If you said 5, you’d be correct! The key point of this is:\n\n\n\n\n\n\nImportant\n\n\n\nIn variable assignment, Python starts by executing the righthand side of the equality before executing the lefthand side.\n\n\nSo, in code example above, Python first executed x + 3 (which is equivalent to 2 + 3; i.e. 5), and then re-assigned x the value 5."
  },
  {
    "objectID": "Pages/Labs/Lab01_v2/lab01_v2.html#comments",
    "href": "Pages/Labs/Lab01_v2/lab01_v2.html#comments",
    "title": "Lab01",
    "section": "Comments",
    "text": "Comments\nWhen writing large pieces of code, programmers will often utilize comments to annotate their work and help readers understand what their code is doing. In Python there are two types of comments: inline comments and multiline comments. As an example of both, consider the following snippet of code:\n\nx = 1             # define x\ny = 2             # define y\nz = (x + y) ** 2  # define z\ny = z / 3         # redefine y\n\n\"\"\"This code is defines 3 variables,\ncalled 'x', 'y', and 'z'.\"\"\"\n\n\n\n\n\n\n\nTask 7\n\n\n\nGo back and add some descriptive comments to some of your previous code cells. (You don’t need a separate markdown cell indicating you have done so.)"
  },
  {
    "objectID": "Pages/Labs/Lab01_v2/lab01_v2.html#data-types",
    "href": "Pages/Labs/Lab01_v2/lab01_v2.html#data-types",
    "title": "Lab01",
    "section": "Data Types",
    "text": "Data Types\nBefore closing out this lab, we should talk a bit about the quantities we assign to variables- i.e. the different data types in Python.\n\nThe term data type loosely refers to the actual type of a particular quantity (e.g. numerical, character, etc.) The main data types we will encounter in this class are:\n\nfloat: refers to numerical (real-valued) quantities\nint: short for integer; refers to numerical quantities that are integers\nstr: short for string; refers to character- or text-type data (and will always be enclosed in either single quotation marks or double quotation marks)\n\n\n\n\n\n\n\nTask 8\n\n\n\nRun each of the following:\n\ntype(1)\ntype(1.1)\ntype(\"hello\")\n\n\n\nLet’s combine our knowledge of variable assignment with our newfound knowledge of data types!\n\n\n\n\n\n\nTask 9\n\n\n\n(a) Perform the following variable assignments:\n\ncourse = \"PSTAT 5A\"\nnum_sections = 4\nsection_capacity = 25\n\n(c) A new section has been added! Update the variable num_sections to be one more than when you initially defined it above. (Don’t just use num_sections = 5- think about our discussion on updating variables above!)\n(b) Using comments, write down what you think the output of each of the following expressions will be:\n\ntype(course)\ntype(num_sections)\nnum_sections * section_capacity\n\nThen, run each expression in a separate code chunk and comment on the results.\n(c) Create a new variable called course_capacity and assign it the value of the maximum capacity of the course. (Hint: there are only 5 sections, and each section has a maximum capacity of 25. Try to use your already-defined variables as much as possible!)\n\n\n\n\n\n\n\n\nTip\n\n\n\nThe type() function can be used to identify the data type of a particular quantity."
  },
  {
    "objectID": "Pages/Labs/Lab01_v2/lab01_v2.html#final-formatting",
    "href": "Pages/Labs/Lab01_v2/lab01_v2.html#final-formatting",
    "title": "Lab01",
    "section": "Final Formatting",
    "text": "Final Formatting\nIt’s time to start adding the finishing touches to our first lab!\n\n\n\n\n\n\nTask 10\n\n\n\n\nClick on the gear-shaped icon in the top-right of your console:\n\n\n\nScroll down until you see the Notebook Metadata:\n\n\n\nRight after the second-to-last brace (}), add a comma , and then the following code:\n\n\n\"authors\": [\n        {\n            \"name\": \"<YOUR NAME>\"\n        },\n        {\n            \"name\": \"<YOUR NETID>\"\n        }\n    ]\n\nwhere you replace <YOUR NAME> and <YOUR NETID> with your name and NetID, respectively. For example, after performing the above steps, my Notebook Metadata would look like:"
  },
  {
    "objectID": "Pages/Labs/Lab01_v2/lab01_v2.html#what-to-turn-in",
    "href": "Pages/Labs/Lab01_v2/lab01_v2.html#what-to-turn-in",
    "title": "Lab01",
    "section": "What to Turn In",
    "text": "What to Turn In\nCongrats on finishing the first PSTAT 5A Computing Lab! Here’s what you need to submit:\n\nYour downloaded .ipynb file\nYour downloaded .PDF file\n\n(Please consult the video on Canvas showing you how to upload your work to Gradescope). Toward the end of Lab, your TA will show you how to download the above files. You will have until 40 minutes after the end of your Section (i.e. until 30 minutes past the next hour) to turn in your work in order to get credit for the lab. Also, please remember that you need to upload We will be grading labs based on effort, so just turn in what you are able to!"
  },
  {
    "objectID": "Pages/course_staff.html",
    "href": "Pages/course_staff.html",
    "title": "PSTAT 5A: Understanding Data",
    "section": "",
    "text": "Instructor: Ethan P. Marzban\n\n\n\n\n\n\n\n\n\n\n\n\n\nEthan P. Marzban\n\n\nHello! I am currently in the 3rd year of my PhD program here in the PSTAT department, having joined back in 2020 (after having completed my undergraduate degree in Statistics as well). Outside of school I enjoy playing the piano, drinking boba, and talking about cats!\n\n\n\n\n\nEmail:\n\n\nepmarzban@pstat.ucsb.edu\n\n\n\n\nOH:\n\n\nHW Clinic: Tuesdays, 4:30 - 5:30 in ELLSN 2626  OH: Fridays, 12 - 1pm in SH 5607F (Sobel)"
  },
  {
    "objectID": "Pages/course_staff.html#teaching-assistants-tas",
    "href": "Pages/course_staff.html#teaching-assistants-tas",
    "title": "PSTAT 5A: Understanding Data",
    "section": "Teaching Assistants (TAs)",
    "text": "Teaching Assistants (TAs)\n\n\n\n\n\n\n\nTA: Nickolas Thiessen\n\n\n\n\n\n\n\n\n\n\n\n\n\nNickolas Thiessen\n\n\nNickolas is currently a student in the BS/MS program in Actuarial Science, in the PSTAT department.\n\n\n\n\n\nEmail:\n\n\nnickolas@ucsb.edu\n\n\n\n\nOH:\n\n\nFridays, 9 - 11am in Building 434 Rm 113\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTA: Jason Teng\n\n\n\n\n\n\n\n\n\n\n\n\n\nJason Teng\n\n\nJason is currently a student in the Masters Program in the PSTAT department.\n\n\n\n\n\nEmail:\n\n\njteng@ucsb.edu\n\n\n\n\nOH:\n\n\nThursdays, 11am - noon in South Hall 5421 (the StatLab)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTA: Yuan Zhou\n\n\n\n\n\n\n\n\n\n\n\n\n\nYuan Zhou\n\n\nYuan is currently a student in the Masters program in the PSTAT department.\n\n\n\n\n\nEmail:\n\n\nyuan_zhou@ucsb.edu\n\n\n\n\nOH:\n\n\nTuesdays, 10 - 11am in South Hall 5421 (the StatLab)"
  },
  {
    "objectID": "Pages/course_staff.html#undergraduate-learning-assistants-ulas",
    "href": "Pages/course_staff.html#undergraduate-learning-assistants-ulas",
    "title": "PSTAT 5A: Understanding Data",
    "section": "Undergraduate Learning Assistants (ULAs)",
    "text": "Undergraduate Learning Assistants (ULAs)\n\n\n\n\n\n\n\nULA: Catherine Li\n\n\n\n\n\n\n\n\n\n\n\n\n\nCatherine Li\n\n\nMore information coming soon!\n\n\n\n\n\nEmail:\n\n\ncatherine_li@umail.ucsb.edu\n\n\n\n\nOH:\n\n\nM 2 - 4pm, Th 9 - 11am (Zoom)\n\n\n\nStudy Groups:\n\n\nT 3:30 - 4:30pm (ELLSN 2626), Th 3:30 - 5:30 (SH 5421)"
  },
  {
    "objectID": "Pages/syllabus.html",
    "href": "Pages/syllabus.html",
    "title": "PSTAT 5A: Understanding Data",
    "section": "",
    "text": "WELCOME TO PSTAT 5A! I am very excited to introduce to you the wonderful worlds of Statistics and Data Science. As our world becomes ever more saturated with data, the need for data literacy becomes increasingly important. By the end of this course, I hope you will be able to think critically about statistical studies and results, understand how data can be used to simultaneously inform and manipulate, and begin applying your newfound techniques to your future endeavors, all while gaining an introduction to the fields of Statistics and Data Science. I am very much looking forward to a great quarter with all of you!\n— Ethan"
  },
  {
    "objectID": "Pages/syllabus.html#lecture-information",
    "href": "Pages/syllabus.html#lecture-information",
    "title": "PSTAT 5A: Understanding Data",
    "section": "Lecture Information",
    "text": "Lecture Information\n\n\n\n\n\n\nLecture Times and Locations\n\n\n\nTuesdays and Thursdays: 2:00pm - 3:15pm in CHEM 1171"
  },
  {
    "objectID": "Pages/syllabus.html#course-staff",
    "href": "Pages/syllabus.html#course-staff",
    "title": "PSTAT 5A: Understanding Data",
    "section": "Course Staff",
    "text": "Course Staff\n\n\n\n\n\n\n\n\n\n\nInstructor:\nEthan P. Marzban\n\n\n\n\nEmail:\nepmarzban@pstat.ucsb.edu\n\n\nHelp Hours:\n\nHW Clinic: Tuesdays 4:30 - 5:30pm in ELLSN 2626\nOH: Fridays 12-1pm in SH 5607F\n\n\n\n\n\n\n\n\n\n\n\n\nTAs\n\n\n\n\nNickolas Thiessen\n(nickolas@ucsb.edu)\n\n\nJason Teng\n(jteng@ucsb.edu)\n\n\nYuan Zhou\n(yuan_zhou@ucsb.edu)"
  },
  {
    "objectID": "Pages/syllabus.html#course-description",
    "href": "Pages/syllabus.html#course-description",
    "title": "PSTAT 5A: Understanding Data",
    "section": "Course Description",
    "text": "Course Description\nThe official description of this course, from the Course Catalogue, is:\n\nIntroduction to data science. Concepts of statistical thinking. Topics include random variables, sampling distributions, hypothesis testing, correlation and regression. Visualizing, analyzing and interpreting real world data using Python. Computing labs required."
  },
  {
    "objectID": "Pages/syllabus.html#textbooks",
    "href": "Pages/syllabus.html#textbooks",
    "title": "PSTAT 5A: Understanding Data",
    "section": "Textbook(s)",
    "text": "Textbook(s)\nThis quarter, we do not have a required textbook- the lecture slides and lab activities are designed to be self-sufficient. However, the following textbooks are highly recommended:\n\nOpenIntro: Statistics. David Diez, Mine Çetinkaya-Rundel, and Christopher D Barr. (free version, courtesy of the authors, available at https://leanpub.com/os)\nComputational and Inferential Thinking: The Foundations of Data Science. Ani Adhikari and John DeNero. (available at: https://www.inferentialthinking.com)\nStatClass (2nd Edition, Revised). Dawn E. Holmes and Lubella A. Lenaburg"
  },
  {
    "objectID": "Pages/syllabus.html#course-components",
    "href": "Pages/syllabus.html#course-components",
    "title": "PSTAT 5A: Understanding Data",
    "section": "Course Components",
    "text": "Course Components\nThe following are the assignments and metrics that will be used to compute your final grade in this course:\n\nHomework:\nThere will be weekly homework assignments that are each graded out of 10 points, on a combination of correctness and completion: we will select a few parts/problems to be graded out of 8 points on correctness, and you will be awarded 2 points for completing the remainder of the homework. Your lowest homework score will be dropped.\n\nHomework assignments will typically be released on Wednesdays and be due on Tuesdays, with the exception of Exam Weeks when the homework will be due on Monday.\n\n\nQuizzes\nQuizzes will be administered on Wednesdays, During your Lab Section. Make-up quizzes will not be offered; instead, your lowest quiz score will be dropped at the end of the quarter. There are no quizzes in Exam Weeks.\n\n\nExams\nThere are two midterms and a final exam for this class. You are required to take all three exams; failure to do so will result in an automatic grade of “F”, so please ensure you are able to take the exams on the dates listed below.\n\n\n\n\n\n\nExam Dates:\n\n\n\n\nMidterm 1 is scheduled to take place Tuesday, April 25 from 2 - 3:15pm (lecture time)\nMidterm 2 is scheduled to take place Tuesday, May 23 from 2 - 3:15pm (lecture time)\nThe final is scheduled to take place Tuesday, June 13 from 4 - 7pm (as determined by the University)\n\n\n\nThe midterms are scheduled to take place in Embarcadero Hall, and will have assigned seating. The Final Exam will also take place in Embarcadero Hall. Unless stated otherwise, all exams will be cumulative.\n\n\nSchedule of Due Dates\nA tentative schedule of release and due dates can be found here"
  },
  {
    "objectID": "Pages/syllabus.html#grading-scheme",
    "href": "Pages/syllabus.html#grading-scheme",
    "title": "PSTAT 5A: Understanding Data",
    "section": "Grading Scheme",
    "text": "Grading Scheme\nYour final grade will be computed using the following weights:\n\n\n\nHomework:\n10%\n\n\nLabs:\n10%\n\n\nQuizzes:\n10%\n\n\nMidterm 1\n20%\n\n\nMidterm 2\n20%\n\n\nFinal Examination:\n30%\n\n\n\nPlease note that late submissions for any of the above will not be accepted. Instead, I will drop your lowest homework, lab, quiz, and midterm score (you must take all three exams; failure to do so will result in an automatic ‘F’)\nYour final letter grade will be issued according to the following scheme (cutoffs between plusses and minuses will be calculated at the end of the quarter):\n\nA– – A+: 90 – 100%\nB– – B+: 80 – 89.99%\nC– – C+: 70 – 79.99%\nD– – D+ : 60 – 69.99%\nF: 0 – 59.99%\n\nPlease note: I have elected to adopt an uncurved grading scheme to eliminate any sense of “competition” among students; I highly encourage you all to collaborate with and uplift each other. Having said that, I will certainly consider adjusting the cutoffs (naturally, in everyone’s favor) at the end of the quarter if necessary."
  },
  {
    "objectID": "Pages/syllabus.html#academic-integrity",
    "href": "Pages/syllabus.html#academic-integrity",
    "title": "PSTAT 5A: Understanding Data",
    "section": "Academic Integrity",
    "text": "Academic Integrity\nAs a member of the UCSB community, it is expected that you will act with academic integrity. This means, among other things, that the work you submit should be entirely your own and not copied from any external sources. Collaboration on homework assignments is perfectly acceptable (even encouraged) but the work you submit should still be your own; you can’t have someone else write up solutions for you, nor can you consult cites like Chegg, CourseHero, etc. Anyone found guilty of academic misconduct will be reported to the Academic Senate, and will receive at minimum a failing grade on the assignment in question; further actions may also include failing the course, and marks being made on permanent records. Depending on the severity of the infraction, expulsion is also a possibility.\nBasically, don’t cheat- please! If you’re ever struggling with course material, please come talk to me or the TA’s. We are truly here for you, and want only the best for you."
  },
  {
    "objectID": "Pages/syllabus.html#intellectual-property",
    "href": "Pages/syllabus.html#intellectual-property",
    "title": "PSTAT 5A: Understanding Data",
    "section": "Intellectual Property",
    "text": "Intellectual Property\nYou’ve probably seen a clause on other syllabi stating something to the effect of “all material in this course is the intellectual property of myself and may not be shared with anyone outside this class without my explicit written permission.”\nThough this is all true, I will be making most course-related material available on a public GitHub site, which can be accessed here: https://pstat5a.github.io."
  },
  {
    "objectID": "Pages/syllabus.html#disabled-students-program-dsp",
    "href": "Pages/syllabus.html#disabled-students-program-dsp",
    "title": "PSTAT 5A: Understanding Data",
    "section": "Disabled Students Program (DSP)",
    "text": "Disabled Students Program (DSP)\nIf you have a disability, or otherwise require accommodations for the exams and/or quizzes please reach out to the Disabled Students Program (DSP) ASAP to ensure your request(s) for accommodation can be processed. We ask that all requests be logged at least a week in advance, to ensure the system enough time to process. Please note that we cannot grant any requests for accommodations unless they come to us from DSP directly."
  },
  {
    "objectID": "Pages/syllabus.html#technology-needs",
    "href": "Pages/syllabus.html#technology-needs",
    "title": "PSTAT 5A: Understanding Data",
    "section": "Technology Needs",
    "text": "Technology Needs\nAs a part of this course, you will be required to program in Python. Though the Lab Sections take place in specially designed classrooms that come equipped with computers, your homework and quizzes may cover Python-related questions, which means we expect you to have access to a laptop capable of connecting to the internet. If you do not currently possess such a laptop, please check out UCSB’s Basic Needs Resource page on Technology Resources to try and acquire one."
  },
  {
    "objectID": "Pages/syllabus.html#section-switching",
    "href": "Pages/syllabus.html#section-switching",
    "title": "PSTAT 5A: Understanding Data",
    "section": "Section Switching",
    "text": "Section Switching\nAs mentioned above, Sections (both Discussion and Lab) take place in special “Collaborate Classrooms” which are equipped with laptops. There are a fixed number of seats and laptops in these classrooms, meaning we cannot under any circumstance over-enroll sections. Therefore, if you want to switch section unofficially (we do not have the ability to switch your official enrollment through GOLD), please follow the steps at this link. Any requests to switch sections that do not adhere to the guidelines posted at that link will be ignored."
  },
  {
    "objectID": "Pages/syllabus.html#email-policy",
    "href": "Pages/syllabus.html#email-policy",
    "title": "PSTAT 5A: Understanding Data",
    "section": "Email Policy",
    "text": "Email Policy\nIf you need to send an email to me (Ethan), please include “PSTAT 5A” in the subject line of your email. Additionally, please allow up to one business day for a reply (though I will do my best to get back to you ASAP) Please note that I do not answer questions with extensive mathematics/equations over email (as trying to communicate in math over email can be a bit of a technical nightmare) Instead, if you have questions relating to course content I welcome you to either ask over Discord or during one of my Office Hours. Also, should you need to include your TA, please send a single email to both your TA and myself, as opposed to separate emails to the two of us. Thank you!"
  },
  {
    "objectID": "Pages/syllabus.html#disclaimer",
    "href": "Pages/syllabus.html#disclaimer",
    "title": "PSTAT 5A: Understanding Data",
    "section": "Disclaimer",
    "text": "Disclaimer\nThe instructor reserves the right to modify this syllabus if he deems such modifications academically advisable. Such modifications, should they occur, will be announced publicly."
  },
  {
    "objectID": "Pages/hw.html",
    "href": "Pages/hw.html",
    "title": "PSTAT 5A: Understanding Data",
    "section": "",
    "text": "Here you will find all homework assignments and their solutions.\n\nHomework 1: due by 11:59pm on Tuesday, April 11 .pdf Solns \nHomework 2: due by 11:59pm on Tuesday, April 18 .pdf Solns \nHomework 3: due by 11:59pm on MONDAY, APRIL 24 .pdf Solns \nHomework 4: due by 11:59pm on Tuesday, May 2 .pdf Solns \nHomework 5: will be posted by 6:30pm"
  },
  {
    "objectID": "Pages/Lectures/Lecture04/Lec04.html#last-time",
    "href": "Pages/Lectures/Lecture04/Lec04.html#last-time",
    "title": "PSTAT 5A: Lecture 04",
    "section": "Last Time",
    "text": "Last Time\n\nLast time we discussed the basics of probability.\n\nThese included things like: experiments, outcome spaces, events, and probability.\n\nI’d like to impart one additional tool that can help with visualizing the relationship between events: Venn Diagrams\nWe denote the outcome space \\(\\Omega\\) by a large rectangle, and denote events by circles.\nSince events are subsets of \\(\\Omega\\), we draw them inside (physically) the rectangle representing \\(\\Omega\\)."
  },
  {
    "objectID": "Pages/Lectures/Lecture04/Lec04.html#summary",
    "href": "Pages/Lectures/Lecture04/Lec04.html#summary",
    "title": "PSTAT 5A: Lecture 04",
    "section": "Summary",
    "text": "Summary\n\n\n\n\n\n \\(A^\\complement\\)  (complement)\n\n\n\n\n\n\n\n\n \\(A \\cap B\\)  (intersection)\n\n\n\n\n\n\n\n\n \\(A \\cup B\\)  (union)"
  },
  {
    "objectID": "Pages/Lectures/Lecture04/Lec04.html#demorgans-laws",
    "href": "Pages/Lectures/Lecture04/Lec04.html#demorgans-laws",
    "title": "PSTAT 5A: Lecture 04",
    "section": "DeMorgan’s Laws",
    "text": "DeMorgan’s Laws\n\nThis can also help give us some intuition on DeMorgan’s Laws as well!\n\nLet’s do this on the chalkboard together.\n\nWe will return to Venn Diagrams periodically throughout this course- for now, I hope they provide a useful tool to help you visualize the set operations we discussed last lecture."
  },
  {
    "objectID": "Pages/Lectures/Lecture04/Lec04.html#leadup",
    "href": "Pages/Lectures/Lecture04/Lec04.html#leadup",
    "title": "PSTAT 5A: Lecture 04",
    "section": "Leadup",
    "text": "Leadup\n\nNow, let’s return to the classical approach to probability.\nAssuming the outcomes in our outcome space \\(\\Omega\\) are equally likely, the classical approach tells us to compute the probability of any event \\(E\\) as \\[ \\mathbb{P}(E) = \\frac{\\text{number of ways $E$ can occur}}{\\text{total number of elements in $\\Omega$}} \\]\nUp until now, we’ve computed both the numerator and the denominator by explicitly listing out the elements contained in the respective sets, and then counting the number of elements.\nThis works decently for small sets, but is highly inefficient for large sets."
  },
  {
    "objectID": "Pages/Lectures/Lecture04/Lec04.html#ice-cream",
    "href": "Pages/Lectures/Lecture04/Lec04.html#ice-cream",
    "title": "PSTAT 5A: Lecture 04",
    "section": "Ice Cream",
    "text": "Ice Cream\n\nBefore diving fully into the principles of counting, let’s examine a simple situation.\nSuppose we are at a small boutique ice cream parlor that offers only 3 flavors (Vanilla, Chocolate, and Matcha), and 2 toppings (sprinkles or coconut).\n\nFurther suppose that an order of ice cream must contain only 1 flavor and 1 topping.\n\nWe can list out the different orders that are possible (i.e. the outcome space of the experiment of ordering an ice cream from this shop) using a tree diagram:"
  },
  {
    "objectID": "Pages/Lectures/Lecture04/Lec04.html#fundamental-principle-of-counting",
    "href": "Pages/Lectures/Lecture04/Lec04.html#fundamental-principle-of-counting",
    "title": "PSTAT 5A: Lecture 04",
    "section": "Fundamental Principle of Counting",
    "text": "Fundamental Principle of Counting\n\n\nThis is no accident!\n\n\n\n\n\n\n\n\n\n\nFundamental Principle of Counting\n\n\n\nIf an experiment consists of \\(k\\) stages, where the \\(i\\)th stage has \\(n_i\\) possible configurations, then the total number of elements in the outcome space is \\[ n_1 \\times n_2 \\times \\cdots \\times n_k \\]\n\n\n\n\n\n\n\nSo, when we obtained our answer of \\(6\\) on the previous slide, we were implicitly using the Fundamental Principle of Counting with 2 stages (picking a flavor, and picking a topping) where the first stage (picking a flavor) had 3 possible configurations (Vanilla, Chocolate, or Matcha) and the second stage (picking a topping) had two possible configurations (sprinkles or coconut)."
  },
  {
    "objectID": "Pages/Lectures/Lecture04/Lec04.html#slot-diagrams",
    "href": "Pages/Lectures/Lecture04/Lec04.html#slot-diagrams",
    "title": "PSTAT 5A: Lecture 04",
    "section": "Slot Diagrams",
    "text": "Slot Diagrams\n\nWhen dealing with the Fundamental Principle of Counting, I find it useful to utilize what are sometimes referred to as slot diagrams.\nHere’s how we use slot diagrams:\n\nFirst put down as many slots as there are stages in our experiment: \\[ \\underline{\\ \\ \\ \\ \\ } \\ \\ \\  \\underline{\\ \\ \\ \\ \\ } \\ \\ \\ \\cdots \\ \\ \\   \\underline{\\ \\ \\ \\ \\ }  \\]\nThen, fill in each slot with the corresponding number of configurations: \\[ \\underline{\\ n_1 \\ } \\ \\ \\  \\underline{\\ n_2 \\ } \\ \\ \\ \\cdots \\ \\ \\  \\underline{\\ n_k \\ }  \\]\nFinally, invoke the Fundamental Principle of Counting to multiply the slots together: \\[ \\underline{\\ n_1 \\ } \\ \\times \\  \\underline{\\ n_2 \\ } \\ \\times \\ \\cdots \\ \\times  \\underline{\\ n_k \\ }\\]"
  },
  {
    "objectID": "Pages/Lectures/Lecture04/Lec04.html#worked-out-example",
    "href": "Pages/Lectures/Lecture04/Lec04.html#worked-out-example",
    "title": "PSTAT 5A: Lecture 04",
    "section": "Worked-Out Example",
    "text": "Worked-Out Example\n\n\n\n\n\n\nWorked-Out Example 1\n\n\n\n\nSuppose a (different) ice cream parlor has 32 flavors, 5 toppings, and 3 drizzles. If a “scoop” consists of a flavor, topping, and drizzle, how many scoops can be created?\n\n\n\n\n\n\nThere are 3 stages: picking a flavor, picking a topping, and picking a drizzle. Hence, we draw three slots: \\[ \\underline{\\ \\ \\ \\ \\ } \\ \\ \\ \\underline{\\ \\ \\ \\ \\ } \\ \\ \\ \\underline{\\ \\ \\ \\ \\ } \\]\nThe first stage has 32 configurations, the second has 5, and the third has 3: \\[ \\underline{\\ 32 \\ } \\ \\ \\ \\underline{\\ 5 \\ } \\ \\ \\ \\underline{\\ 3 \\ } \\]\nFinally, we multiply through: \\[ \\underline{\\ 32 \\ } \\ \\times \\ \\underline{\\ 5 \\ } \\ \\times \\ \\underline{\\ 3 \\ } = \\boxed{480} \\]"
  },
  {
    "objectID": "Pages/Lectures/Lecture04/Lec04.html#ordering",
    "href": "Pages/Lectures/Lecture04/Lec04.html#ordering",
    "title": "PSTAT 5A: Lecture 04",
    "section": "Ordering",
    "text": "Ordering\n\nHere’s a question: given \\(n\\) tickets (labeled \\(1\\) through \\(n\\)), how many different ways are there to arrange them in a line?\nLet’s answer this using a slot diagram!\nWe can think of \\(n\\) stages, where the first stage corresponds to placing the first ticket down, the second stage corresponds to placing the second ticket down, and so on and so forth. \\[ \\underbrace{ \\underline{\\ \\ \\ \\ \\ } \\ \\ \\  \\underline{\\ \\ \\ \\ \\ } \\ \\ \\ \\cdots \\ \\ \\   \\underline{\\ \\ \\ \\ \\ } \\ \\ \\   \\underline{\\ \\ \\ \\ \\ } }_{\\text{$n$ slots}} \\]"
  },
  {
    "objectID": "Pages/Lectures/Lecture04/Lec04.html#factorials",
    "href": "Pages/Lectures/Lecture04/Lec04.html#factorials",
    "title": "PSTAT 5A: Lecture 04",
    "section": "Factorials",
    "text": "Factorials\n\n\n\n\n\n\n\nDefinition\n\n\n\nFor a positive integer \\(n\\), we define \\(n\\) factorial (denoted \\(n!\\)), to be \\[ n! = n \\times (n - 1) \\times (n - 2) \\times \\cdots \\times 2 \\times 1 \\]\n\n\n\n\n\n\nFor example:\n\n\\(3! = 3 \\times 2 \\times 1 = 6\\)\n\\(4! = 4 \\times 3 \\times 2 \\times 1 = 24\\)\n\\(5! = 5 \\times 4 \\times 3 \\times 2 \\times 1 = 120\\)"
  },
  {
    "objectID": "Pages/Lectures/Lecture04/Lec04.html#worked-out-example-2",
    "href": "Pages/Lectures/Lecture04/Lec04.html#worked-out-example-2",
    "title": "PSTAT 5A: Lecture 04",
    "section": "Worked-Out Example",
    "text": "Worked-Out Example\n\n\n\n\n\n\nWorked-Out Example 1\n\n\n\n\nSiobhan has 4 shirts in her closet: 2 purple shirts and 2 red shirts. When organizing these shirts in her closet she wants to keep the purple shirts together and the red shirts together, but doesn’t care if the purple group is to the left or the right of the red group. How many ways are there for Siobhan to arrange these shirts in her closet?\n\n\n\n\n\n\nLet’s answer this question two ways: using direct enumeration, and then using counting techniques.\nLabel the two purple shirts \\(P_1\\) and \\(P_2\\) respectively, and label the two red shirts \\(R_1\\) and \\(R_2\\) respectively. Then here are all of the possible reorderings of the shirts:\n\n\n\\[\\begin{align*}\n  \\Omega = \\{ & P_1 P_2 R_1 R_2, \\ P_1 P_2 R_2 R_1, \\ P_2 P_1 R_1 R_2, \\ P_2 P_1 R_2 R_1 , \\\\\n  & R_1 R_2 P_1 P_2, \\ R_2 R_1P_1 P_2, \\ R_1 R_2 P_2 P_1, \\  R_2 R_1P_2 P_1 \\}\n\\end{align*}\\]"
  },
  {
    "objectID": "Pages/Lectures/Lecture04/Lec04.html#does-order-matter",
    "href": "Pages/Lectures/Lecture04/Lec04.html#does-order-matter",
    "title": "PSTAT 5A: Lecture 04",
    "section": "Does Order Matter?",
    "text": "Does Order Matter?\n\nLet’s now consider a slightly more abstract experiment: consider drawing two tickets from a box with tickets labeled \\(A\\) through \\(C\\), not replacing my first ticket after I draw it.\n\nHow many elements are in the outcome space of this experiment?\n\nWell, the answer is…. it depends!\nSpecifically, we need to know: does order matter?\nHere’s what I mean by order mattering: in a license plate, 123ABC and ABC123 are clearly two different license plates, despite the fact that they are comprised of the same letters and numbers!\n\nAn example of a situation in which order does not matter is drawing cards from a deck of cards: whether I get the Ace of Hearts before or after the King of Diamonds doesn’t matter- all that mattes is that I have the Ace of Hearts and the King of Diamonds!\nSpeaking of cards, you’ll discuss playing cards a bit more on HW02."
  },
  {
    "objectID": "Pages/Lectures/Lecture04/Lec04.html#if-order-does-matter",
    "href": "Pages/Lectures/Lecture04/Lec04.html#if-order-does-matter",
    "title": "PSTAT 5A: Lecture 04",
    "section": "If Order Does Matter",
    "text": "If Order Does Matter\n\nLet’s examine what happens when we assume order does matter.\nIn the context of our drawing tickets example, this means that getting \\(A\\) followed by \\(C\\) is different than getting \\(C\\) followed by \\(A\\).\nThen, letting \\((X, Y)\\) denote the outcome ``I drew the ticket labelled \\(X\\) first, then the ticket labelled \\(Y\\) second’’ (for \\(X \\in \\{A, B, C\\}\\) and \\(Y \\in \\{A, B, C\\}\\)), we have \\[\\begin{align*}\n  \\Omega   = \\{ & (A, B), \\ (A, C) \\\\\n      & (B, A), \\ (B, C)  \\\\\n      & (C, A), \\ (C, B) \\}\n\\end{align*}\\]\n\nBy the way, can anyone tell me why I didn’t include outcomes like \\((A, A)\\)?"
  },
  {
    "objectID": "Pages/Lectures/Lecture04/Lec04.html#generalizing",
    "href": "Pages/Lectures/Lecture04/Lec04.html#generalizing",
    "title": "PSTAT 5A: Lecture 04",
    "section": "Generalizing",
    "text": "Generalizing\n\nLet’s generalize to picking \\(k\\) tickets from a total \\(n\\): \\[ \\underline{\\ \\ \\ \\ \\ {\\color{blue} {n}} \\ \\ \\ \\ \\ } \\ {\\times} \\\n  \\underline{\\ \\ \\ \\ \\ {\\color{blue}{n - 1}} \\ \\ \\ \\ \\ } \\ {\\times}  \\\n  \\underline{\\ \\ \\ \\ \\ {\\color{blue}{n - 2}} \\ \\ \\ \\ \\ } \\ {\\times}  \\\n  \\cdots \\ {\\times}  \n  \\underline{\\ \\ \\ \\ \\ {\\color{blue} {n - k + 1}} \\ \\ \\ \\ \\ } \\]\nWe can write this a little more succinctly using factorials: \\[ n \\times (n - 1) \\times \\cdots \\times (n - k + 1) = \\frac{n!}{(n - k)!} \\]\nThis is yet another quantity that arises so often, we give it a name: this time we call it \\(n\\) order \\(k\\), and write \\((n)_k\\)"
  },
  {
    "objectID": "Pages/Lectures/Lecture04/Lec04.html#n-order-k",
    "href": "Pages/Lectures/Lecture04/Lec04.html#n-order-k",
    "title": "PSTAT 5A: Lecture 04",
    "section": "\\(n\\) order \\(k\\)",
    "text": "\\(n\\) order \\(k\\)\n\n\n\n\n\n\n\nDefinition\n\n\n\nFor a positive integer \\(n\\) and another positive integer \\(k\\) that is less than \\(n\\), \\[ (n)_k = \\frac{n!}{(n - k)!}  = n \\times (n - 1) \\times \\cdots \\times (n - k + 1)  \\]\n\n\n\n\n\n\nFor example:\n\n\\((5)_3 = 5 \\times 4 \\times 3 = 60\\)\n\\((6)_2 = 6 \\times 5 = 30\\)\n\\((4)_4 = 4 \\times 3 \\times 2 \\times 1 = 24\\)"
  },
  {
    "objectID": "Pages/Lectures/Lecture04/Lec04.html#worked-out-example-3",
    "href": "Pages/Lectures/Lecture04/Lec04.html#worked-out-example-3",
    "title": "PSTAT 5A: Lecture 04",
    "section": "Worked-Out Example",
    "text": "Worked-Out Example\n\n\n\n\n\n\nWorked-Out Example 2\n\n\n\n\nSuppose now that I have 5 tickets, labeled \\(A\\) through \\(E\\), and I now want to draw 3. How many ways are there to do this, assuming order matters?\n\n\n\n\n\n\nBy our work above, the answer is \\((5)_3 = 5 \\times 4 \\times 3 = \\boxed{60}\\).\nDon’t believe me?\n\n\n\\[{\\tiny \\begin{aligned}[t]\n\\Omega  & = \\{ (A, B, C), \\ (A, B, D), \\ (A, B, E), \\ (A, C, B), \\ (A, C, D), \\ (A, C, E), \\ (A, D, B), \\ (A, D, C), \\ (A, D, E), \\ (A, E, B), \\ (A, E, C), \\ (A, E, D), \\\\\n    %\n    & \\hspace{5mm} (B, A, C), \\ (B, A, D), \\ (B, A, E), \\ (B, C, A), \\ (B, C, D), \\ (B, C, E), \\ (B, D, A), \\ (B, D, C), \\ (B, D, E), \\ (B, E, A), \\ (B, E, C), \\ (B, E, D), \\\\\n    %\n    & \\hspace{5mm} (C, A, B), \\ (C, A, D), \\ (C, A, E), \\ (C, B, A), \\ (C, B, D), \\ (C, B, E), \\ (C, D, A), \\ (C, D, B), \\ (C, D, E), \\ (C, E, A), \\ (C, E, B), \\ (C, E, D), \\\\\n    %\n    & \\hspace{5mm} (D, A, B), \\ (D, A, C), \\ (D, A, E), \\ (D, B, A), \\ (D, B, C), \\ (D, B, E), \\ (D, C, A), \\ (D, C, B), \\ (D, C, E), \\ (D, E, A), \\ (D, E, B), \\ (D, E, C), \\\\\n    %\n    & \\hspace{5mm} (E, A, B), \\ (E, A, C), \\ (E, A, D), \\ (E, B, A), \\ (E, B, C), \\ (E, B, D), \\ (E, C, A), \\ (E, C, B), \\ (E, C, D), \\ (E, D, A), \\ (E, D, B), \\ (E, D, C) \\}\n    \\end{aligned}}\\]"
  },
  {
    "objectID": "Pages/Lectures/Lecture04/Lec04.html#order-doesnt-matter",
    "href": "Pages/Lectures/Lecture04/Lec04.html#order-doesnt-matter",
    "title": "PSTAT 5A: Lecture 04",
    "section": "Order Doesn’t Matter",
    "text": "Order Doesn’t Matter\n\nLet’s return to our example of drawing \\(2\\) tickets from a set of tickets labeled \\(A\\) through \\(C\\).\nWe previously saw that if order does matter, there are 6 possible outcomes: \\[\\begin{align*}\n  \\Omega   = \\{ & (A, B), \\ (A, C) \\\\\n      & (B, A), \\ (B, C)  \\\\\n      & (C, A), \\ (C, B) \\}\n\\end{align*}\\]\nIf order doesn’t matter, we actually have fewer outcomes! Specifically:\n\n\\((A, C)\\) and \\((C, A)\\) become equivalent\n\\((A, B)\\) and \\((B, A)\\) become equivalent\n\\((B, C)\\) and \\((C, B)\\) become equivalent\n\nSo, \\(\\Omega\\) becomes \\(\\{(A, B), \\ (A, C), \\ (B, C)\\}\\), so we have only 3 elements in \\(\\Omega\\)."
  },
  {
    "objectID": "Pages/Lectures/Lecture04/Lec04.html#dont-worry",
    "href": "Pages/Lectures/Lecture04/Lec04.html#dont-worry",
    "title": "PSTAT 5A: Lecture 04",
    "section": "Don’t Worry!",
    "text": "Don’t Worry!\n\nI know that was a lot of math, pretty quickly.\nDon’t worry! We will be returning to a few of these concepts over the coming weeks.\nMy main goal for today’s lecture was to give you an overview of the types of arguments we make when dealing with counting problems, as well as to give you some tools to answer counting problems."
  },
  {
    "objectID": "Pages/Lectures/Lecture04/Lec04.html#an-exercise",
    "href": "Pages/Lectures/Lecture04/Lec04.html#an-exercise",
    "title": "PSTAT 5A: Lecture 04",
    "section": "An Exercise",
    "text": "An Exercise\n\n\n\n\n\n\nExercise 1\n\n\n\n\nCalifornia state license plates consist of 7 characters: a digit, followed by 3 letters, followed by 3 digits.\n\nSuppose we do not allow repeated letters or digits in a license plate: i.e. A123BCD456 is a valid plate whereas A122BCC345 is not. How many license plates can be created using this scheme?\nRealistically, license plates are allowed to contain repeated letters or digits. Re-answer the question of how many license plates can be created using this scheme.\nUsing the scheme outlined in part (b), what is the probability of picking a random license plate and having it be B131GHA?"
  },
  {
    "objectID": "Pages/Lectures/Lecture04/Lec04.html#lecture-summary-1",
    "href": "Pages/Lectures/Lecture04/Lec04.html#lecture-summary-1",
    "title": "PSTAT 5A: Lecture 04",
    "section": "Lecture Summary",
    "text": "Lecture Summary\n\nWe started off by talking about Venn Diagrams.\nBut, the main topic of today’s lecture was counting, which refers to the tools we use to systematically count the elements in a set without having to list out all of the elements contained in it.\nWe talked briefly about what it means for order to matter (or, consequently, not matter).\n\nThis lead us to the notations \\(n!\\), \\((n)_k\\), and \\(\\binom{n}{k}\\).\n\nNext time, we’ll see how we can use new information to update our beliefs on certain events by way of what are known as conditional probabilities.\n\nWe’ll also be able to work through a few more interesting examples."
  },
  {
    "objectID": "Pages/Lectures/MT1Rev/mt1_rev_slides.html#structure-of-data",
    "href": "Pages/Lectures/MT1Rev/mt1_rev_slides.html#structure-of-data",
    "title": "PSTAT 5A: Midterm 1 Review",
    "section": "Structure of Data",
    "text": "Structure of Data\n\nWe started by talking about the structure of data.\nWe were exposed to the notion of a data matrix, which is comprised of a series of observational units (i.e. rows) on a series of variables (i.e. columns)\nFor instance, the palmerpenguins data matrix is:\n\n\n\n\n   species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n 1 Adelie  Torgersen           39.1          18.7               181        3750\n 2 Adelie  Torgersen           39.5          17.4               186        3800\n 3 Adelie  Torgersen           40.3          18                 195        3250\n 4 Adelie  Torgersen           NA            NA                  NA          NA\n 5 Adelie  Torgersen           36.7          19.3               193        3450\n 6 Adelie  Torgersen           39.3          20.6               190        3650\n 7 Adelie  Torgersen           38.9          17.8               181        3625\n 8 Adelie  Torgersen           39.2          19.6               195        4675\n 9 Adelie  Torgersen           34.1          18.1               193        3475\n10 Adelie  Torgersen           42            20.2               190        4250\n# ℹ 334 more rows\n# ℹ 2 more variables: sex <fct>, year <int>"
  },
  {
    "objectID": "Pages/Lectures/MT1Rev/mt1_rev_slides.html#structure-of-data-1",
    "href": "Pages/Lectures/MT1Rev/mt1_rev_slides.html#structure-of-data-1",
    "title": "PSTAT 5A: Midterm 1 Review",
    "section": "Structure of Data",
    "text": "Structure of Data\n\n\nOf course, the reader is not expected to a priori know what the variables in a dataset represent; as such, most datasets come equipped with a data dictionary that lists out the variables included in the dataset along with a brief description of each.\n\n\n\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\nspecies\nThe species of penguin (either Adelie, Chinstrap, or Gentoo)\n\n\nisland\nThe island on which the penguin was found (either Biscoe, Dream, or Torgersen)\n\n\nbill_length_mm\nThe length (millimeters) of the penguin’s bill\n\n\nbill_depth_mm\nThe depth (in millimeters) of the penguin’s bill\n\n\nflipper_length_mm\nThe length (in millimeters) of the penguin’s flipper\n\n\nbody_mass_g\nThe mass (in grams) of the penguin\n\n\nsex\nThe sex of the penguin (either Male or Female)\n\n\nyear\nThe year in which the penguin was observed"
  },
  {
    "objectID": "Pages/Lectures/MT1Rev/mt1_rev_slides.html#classification-of-variables",
    "href": "Pages/Lectures/MT1Rev/mt1_rev_slides.html#classification-of-variables",
    "title": "PSTAT 5A: Midterm 1 Review",
    "section": "Classification of Variables",
    "text": "Classification of Variables\n\nWe also saw that variables fall into two main types: numerical and categorical.\n\nRemember that it is not enough to simply check whether our data is comprised of numbers, as categorical data can be encoded using numbers (e.g. months in a year).\nRather, we should check whether it makes interpretable sense to add two elements in our variable (e.g. 1 + 2 is 3, whereas Jan + Feb is not March)."
  },
  {
    "objectID": "Pages/Lectures/MT1Rev/mt1_rev_slides.html#classification-of-variables-1",
    "href": "Pages/Lectures/MT1Rev/mt1_rev_slides.html#classification-of-variables-1",
    "title": "PSTAT 5A: Midterm 1 Review",
    "section": "Classification of Variables",
    "text": "Classification of Variables\n\nWithin numerical data, we have a further subdivision into discrete and continuous variables.\n\nThe set of possible values of a discrete variable has jumps, whereas the set possible values of a continuous variable has no jumps.\n\nWithin categorical data, we have a further subdivision into ordinal and nominal variables.\n\nOrdinal variables have a natural ordering (e.g. letter grades, months of the year, etc.) whereas nominal variables do not (e.g. favorite color)"
  },
  {
    "objectID": "Pages/Lectures/MT1Rev/mt1_rev_slides.html#full-classification-scheme",
    "href": "Pages/Lectures/MT1Rev/mt1_rev_slides.html#full-classification-scheme",
    "title": "PSTAT 5A: Midterm 1 Review",
    "section": "Full Classification Scheme",
    "text": "Full Classification Scheme\n\n\n\n\n\n\n\ndata_classification\n\n \n\ncluster_main\n\n  \n\ncluster_0\n\n  \n\ncluster_1\n\n  \n\ncluster_2\n\n  \n\ncluster_3\n\n   \n\nData\n\n Variable   \n\nnumerical\n\n Numerical   \n\nData->numerical\n\n    \n\ncategorical\n\n Categorical   \n\nData->categorical\n\n    \n\ncontinuous\n\n Continuous   \n\nnumerical->continuous\n\n    \n\ndiscrete\n\n Discrete   \n\nnumerical->discrete\n\n    \n\nnominal\n\n Nominal   \n\ncategorical->nominal\n\n    \n\nordinal\n\n Ordinal   \n\ncategorical->ordinal"
  },
  {
    "objectID": "Pages/Lectures/MT1Rev/mt1_rev_slides.html#visualization",
    "href": "Pages/Lectures/MT1Rev/mt1_rev_slides.html#visualization",
    "title": "PSTAT 5A: Midterm 1 Review",
    "section": "Visualization",
    "text": "Visualization\n\nOnce we have classified a variable as being either numerical or categorical, we can ask ourselves: how can we best visualize this variable?\nFor categorical data, we use a bargraph and for numerical data we use either a histogram or a boxplot."
  },
  {
    "objectID": "Pages/Lectures/MT1Rev/mt1_rev_slides.html#bargraph",
    "href": "Pages/Lectures/MT1Rev/mt1_rev_slides.html#bargraph",
    "title": "PSTAT 5A: Midterm 1 Review",
    "section": "Bargraph",
    "text": "Bargraph"
  },
  {
    "objectID": "Pages/Lectures/MT1Rev/mt1_rev_slides.html#histogram",
    "href": "Pages/Lectures/MT1Rev/mt1_rev_slides.html#histogram",
    "title": "PSTAT 5A: Midterm 1 Review",
    "section": "Histogram",
    "text": "Histogram\n\n\nRemember the importance of binwidth: demo"
  },
  {
    "objectID": "Pages/Lectures/MT1Rev/mt1_rev_slides.html#boxplot",
    "href": "Pages/Lectures/MT1Rev/mt1_rev_slides.html#boxplot",
    "title": "PSTAT 5A: Midterm 1 Review",
    "section": "Boxplot",
    "text": "Boxplot\n\n\nRemember that the whiskers are never allowed to extend beyond 1.5 times the IQR (and recall that the IQR is just the width of the box)."
  },
  {
    "objectID": "Pages/Lectures/MT1Rev/mt1_rev_slides.html#numerical-summaries",
    "href": "Pages/Lectures/MT1Rev/mt1_rev_slides.html#numerical-summaries",
    "title": "PSTAT 5A: Midterm 1 Review",
    "section": "Numerical Summaries",
    "text": "Numerical Summaries\n\nWe can also produce numerical summaries of numerical variables.\nMeasures of Central Tendency are different quantities that summarize the “center” of a variable\n\nThere are two main measures of central tendency we discussed: the mean and the median.\n\nThe mean (or arithmetic mean) is a sort of “balancing point”:\n\n\n\n\n\n\n\n\n\n\\[ \\overline{x} = \\frac{1}{n} \\sum_{i=1}^{n} x_i \\]"
  },
  {
    "objectID": "Pages/Lectures/MT1Rev/mt1_rev_slides.html#spread",
    "href": "Pages/Lectures/MT1Rev/mt1_rev_slides.html#spread",
    "title": "PSTAT 5A: Midterm 1 Review",
    "section": "Spread",
    "text": "Spread\n\nAnother way we could summarize a numerical dataset (i.e. a dataset containing only one variable, one that is numerical) is to describe how “spread out” the values are.\nThe variance is a sort of “average distance of points to the mean”:\n\n\n\n\n\n\n\n\n\n\\[ s_x^2 = \\frac{1}{n - 1} \\sum_{i=1}^{n} (x_i - \\overline{x})^2 \\]\n\n\nThe standard deviation is just the square root of the variance"
  },
  {
    "objectID": "Pages/Lectures/MT1Rev/mt1_rev_slides.html#spread-1",
    "href": "Pages/Lectures/MT1Rev/mt1_rev_slides.html#spread-1",
    "title": "PSTAT 5A: Midterm 1 Review",
    "section": "Spread",
    "text": "Spread\n\nThe interquartile range (IQR) is another measure of spread: \\[ \\mathrm{IQR} = Q_3 - Q_1 \\] where \\(Q_1\\) and \\(Q_3\\) denote the first and third quartiles, respectively.\n\nRecall that the \\(p\\)th percentile of a dataset \\(X\\) is the value \\(\\pi_{x, \\ 0.5}\\) such that p% of observations lie to the left of (i.e. are less than) \\(\\pi_{x, \\ 0.5}\\).\n\\(Q_1\\) is the 25th percentile and \\(Q_3\\) is the 75th percentile\n\nThe third measure of spread we discussed is the range: \\[ \\mathrm{range}(X) = \\max\\{x_1, \\cdots, x_n\\} - \\min\\{x_1, \\ \\cdots, \\ x_n\\} \\]"
  },
  {
    "objectID": "Pages/Lectures/MT1Rev/mt1_rev_slides.html#number-summary",
    "href": "Pages/Lectures/MT1Rev/mt1_rev_slides.html#number-summary",
    "title": "PSTAT 5A: Midterm 1 Review",
    "section": "5-Number Summary",
    "text": "5-Number Summary\n\nRecall the five number summary, which contains:\n\nThe minimum\nThe first quartile\nThe median\nThe third quartile\nThe maximum\n\nAlso recall how all of these quantities appear on a boxplot!"
  },
  {
    "objectID": "Pages/Lectures/MT1Rev/mt1_rev_slides.html#comparisons-of-variables",
    "href": "Pages/Lectures/MT1Rev/mt1_rev_slides.html#comparisons-of-variables",
    "title": "PSTAT 5A: Midterm 1 Review",
    "section": "Comparisons of Variables",
    "text": "Comparisons of Variables\n\nIf we want to compare two variables, there are three cases to consider:\n\nNumerical vs. Numerical\nNumerical vs. Categorical\nCategorical vs. Categorical\n\nWhen comparing two numerical variables, we use a scatterplot\nWhen comparing a numerical variable to a categorical variable, we use a side-by-side boxplot\nWhen comparing two categorical variables, we construct a contingency table"
  },
  {
    "objectID": "Pages/Lectures/MT1Rev/mt1_rev_slides.html#basics-of-probability",
    "href": "Pages/Lectures/MT1Rev/mt1_rev_slides.html#basics-of-probability",
    "title": "PSTAT 5A: Midterm 1 Review",
    "section": "Basics of Probability",
    "text": "Basics of Probability\n\nProbability is, in many ways, the language of uncertainty.\nAn experiment is any procedure we can repeat an infinite number of times, where each time we repeat the procedure the same fixed set of “things” can occur\n\nThese “things” are called outcomes\nThe outcome space, denoted \\(\\Omega\\), is the set containing all outcomes associated with a particular experiment.\nEvents are just subset of the outcome space.\n\nWe can express outcome spaces using tables or trees."
  },
  {
    "objectID": "Pages/Lectures/MT1Rev/mt1_rev_slides.html#probability-1",
    "href": "Pages/Lectures/MT1Rev/mt1_rev_slides.html#probability-1",
    "title": "PSTAT 5A: Midterm 1 Review",
    "section": "Probability",
    "text": "Probability\n\nProbability is a function that acts on events\n\nNotationally: \\(\\mathbb{P}(E)\\)\n\nThere are two main approaches to computing probabilities:\n\nThe Classical Aproach: if outcomes are equally likely, then for any event \\(E\\) \\[ \\mathbb{P}(E) = \\frac{\\#(E)}{\\#(\\Omega)} \\]\nThe long-run [relative] frequency approach: repeat the experiment an infinite number of times and define \\(\\mathbb{P}(E)\\) to be the proportion of times \\(E\\) occurs"
  },
  {
    "objectID": "Pages/Lectures/MT1Rev/mt1_rev_slides.html#long-run-frequencies-example",
    "href": "Pages/Lectures/MT1Rev/mt1_rev_slides.html#long-run-frequencies-example",
    "title": "PSTAT 5A: Midterm 1 Review",
    "section": "Long-Run Frequencies Example",
    "text": "Long-Run Frequencies Example\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nToss\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\n\nOutcome\nH\nT\nT\nH\nT\nH\nH\nH\nT\nT\n\n\nRaw freq. of H\n1\n1\n1\n2\n2\n3\n4\n5\n5\n5\n\n\nRel. freq of H\n1/1\n1/2\n1/3\n2/4\n2/5\n3/6\n4/7\n5/8\n5/9\n5/10"
  },
  {
    "objectID": "Pages/Lectures/MT1Rev/mt1_rev_slides.html#set-operations",
    "href": "Pages/Lectures/MT1Rev/mt1_rev_slides.html#set-operations",
    "title": "PSTAT 5A: Midterm 1 Review",
    "section": "Set Operations",
    "text": "Set Operations\n\nGiven two events \\(E\\) and \\(F\\), there are several operations we can perform:\n\nComplement: \\(E^\\complement\\); denotes “not \\(E\\)”\nUnion: \\(E \\cup F\\); denotes \\(E\\) or \\(F\\) (or both)\nIntersection: \\(E \\cap F\\); denotes \\(E\\) and \\(F\\)"
  },
  {
    "objectID": "Pages/Lectures/MT1Rev/mt1_rev_slides.html#venn-diagrams",
    "href": "Pages/Lectures/MT1Rev/mt1_rev_slides.html#venn-diagrams",
    "title": "PSTAT 5A: Midterm 1 Review",
    "section": "Venn Diagrams",
    "text": "Venn Diagrams\n\n\n\n\n\n \\(A^\\complement\\)  (complement)\n\n\n\n\n\n\n\n\n \\(A \\cap B\\)  (intersection)\n\n\n\n\n\n\n\n\n \\(A \\cup B\\)  (union)"
  },
  {
    "objectID": "Pages/Lectures/MT1Rev/mt1_rev_slides.html#axioms-of-probability",
    "href": "Pages/Lectures/MT1Rev/mt1_rev_slides.html#axioms-of-probability",
    "title": "PSTAT 5A: Midterm 1 Review",
    "section": "Axioms of Probability",
    "text": "Axioms of Probability\n\n\\(\\mathbb{P}(E) \\geq 0\\) for any event \\(E\\)\n\\(\\mathbb{P}(\\Omega) = 1\\)\nFor disjoint events \\(E\\) and \\(F\\) (i.e. for \\(E \\cap F = \\varnothing\\)), \\(\\mathbb{P}(E \\cup F) = \\mathbb{P}(E) + \\mathbb{P}(F)\\)"
  },
  {
    "objectID": "Pages/Lectures/MT1Rev/mt1_rev_slides.html#probability-rules",
    "href": "Pages/Lectures/MT1Rev/mt1_rev_slides.html#probability-rules",
    "title": "PSTAT 5A: Midterm 1 Review",
    "section": "Probability Rules",
    "text": "Probability Rules\n\nProbability of the Empty Set: \\(\\mathbb{P}(\\varnothing) = 0\\)\nComplement Rule: \\(\\mathbb{P}(E^\\complement) = 1 - \\mathbb{P}(E)\\)\nAddition Rule: \\(\\mathbb{P}(E \\cup F) = \\mathbb{P}(E) + \\mathbb{P}(F) - \\mathbb{P}(E \\cap F)\\)"
  },
  {
    "objectID": "Pages/Lectures/MT1Rev/mt1_rev_slides.html#conditional-probabilities",
    "href": "Pages/Lectures/MT1Rev/mt1_rev_slides.html#conditional-probabilities",
    "title": "PSTAT 5A: Midterm 1 Review",
    "section": "Conditional Probabilities",
    "text": "Conditional Probabilities\n\n\\(\\mathbb{P}(E \\mid F)\\) denotes an “updating” of our beliefs on \\(E\\) in the presence of \\(F\\))\n\nDefinition: \\(\\displaystyle \\mathbb{P}(E \\mid F) = \\frac{\\mathbb{P}(E \\cap F)}{\\mathbb{P}(F)}\\), provided \\(\\mathbb{P}(F) \\neq 0\\)\n\nMultiplication Rule: \\(\\mathbb{P}(E \\cap F) = \\mathbb{P}(E \\mid F) \\cdot \\mathbb{P}(F) = \\mathbb{P}(F \\mid E) \\cdot \\mathbb{P}(E)\\)\nBayes’ Rule: \\(\\displaystyle \\mathbb{P}(E \\mid F) = \\frac{\\mathbb{P}(F \\mid E) \\cdot \\mathbb{P}(E)}{\\mathbb{P}(F)}\\)\n\n\n\n\nIndependence asserts that \\(\\mathbb{P}(E \\mid F) = \\mathbb{P}(E)\\), which in turn implies \\(\\mathbb{P}(F \\mid E) = \\mathbb{P}(F)\\) and \\(\\mathbb{P}(E \\cap F) = \\mathbb{P}(E) \\cdot \\mathbb{P}(F)\\)\n\nNote that \\(\\mathbb{P}(E \\cap F) = \\mathbb{P}(E) \\cdot \\mathbb{P}(F)\\) only when \\(E\\) and \\(F\\) are independent! Otherwise, you have to compute \\(\\mathbb{P}(E \\cap F)\\) using the multiplication rule.\nThe interpretation of independence is that the two events “do not affect each other”"
  },
  {
    "objectID": "Pages/Lectures/Lecture03/Lec03.html#uncertainty",
    "href": "Pages/Lectures/Lecture03/Lec03.html#uncertainty",
    "title": "PSTAT 5A: Lecture 03",
    "section": "Uncertainty",
    "text": "Uncertainty\n\n\nUncertainty surrounds us!\n\n\n\nStatistics is, in many ways, the study of uncertainty.\nProbability is the language of uncertainty; it gives us a way to quantify exactly how this uncertainty factors into our decision making process."
  },
  {
    "objectID": "Pages/Lectures/Lecture03/Lec03.html#experiment",
    "href": "Pages/Lectures/Lecture03/Lec03.html#experiment",
    "title": "PSTAT 5A: Lecture 03",
    "section": "Experiment",
    "text": "Experiment\n\n\nWe begin with the notion of an experiment. In the context of Probability, we have the following definition:\n\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nAn experiment is any procedure that can be repeated an infinite number of times, and each time the procedure is repeated there are a fixed set of things that could occur.\n\n\n\n\n\n\nAn example of an experiment is tossing a coin:\n\nI could go into Storke field and toss a coin an infinite number of times, and each time I toss the coin it will land on either heads or tails."
  },
  {
    "objectID": "Pages/Lectures/Lecture03/Lec03.html#outcome-space",
    "href": "Pages/Lectures/Lecture03/Lec03.html#outcome-space",
    "title": "PSTAT 5A: Lecture 03",
    "section": "Outcome Space",
    "text": "Outcome Space\n\n\nThe things that could occur on each repetition of an experiment are called outcomes.\n\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nThe outcome space of an experiment is the set \\(\\Omega\\) consisting of all outcomes of the experiment.\n\n\n\n\n\n\nFor instance, in the coin tossing example the outcome space is  \\(\\Omega =\\{\\)heads,  tails\\(\\}\\).\nAs an aside: some textbooks/professors refer to the outcome space as the sample space, and use the letter \\(S\\) to denote it.\n\nSo, if you are doing self-study and encounter the term “sample space”, know that it is the same thing as what we are calling the “outcome space”!"
  },
  {
    "objectID": "Pages/Lectures/Lecture03/Lec03.html#worked-out-example",
    "href": "Pages/Lectures/Lecture03/Lec03.html#worked-out-example",
    "title": "PSTAT 5A: Lecture 03",
    "section": "Worked-Out Example",
    "text": "Worked-Out Example\n\n\nLet’s do an example together.\n\n\n\n\n\n\n\n\nWorked-Out Exercise 1\n\n\n\nConsider the experiment of rolling two four-sided dice and recording the faces that appear. What is an appropriate outcome space for this experiment?\n\n\n\n\n\nOn each die roll, we will observe either a \\(1\\), \\(2\\), \\(3\\), or \\(4\\).\nBut, we cannot simply say that our outcome space is \\(\\{1, 2, 3, 4\\}\\) as this does not take into account the fact that we rolled two dice!"
  },
  {
    "objectID": "Pages/Lectures/Lecture03/Lec03.html#now-its-your-turn",
    "href": "Pages/Lectures/Lecture03/Lec03.html#now-its-your-turn",
    "title": "PSTAT 5A: Lecture 03",
    "section": "Now it’s Your Turn!",
    "text": "Now it’s Your Turn!\n\n\n\n\n\n\nExercise 1\n\n\n\nConsider the experiment of tossing a coin, rolling a 4-sided die, and then tossing another coin. What is the outcome space of this experiment?"
  },
  {
    "objectID": "Pages/Lectures/Lecture03/Lec03.html#other-ways-of-describing-outcome-spaces",
    "href": "Pages/Lectures/Lecture03/Lec03.html#other-ways-of-describing-outcome-spaces",
    "title": "PSTAT 5A: Lecture 03",
    "section": "Other Ways of Describing Outcome Spaces",
    "text": "Other Ways of Describing Outcome Spaces\n\nThere are a few other ways we can use to describe the outcome space of an experiment.\nLet’s return to the tossing four dice example from a few slides ago. Another way we could have kept track of the outcomes was by using a table, recording the outcome of the first die roll in the rows and the outcomes of the second in the columns:\n\n\n\n\n\n\n\n\n1\n\n\n2\n\n\n3\n\n\n4\n\n\n\n\n1\n\n\n(1, 1)\n\n\n(1, 2)\n\n\n(1, 3)\n\n\n(1, 4)\n\n\n\n\n2\n\n\n(2, 1)\n\n\n(2, 2)\n\n\n(2, 3)\n\n\n(2, 4)\n\n\n\n\n3\n\n\n(3, 1)\n\n\n(3, 2)\n\n\n(3, 3)\n\n\n(3, 4)\n\n\n\n\n4\n\n\n(4, 1)\n\n\n(4, 2)\n\n\n(4, 3)\n\n\n(4, 4)"
  },
  {
    "objectID": "Pages/Lectures/Lecture03/Lec03.html#other-ways-of-describing-outcome-spaces-1",
    "href": "Pages/Lectures/Lecture03/Lec03.html#other-ways-of-describing-outcome-spaces-1",
    "title": "PSTAT 5A: Lecture 03",
    "section": "Other Ways of Describing Outcome Spaces",
    "text": "Other Ways of Describing Outcome Spaces\n\nSo, tables are a good way of keeping track of outcomes.\nBut, they really only work when we have two of something (e.g. two dice, two coins, etc.). What happens if we, for example, toss three coins?\nThis is where tree diagrams can become useful.\n\n\n\n\n\n\n\n\n\ntree_diagram\n\n  \n\nbase\n\no   \n\nH1\n\nH   \n\nbase->H1\n\n    \n\nT1\n\nT   \n\nbase->T1\n\n    \n\nH21\n\nH   \n\nH1->H21\n\n    \n\nT21\n\nT   \n\nH1->T21\n\n    \n\nH22\n\nH   \n\nT1->H22\n\n    \n\nT22\n\nT   \n\nT1->T22\n\n    \n\nH311\n\nH   \n\nH21->H311\n\n    \n\nT311\n\nT   \n\nH21->T311\n\n    \n\nH321\n\nH   \n\nT21->H321\n\n    \n\nT321\n\nT   \n\nT21->T321\n\n    \n\nH312\n\nH   \n\nH22->H312\n\n    \n\nT312\n\nT   \n\nH22->T312\n\n    \n\nH322\n\nH   \n\nT22->H322\n\n    \n\nT322\n\nT   \n\nT22->T322"
  },
  {
    "objectID": "Pages/Lectures/Lecture03/Lec03.html#events",
    "href": "Pages/Lectures/Lecture03/Lec03.html#events",
    "title": "PSTAT 5A: Lecture 03",
    "section": "Events",
    "text": "Events\n\nSometimes, it will be useful to consider quantities that are a bit more complex than single outcomes.\nFor example, consider the experiment of rolling two 4-sided dice. I could ask myself: in how many outcomes does the second die roll result in a higher number than the first?\nThis leads us to the notion of an event.\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nAn event is a subset of the outcome space. In other words, an event is just a set consisting of one or more outcomes."
  },
  {
    "objectID": "Pages/Lectures/Lecture03/Lec03.html#unions-and-intersections",
    "href": "Pages/Lectures/Lecture03/Lec03.html#unions-and-intersections",
    "title": "PSTAT 5A: Lecture 03",
    "section": "Unions and Intersections",
    "text": "Unions and Intersections\n\nRemember how we talked about the union of two sets last week?\nWell, since events are just sets, we can talk about the union of two sets.\n\nIn words, the union corresponds to an “or” statement.\nFor example, let \\(E\\) denote the event “it is raining” and \\(F\\) denote the event “the ground is wet”, then the event \\(E \\cup F\\) would be the event “it is raining or the ground is wet”.\n\nThe intersection of two events (denoted with the \\(\\cap\\) symbol), corresponds to an “and” statement\n\nFor example, if \\(E\\) and \\(F\\) are defined as in the bullet point above, then \\(E \\cap F\\) denotes the event “it is raining and the ground is wet”."
  },
  {
    "objectID": "Pages/Lectures/Lecture03/Lec03.html#complements",
    "href": "Pages/Lectures/Lecture03/Lec03.html#complements",
    "title": "PSTAT 5A: Lecture 03",
    "section": "Complements",
    "text": "Complements\n\nThe complement of an event \\(E\\), denoted \\(E^{\\complement}\\), represents the event “not \\(E\\)”\n\nFor instance, if \\(E\\) again denotes the event “it is raining”, then \\(E^{\\complement}\\) denotes the event “it is not raining”."
  },
  {
    "objectID": "Pages/Lectures/Lecture03/Lec03.html#leadup",
    "href": "Pages/Lectures/Lecture03/Lec03.html#leadup",
    "title": "PSTAT 5A: Lecture 03",
    "section": "Leadup",
    "text": "Leadup\n\nRecall that \\(E \\cap F\\) denotes the event “both \\(E\\) and \\(F\\) occurred.”\nAlso recall that \\(A^{\\complement}\\) denotes “not \\(A\\)”; i.e. “\\(A\\) did not occur”\nAs such, \\((E \\cap F)^{\\complement}\\) denotes the event “it is not the case that both \\(E\\) or \\(F\\) occurred.”\n\nThis means that either \\(E\\) did not occur, or \\(F\\) did not occur (or both).\nMathematically, this is equivalent to \\(E^\\complement \\cup F^\\complement\\).\n\nAs such, it seems we have arrived at the following equality: \\[ (E \\cap F)^{\\complement} = E^\\complement \\cup F^\\complement \\]"
  },
  {
    "objectID": "Pages/Lectures/Lecture03/Lec03.html#demorgans-laws",
    "href": "Pages/Lectures/Lecture03/Lec03.html#demorgans-laws",
    "title": "PSTAT 5A: Lecture 03",
    "section": "DeMorgan’s Laws",
    "text": "DeMorgan’s Laws\n\n\nThis is one of what are known as DeMorgan’s Laws.\n\n\n\n\n\n\n\n\n\n\nDeMorgan’s Laws\n\n\n\nGiven two events \\(E\\) and \\(F\\), we have the following:\n\n\\((E \\cap F)^{\\complement} = E^\\complement \\cup F^\\complement\\)\n\\((E \\cup F)^{\\complement} = E^\\complement \\cap F^\\complement\\)\n\n\n\n\n\n\n\n\nWe will not prove these in this class. However, please familiarize yourself with them as they will be incredibly useful!"
  },
  {
    "objectID": "Pages/Lectures/Lecture03/Lec03.html#leadup-1",
    "href": "Pages/Lectures/Lecture03/Lec03.html#leadup-1",
    "title": "PSTAT 5A: Lecture 03",
    "section": "Leadup",
    "text": "Leadup\n\nNow, there is something interesting about the events defined in the previous example.\nThe outcome space of the underlying experiment is \\[ \\Omega = \\{ (H, H), \\ (H, T), \\ (T, H), \\ (T, T)\\} \\] and\n\n\\(A = \\{(H, H), \\ (T, T)\\}\\)\n\\(B = \\{(H, T), \\ (T, H)\\}\\)\n\\(C = \\{(H, H)\\}\\)"
  },
  {
    "objectID": "Pages/Lectures/Lecture03/Lec03.html#probability",
    "href": "Pages/Lectures/Lecture03/Lec03.html#probability",
    "title": "PSTAT 5A: Lecture 03",
    "section": "Probability",
    "text": "Probability\n\nNow, you may note that we have yet to mention the term “probability.”\nTo get a better sense of “probability”, let’s examine how we use the word in everyday speech:\n\n“the chance of rain is 50%”\n“odds of winning big at a Casino is 1%”\n“probability of scoring a 100% on the PSTAT 5A Midterm 1 is 95%”\n\nNotice that “rain”, “winning big at a Casino”, and “scoring 100% on the PSTAT 5A Midterm 1” are all events.\nAs such, “probability” seems to take in an event and spit out a number."
  },
  {
    "objectID": "Pages/Lectures/Lecture03/Lec03.html#probability-1",
    "href": "Pages/Lectures/Lecture03/Lec03.html#probability-1",
    "title": "PSTAT 5A: Lecture 03",
    "section": "Probability",
    "text": "Probability\n\n\nIn other words, we can think of “probability” (or, more accurately, what we refer to as a probability measure) as a function that takes in an event and outputs a number.\n\n\n\nThe symbol we use for a probability measure is \\(\\mathbb{P}\\); i.e. we write \\(\\mathbb{P}(E)\\) to denote “the probability of event \\(E\\)”.\nNow, this doesn’t really tell us how to define \\(\\mathbb{P}(E)\\) for an arbitrary event \\(E\\).\nThere are (roughly) two schools of thought when it comes to defining the probability of an event: the long-run frequency approach, and the classical approach."
  },
  {
    "objectID": "Pages/Lectures/Lecture03/Lec03.html#long-run-frequency-approach",
    "href": "Pages/Lectures/Lecture03/Lec03.html#long-run-frequency-approach",
    "title": "PSTAT 5A: Lecture 03",
    "section": "Long-Run-Frequency Approach",
    "text": "Long-Run-Frequency Approach\n\nThe long-run frequency approach defines the probability of an event \\(E\\) to be the proportion of times \\(E\\) occurs, if the underlying experiment were to be repeated a large number of times.\nTo help us understand the notion of long-run frequencies, let’s go through an example together. Suppose we toss a coin and record whether the outcome lands heads or tails, and further suppose we observe the following tosses:\n\n\n\nH,  T,   T,   H,   T,   H,   H,   H,   T,   T\n\n\n\nTo compute the relative frequency of heads after each toss, we count the number of times we observed heads and divide by the total number of tosses observed."
  },
  {
    "objectID": "Pages/Lectures/Lecture03/Lec03.html#classical-approach",
    "href": "Pages/Lectures/Lecture03/Lec03.html#classical-approach",
    "title": "PSTAT 5A: Lecture 03",
    "section": "Classical Approach",
    "text": "Classical Approach\n\nThe second way to define probabilities is what is known as the classical approach.\nAs an important note: we can only apply the classical approach if we believe all outcomes in our experiment to be equally likely.\n\nExamples of situations in which it is safe to assume equally likely outcomes include: tossing a fair coin some number of times, rolling a fair \\(k\\)-sided die, selecting a card at random from a deck of cards, etc.\n\nIf we make the equally likely outcomes assumption, then the classical approach to probability tells us to define \\(\\mathbb{P}(E)\\) as \\[ \\mathbb{P}(E) = \\frac{\\text{number of ways $E$ can occur}}{\\text{total number of outcomes}} \\]\nSo, for example, if we toss a fair coin once, then the classical approach to probability (which can be used since the coin is fair) states that \\[ \\mathbb{P}(\\texttt{heads}) = \\frac{1}{2} \\]"
  },
  {
    "objectID": "Pages/Lectures/Lecture03/Lec03.html#comparisons",
    "href": "Pages/Lectures/Lecture03/Lec03.html#comparisons",
    "title": "PSTAT 5A: Lecture 03",
    "section": "Comparisons",
    "text": "Comparisons\n\nLet’s quickly compare these two approaches to defining the probability of an event.\nThe long-run frequencies definition has the benefit of not requiring the assumption of equally likely outcomes.\n\nHowever, it relies on the (perhaps odd) consideration of considering what happens when we repeat an experiment a large number of times.\n\nThe classical approach does not rely on such considerations, making the definitions it produces perhaps a bit more easily interpretable.\n\nHowever, it crucially requires the assumption of equally likely outcomes."
  },
  {
    "objectID": "Pages/Lectures/Lecture03/Lec03.html#comparisons-1",
    "href": "Pages/Lectures/Lecture03/Lec03.html#comparisons-1",
    "title": "PSTAT 5A: Lecture 03",
    "section": "Comparisons",
    "text": "Comparisons\n\n\nFor the purposes of this class, we won’t be too concerned with defining the probability of an event: in many cases, we will just give you the probability.\n\n\n\nIn situations where we do not provide a probability a priori, there will likely be some key word or phrase that lets you know we are looking for the classical definition.\n\nAgain, important words/phrases to look out for are: fair, at random, etc."
  },
  {
    "objectID": "Pages/Lectures/Lecture03/Lec03.html#axioms-of-probability",
    "href": "Pages/Lectures/Lecture03/Lec03.html#axioms-of-probability",
    "title": "PSTAT 5A: Lecture 03",
    "section": "Axioms of Probability",
    "text": "Axioms of Probability\n\nIt turns out that there are three axioms that a probability measure must satisfy, collectively called the axioms of probability:\n\n\\(\\mathbb{P}(E) \\geq 0\\) for any event \\(E\\)\n\\(\\mathbb{P}(\\Omega) = 1\\)\nFor disjoint events \\(E\\) and \\(F\\), \\(\\mathbb{P}(E \\cup F) = \\mathbb{P}(E) + \\mathbb{P}(F)\\).\n\nIf you are not familiar with the notion of axioms: an axiom is a fundamental “truth” of math, that does not need to be proven.\n\nAxioms are like the building blocks, or base assumptions on which a system of math is predicated."
  },
  {
    "objectID": "Pages/Lectures/Lecture03/Lec03.html#summary",
    "href": "Pages/Lectures/Lecture03/Lec03.html#summary",
    "title": "PSTAT 5A: Lecture 03",
    "section": "Summary",
    "text": "Summary\n\nLet’s quickly summarize the concepts/terms we’ve covered:\n\nExperiment: any procedure that can be repeated an infinite number of times, where each time the procedure is repeated there are a fixed set of outcomes that can occur.\nOutcome Space: the set of all outcomes associated with a particular experiment.\nEvent: a subset of the outcome space\nProbability (measure): a function that takes an event and outputs a number\n\nThese are the basic building blocks of probability.\nWe will now combine them!"
  },
  {
    "objectID": "Pages/Lectures/Lecture03/Lec03.html#notational-reminder",
    "href": "Pages/Lectures/Lecture03/Lec03.html#notational-reminder",
    "title": "PSTAT 5A: Lecture 03",
    "section": "Notational Reminder",
    "text": "Notational Reminder\n\nBefore we go any further, I’d like to stress something:\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nIn this class, using proper notation is very important.\n\n\n\n\n\n\n\nFor example, if we have an event \\(E\\) whose probability of occurring is, say, \\(0.5\\), we must write \\(\\mathbb{P}(E) = 0.5\\); it is NOT correct to say \\(E = 0.5\\), or \\(\\mathbb{P} = 0.5\\)."
  },
  {
    "objectID": "Pages/Lectures/Lecture03/Lec03.html#the-complement-rule",
    "href": "Pages/Lectures/Lecture03/Lec03.html#the-complement-rule",
    "title": "PSTAT 5A: Lecture 03",
    "section": "The Complement Rule",
    "text": "The Complement Rule\n\nThe first result we will explore is the so-called complement rule.\n\n\n\n\n\n\n\n\n\nThe Complement Rule\n\n\n\nGiven an event \\(E\\), we have \\(\\mathbb{P}(E^\\complement) = 1 - \\mathbb{P}(E)\\)\n\n\n\n\n\n\n\nAs an example: if we roll a fair six-sided die and if \\(E =\\) “rolling a \\(1\\)”, then \\(E^\\complement =\\) “not rolling a \\(1\\)” and \\[\\mathbb{P}(E^\\complement) = 1 - \\mathbb{P}(E) = 1 - 1/6 = \\boxed{5/6}\\]"
  },
  {
    "objectID": "Pages/Lectures/Lecture03/Lec03.html#the-probability-of-the-empty-set",
    "href": "Pages/Lectures/Lecture03/Lec03.html#the-probability-of-the-empty-set",
    "title": "PSTAT 5A: Lecture 03",
    "section": "The Probability of the Empty Set",
    "text": "The Probability of the Empty Set\n\nRecall that the empty set (\\(\\varnothing\\)) is the set containing no elements.\n\n\n\n\n\n\n\n\n\nThe Probability of the Empty Set\n\n\n\n\\(\\mathbb{P}(\\varnothing) = 0\\).\n\n\n\n\n\n\n\nThe “proof” of this is relatively simple: note that \\(\\Omega^\\complement = \\varnothing\\) (the opposite of “everything” is “nothing”); we also know that \\(\\mathbb{P}(\\Omega) = 1\\) so \\[ \\mathbb{P}(\\Omega^\\complement) = \\mathbb{P}(\\varnothing) = 1 - 1 = 0 \\]"
  },
  {
    "objectID": "Pages/Lectures/Lecture03/Lec03.html#the-addition-rule",
    "href": "Pages/Lectures/Lecture03/Lec03.html#the-addition-rule",
    "title": "PSTAT 5A: Lecture 03",
    "section": "The Addition Rule",
    "text": "The Addition Rule\n\nThe next result we will explore is the so-called addition rule.\n\n\n\n\n\n\n\n\n\nThe Addition Rule\n\n\n\nGiven events \\(E\\) and \\(F\\), we have \\(\\mathbb{P}(E \\cup F) = \\mathbb{P}(E) + \\mathbb{P}(F) - \\mathbb{P}(E \\cap F)\\)\n\n\n\n\n\n\n\nNote that if \\(E\\) and \\(F\\) are disjoint, then we recover the third axiom of probability!"
  },
  {
    "objectID": "Pages/Lectures/Lecture03/Lec03.html#worked-out-example-1",
    "href": "Pages/Lectures/Lecture03/Lec03.html#worked-out-example-1",
    "title": "PSTAT 5A: Lecture 03",
    "section": "Worked-Out Example",
    "text": "Worked-Out Example\n\n\n\n\n\n\nWorked-Out Example 2\n\n\n\n\nA recent survey at the Isla Vista Co-Op revealed that 50% of shoppers buy bread, 30% buy jam, and 20% buy both bread and jam.\n\nWhat is the probability that a randomly selected shopper will not purchase jam?\nWhat is the probability that a randomly selected shopper will purchase either bread or jam (or both)?"
  },
  {
    "objectID": "Pages/Lectures/Lecture03/Lec03.html#solution-to-part-a",
    "href": "Pages/Lectures/Lecture03/Lec03.html#solution-to-part-a",
    "title": "PSTAT 5A: Lecture 03",
    "section": "Solution to Part (a)",
    "text": "Solution to Part (a)\n\nLet \\(J\\) denote the event “a randomly selected shopper will purchase jam”.\n\nFrom the problem statement, we have that \\(\\mathbb{P}(J) = 0.3\\)\n\nThe event “a randomly selected shopper will not purchase jam” is given by \\(J^\\complement\\), meaning the quantity we seek is \\(\\mathbb{P}(J^\\complement)\\).\nBy the Complement Rule, we have \\[ \\mathbb{P}(J^\\complement) = 1 - \\mathbb{P}(J) = 1 - 0.3 = \\boxed{0.7 = 70\\%} \\]"
  },
  {
    "objectID": "Pages/Lectures/Lecture03/Lec03.html#solution-to-part-b",
    "href": "Pages/Lectures/Lecture03/Lec03.html#solution-to-part-b",
    "title": "PSTAT 5A: Lecture 03",
    "section": "Solution to Part (b)",
    "text": "Solution to Part (b)\n\nLet \\(J\\) be defined as before, and let \\(B\\) denote the event “a randomly selected shopper will purchase bread or jam”\n\nThe first quantity provided in the problem statement tells us that \\(\\mathbb{P}(B) = 0.5\\)\nThe final quantity provided in the problem statement tells us that \\(\\mathbb{P}(B \\cap J) = 0.2\\)\n\nThe event “a randomly selected shopper will purchase either bread or jam” is given by \\(B \\cup J\\), meaning we seek \\(\\mathbb{P}(B \\cup J)\\).\nBy the Addition Rule,\n\n\n\\[\\begin{align*}\n  \\mathbb{P}(B \\cup J)     & = \\mathbb{P}(B) + \\mathbb{P}(J) - \\mathbb{P}(B \\cap J)   \\\\\n  & = 0.5 + 0.3 - 0.2 = \\boxed{0.6 = 60\\%}\n\\end{align*}\\]"
  },
  {
    "objectID": "Pages/Lectures/Lecture03/Lec03.html#general-strategy",
    "href": "Pages/Lectures/Lecture03/Lec03.html#general-strategy",
    "title": "PSTAT 5A: Lecture 03",
    "section": "General Strategy",
    "text": "General Strategy\n\n\n\n\n\n\n\n\nGeneral Strategy for Probability Word Problems\n\n\n\n\nStart by defining events\nNext, translate the information provided to you (through the problem statement) to be in terms of the events you defined above\nThen, identify the quantity you are trying to obtain\nFinally, apply the various probability rules to solve for the desired quantity."
  },
  {
    "objectID": "Pages/Lectures/Lecture03/Lec03.html#time-to-put-everything-together",
    "href": "Pages/Lectures/Lecture03/Lec03.html#time-to-put-everything-together",
    "title": "PSTAT 5A: Lecture 03",
    "section": "Time to Put Everything Together!",
    "text": "Time to Put Everything Together!\n\n\n\n\n\n\nExercise 5\n\n\n\n\nTwo fair six-sided dice are rolled.\n\nWhat is the outcome space of this experiment?\nWhat is the probability that the first die lands on the number 2?\nWhat is the probability that the first die lands on the number 2, or the second die lands on an even number?"
  },
  {
    "objectID": "Pages/Lectures/Lecture03/Lec03.html#lecture-summary-1",
    "href": "Pages/Lectures/Lecture03/Lec03.html#lecture-summary-1",
    "title": "PSTAT 5A: Lecture 03",
    "section": "Lecture Summary",
    "text": "Lecture Summary\n\nToday, we began our introduction to the field of probability.\n\nProbability, loosely speaking, provides us with a way to quantify uncertainty.\n\nWe discussed the notions of experiments, outcomes, outcome spaces, events, and probabilities.\n\nRemember that there are certain tools/diagrams (namely, tables and tree diagrams) that can help us determine the outcome space of an experiment.\n\nWe then discussed three probability rules: the complement rule, the probability of the empty set, and the addition rule.\nNext time, we will start talking about ways to compute the probability of more complex events under the assumption of equally likely outcomes."
  },
  {
    "objectID": "Pages/Lectures/Lecture02/Lec02.html#last-time",
    "href": "Pages/Lectures/Lecture02/Lec02.html#last-time",
    "title": "PSTAT 5A: Lecture 02",
    "section": "Last Time",
    "text": "Last Time\n\nLast time we started discussing how to produce and interpret visual summaries for datasets consisting of only one variable.\n\nWe learned that histograms and boxplots are good visualizers for numerical variables and barplots are good visualizers for categorical data.\n\nBut, as we also saw (in the palmerpenguins dataset), data is usually comprised of several variables.\nA natural question therefore arises: how might we visualize the relationship between multiple variables?"
  },
  {
    "objectID": "Pages/Lectures/Lecture02/Lec02.html#multiple-variables",
    "href": "Pages/Lectures/Lecture02/Lec02.html#multiple-variables",
    "title": "PSTAT 5A: Lecture 02",
    "section": "Multiple Variables",
    "text": "Multiple Variables\n\nPerhaps unsurprisingly, visualizing the relationship between 3 or more variables can be a bit tricky.\nAs such, we will restrict ourselves to comparing only two variables.\nEven if we compare only two variables, three cases arise:\n\nComparing two numerical variables\nComparing one numerical and one categorical variable\nComparing two categorical variables\n\nWe will examine the first two cases above, and save the third for later."
  },
  {
    "objectID": "Pages/Lectures/Lecture02/Lec02.html#two-numerical-variables",
    "href": "Pages/Lectures/Lecture02/Lec02.html#two-numerical-variables",
    "title": "PSTAT 5A: Lecture 02",
    "section": "Two Numerical Variables",
    "text": "Two Numerical Variables\n\nLet’s say we have two variables, and we want to visualize their relationship.\nAs an example, let’s return to the palmerpenguins dataset and compare the bill_length_mm and bill_depth_mm variables. Let’s also restrict ourselves to Gentoo penguins.\n\n\n\n\n   bill_length_mm bill_depth_mm\n 1           46.1          13.2\n 2           50            16.3\n 3           48.7          14.1\n 4           50            15.2\n 5           47.6          14.5\n 6           46.5          13.5\n 7           45.4          14.6\n 8           46.7          15.3\n 9           43.3          13.4\n10           46.8          15.4\n# ℹ 114 more rows"
  },
  {
    "objectID": "Pages/Lectures/Lecture02/Lec02.html#scatterplot",
    "href": "Pages/Lectures/Lecture02/Lec02.html#scatterplot",
    "title": "PSTAT 5A: Lecture 02",
    "section": "Scatterplot",
    "text": "Scatterplot\n\nThis type of visualization is called a scatterplot.\nSpecifically, when comparing two numerical variables of the same length, we generate a scatterplot by plotting each observational unit on a Cartesian coordinate system where the axes are prescribed by the variables in question.\n\n\n\n\n\n\n\n\nResult\n\n\n\nWhen comparing two numerical variables (of the same length), a scatterplot is the best visulization tool."
  },
  {
    "objectID": "Pages/Lectures/Lecture02/Lec02.html#interpreting-scatterplots",
    "href": "Pages/Lectures/Lecture02/Lec02.html#interpreting-scatterplots",
    "title": "PSTAT 5A: Lecture 02",
    "section": "Interpreting Scatterplots",
    "text": "Interpreting Scatterplots\n\n\n\n\nLet’s return to the scatterplot we generated before:\n\n\n\n\n\n\n\n\n\nNotice how as the values of bill_length_mm increase, the corresponding values of bill_depth_mm also increase on average?\n\nThis makes intutive sense: longer bills are probably deeper!"
  },
  {
    "objectID": "Pages/Lectures/Lecture02/Lec02.html#trend",
    "href": "Pages/Lectures/Lecture02/Lec02.html#trend",
    "title": "PSTAT 5A: Lecture 02",
    "section": "Trend",
    "text": "Trend\n\nThis is an example of what we call a trend; specifically, a positive linear trend.\n\nA trend is, loosely speaking, any relationship we observe between the two variables in a scatterplot.\nA trend is said to be linear if a one-unit change in one variable corresponds to a fixed amount of change in the other (we’ll talk about nonlinear trends in a bit)\nA trend is said to be positive (or increasing) if a one-unit increase in one variable corresponds to a one-unit increase in the other."
  },
  {
    "objectID": "Pages/Lectures/Lecture02/Lec02.html#associations",
    "href": "Pages/Lectures/Lecture02/Lec02.html#associations",
    "title": "PSTAT 5A: Lecture 02",
    "section": "Associations",
    "text": "Associations\n\nAnother way to talk about trends is to phrase things in terms of the variables being compared.\n\nFor example, if the scatterplot of two variables displays a positive linear trend, we might say that the two variables have a positive linear association.\nAs a concrete example: bill length and bill depth appear to have a positive linear association, as seen in the scatterplot from a few slides ago."
  },
  {
    "objectID": "Pages/Lectures/Lecture02/Lec02.html#a-numerical-and-a-categorical-variable",
    "href": "Pages/Lectures/Lecture02/Lec02.html#a-numerical-and-a-categorical-variable",
    "title": "PSTAT 5A: Lecture 02",
    "section": "A Numerical and a Categorical Variable",
    "text": "A Numerical and a Categorical Variable\n\nThe final case we will consider today is comparing a numerical variable to a categorical one.\nAs a concrete example, here is a (mock) dataset comprised of the following variables:\n\n\n\n\n\n\n\n\n\nVariable Name\nDescription\n\n\n\n\nstdy_hrs\naverage amount of time (in hrs) a student spent studying for a particular class each week\n\n\nltr_grd\nthe final letter grade (A+, A, A-, etc.) the student received in the class"
  },
  {
    "objectID": "Pages/Lectures/Lecture02/Lec02.html#side-by-side-boxplots",
    "href": "Pages/Lectures/Lecture02/Lec02.html#side-by-side-boxplots",
    "title": "PSTAT 5A: Lecture 02",
    "section": "Side-by-Side Boxplots",
    "text": "Side-by-Side Boxplots\n\n\n\n\n\n\n\nResult\n\n\n\nWhen comparing one numerical and one categorical variable, it is best to visualize their relationship using a side-by-side boxplot.\n\n\n\n\n\n\nThough the notion of trend is slightly different in the context of a side-by-side boxplot, we can still use them to determine relationships.\nFor example, from the plot on the previous slide, we can see that, on average, students who received lower grades tended to study less than those students who received higher grades."
  },
  {
    "objectID": "Pages/Lectures/Lecture02/Lec02.html#causality",
    "href": "Pages/Lectures/Lecture02/Lec02.html#causality",
    "title": "PSTAT 5A: Lecture 02",
    "section": "Causality",
    "text": "Causality\n\nI should make a very important point: identifying trends is not the same thing as identifying causal relationships.\nFor example, the side-by-side boxplot from a few slides ago does not tell us that “studying less causes your grade to decrease”\n\nThere are a lot of other confounding variables that could contribute to the decrease in grade.\n\nWe won’t talk too much about causality in this course, but it is an important thing to be aware of: association is not the same thing as causation!"
  },
  {
    "objectID": "Pages/Lectures/Lecture02/Lec02.html#quantifying-data",
    "href": "Pages/Lectures/Lecture02/Lec02.html#quantifying-data",
    "title": "PSTAT 5A: Lecture 02",
    "section": "Quantifying Data",
    "text": "Quantifying Data\n\nLet’s once again consider a single numerical variable.\nAs a concrete example, we can consider the exam scores variable from the previous slides:\n\n\n\n\n  [1] 88.236 77.348 81.050 74.431 75.083 79.569 74.998 80.099 74.264 83.850\n [11] 89.857 81.427 79.439 84.260 78.565 77.570 78.224 73.780 88.085 79.341\n [21] 80.554 77.317 81.155 83.842 87.051 78.362 81.528 72.148 74.131 78.927\n [31] 75.446 79.791 78.199 90.769 85.640 78.420 83.484 79.045 97.909 86.736\n [41] 73.723 76.973 81.320 79.238 85.803 86.621 85.781 81.844 82.896 80.478\n [51] 75.903 84.565 76.302 83.432 85.448 69.695 81.049 85.575 84.791 82.525\n [61] 78.361 77.803 86.542 84.171 86.103 72.772 78.730 76.189 75.187 79.194\n [71] 77.159 82.048 82.661 84.021 76.008 79.474 79.015 86.992 72.524 76.094\n [81] 78.765 80.623 82.497 75.776 70.614 79.677 81.182 77.943 76.863 85.561\n [91] 89.569 96.695 73.680 77.770 81.584 81.965 78.373 76.295 73.212 79.229\n[101] 87.273 87.364 82.706 83.843 75.864 82.791 82.637 78.685 72.626 69.302\n[111] 93.408 73.189 83.764 77.832 82.803 80.278 94.962 79.616 85.667 82.710\n[121] 86.823 76.656 74.623 71.508 91.131 78.318 81.058 86.239 76.585 85.652\n[131] 77.122 86.036 83.127 83.234 80.746 83.878 75.544 73.780 81.106 85.523"
  },
  {
    "objectID": "Pages/Lectures/Lecture02/Lec02.html#summarizing-data",
    "href": "Pages/Lectures/Lecture02/Lec02.html#summarizing-data",
    "title": "PSTAT 5A: Lecture 02",
    "section": "Summarizing Data",
    "text": "Summarizing Data\n\nThe remainder of today’s lecture will be devoted to finding numerical summaries of a dataset \\(X = \\{x_i\\}_{i=1}^{n}\\).\nThis will lead us to several different summary statistics, which are mathematical quantities that seek to describe different aspects of our data."
  },
  {
    "objectID": "Pages/Lectures/Lecture02/Lec02.html#quantifying-center",
    "href": "Pages/Lectures/Lecture02/Lec02.html#quantifying-center",
    "title": "PSTAT 5A: Lecture 02",
    "section": "Quantifying “Center”",
    "text": "Quantifying “Center”\n\nHere is a very broad question: what is the center of a dataset \\(X = \\{x_i\\}_{i=1}^{n}\\)?\nPerhaps the scores dataset from earlier is a bit too complicated- let’s simplify things and look at the dataset \\[ X = \\{1, 1, 1, 2, 3, 3, 4, 5, 5, 5, 6, 6\\} \\]\nAs a starting point, I can “plot” these points on a number line (to produce what is known as a dotplot):"
  },
  {
    "objectID": "Pages/Lectures/Lecture02/Lec02.html#quantifying-center-1",
    "href": "Pages/Lectures/Lecture02/Lec02.html#quantifying-center-1",
    "title": "PSTAT 5A: Lecture 02",
    "section": "Quantifying “Center”",
    "text": "Quantifying “Center”\n\n\nBack to our question: what is the center of this dataset?\n\n\n\nPerhaps we can think of center as a balancing point. In other words: where should I place a fulcrum to ensure this number line remains balanced?\n\n\n\n\n\n\n\n\n\nWe call this balancing point the arithmetic mean (or just mean, or average, for short), and denote it \\(\\overline{x}\\)."
  },
  {
    "objectID": "Pages/Lectures/Lecture02/Lec02.html#the-mean",
    "href": "Pages/Lectures/Lecture02/Lec02.html#the-mean",
    "title": "PSTAT 5A: Lecture 02",
    "section": "The Mean",
    "text": "The Mean\n\n\n\n\n\n\nFormula: The Mean\n\n\n\nGiven a set of data \\(x = \\{x_i\\}_{i=1}^{n}\\), we compute its mean, denoted \\(\\overline{x}\\), using the formula \\[ \\overline{x} = \\frac{1}{n} (x_1 + \\cdots + x_n) \\] which can be equivalently written as \\[ \\overline{x} = \\frac{1}{n} \\sum_{i=1}^{n} x_i \\]\n\n\n\n\n\nIn words: we compute the mean by adding up all of the points included in our dataset, and dividing by the total number of points."
  },
  {
    "objectID": "Pages/Lectures/Lecture02/Lec02.html#a-note-on-notation",
    "href": "Pages/Lectures/Lecture02/Lec02.html#a-note-on-notation",
    "title": "PSTAT 5A: Lecture 02",
    "section": "A Note on Notation",
    "text": "A Note on Notation\n\nPerhaps you haven’t seen the notation \\(\\sum_{i=1}^{n} x_i\\) before. Don’t get scared by it! It’s just a shorthand notation for the sum of the points \\(\\{x_1, x_2, \\cdots, x_n\\}\\).\nSo, if it’s easier for you, you can always think of \\((x_1 + \\cdots x_n)\\) in place of \\(\\sum_{i=1}^{n} x_i\\).\nHaving said that, I will often use this notation (called sigma notation, as the symbol \\(\\sum\\) is the capital Greek letter “sigma”) as it saves quite a bit of time in the long run.\n\nI also urge you to familiarze yourself with \\(\\Sigma\\) notation, as I’m sure you will encounter it even beyond this course!"
  },
  {
    "objectID": "Pages/Lectures/Lecture02/Lec02.html#time-for-an-exercise",
    "href": "Pages/Lectures/Lecture02/Lec02.html#time-for-an-exercise",
    "title": "PSTAT 5A: Lecture 02",
    "section": "Time for an Exercise!",
    "text": "Time for an Exercise!\n\n\n\n\n\n\nExercise 1\n\n\n\nCompute the mean of the set \\(B = \\{-1, 0, 1, 1, 2, 4\\}\\). Discuss with your neighbors!"
  },
  {
    "objectID": "Pages/Lectures/Lecture02/Lec02.html#another-one",
    "href": "Pages/Lectures/Lecture02/Lec02.html#another-one",
    "title": "PSTAT 5A: Lecture 02",
    "section": "Another One!",
    "text": "Another One!\n\n\n\n\n\n\nExercise 2\n\n\n\nA collection of \\(n = 42\\) exam scores have an average 50%. Two additional scores of 100% are reported. How does the average of scores change with the addition of these two new scores?"
  },
  {
    "objectID": "Pages/Lectures/Lecture02/Lec02.html#range",
    "href": "Pages/Lectures/Lecture02/Lec02.html#range",
    "title": "PSTAT 5A: Lecture 02",
    "section": "Range",
    "text": "Range\n\nAnother way we can summarize a dataset \\(X = \\{x_i\\}_{i=1}^{n}\\) is to describe how spread out it is.\nOne idea on how we can capture the spread is to say: how far apart is the smallest value from the largest value?\nIndeed, this statistic has a name: the range.\n\n\n\n\n\n\n\n\nFormula: Range\n\n\n\nGiven a set of numbers \\(X = \\{x_1, x_2, \\cdots, x_n\\}\\), we compute the range of \\(X\\) as: \\[ \\mathrm{range}(X) = \\max\\{x_1, \\cdots, x_n\\} - \\min\\{x_1, \\ \\cdots, \\ x_n\\} \\] i.e. the largest value minus the smallest value."
  },
  {
    "objectID": "Pages/Lectures/Lecture02/Lec02.html#leadup",
    "href": "Pages/Lectures/Lecture02/Lec02.html#leadup",
    "title": "PSTAT 5A: Lecture 02",
    "section": "Leadup",
    "text": "Leadup\n\nNow, there is another way to think about spread: suppose we look at the average distance of points from their mean.\nMore specifically: define \\(d_i := x_i - \\overline{x}\\) to be the deviation of the \\(i\\)th point from the mean:"
  },
  {
    "objectID": "Pages/Lectures/Lecture02/Lec02.html#the-variance",
    "href": "Pages/Lectures/Lecture02/Lec02.html#the-variance",
    "title": "PSTAT 5A: Lecture 02",
    "section": "The Variance",
    "text": "The Variance\n\n\nThis is what we call the variance of the set \\(X\\), denoted by \\(s_x^2\\).\n\n\n\n\n\n\n\n\nFormula: Variance, and Standard Deviation\n\n\n\nGiven a set of data \\(X = \\{x_i\\}_{i=1}^{n}\\), we compute the variance of \\(X\\) by \\[ s_x^2 = \\frac{1}{n - 1} \\sum_{i=1}^{n} (x_i - \\overline{x})^2 \\] We define the standard deviation, denoted by \\(s_x\\), to be \\(\\sqrt{s_X^2}\\); i.e. \\[ s_x := \\sqrt{\\frac{1}{n - 1} \\sum_{i=1}^{n} (x_i - \\overline{x})^2} \\]"
  },
  {
    "objectID": "Pages/Lectures/Lecture02/Lec02.html#time-for-an-exercise-1",
    "href": "Pages/Lectures/Lecture02/Lec02.html#time-for-an-exercise-1",
    "title": "PSTAT 5A: Lecture 02",
    "section": "Time for an Exercise!",
    "text": "Time for an Exercise!\n\n\n\n\n\n\nExercise 3\n\n\n\nFor the set \\(X = \\{1, 2, 3, 4, 5\\}\\), compute \\(s_x\\). Discuss with your neighbor!"
  },
  {
    "objectID": "Pages/Lectures/Lecture02/Lec02.html#iqr",
    "href": "Pages/Lectures/Lecture02/Lec02.html#iqr",
    "title": "PSTAT 5A: Lecture 02",
    "section": "IQR",
    "text": "IQR\n\nThere is yet another way to quantify the spread of a dataset, and that is what is known as the Interquartile Range (IQR, for short).\n\n\n\n\n\n\n\n\nFormula: The IQR\n\n\n\nGiven a set of data \\(x = \\{x_i\\}_{i=1}^{n}\\), we compute its interquartile range using the formula \\[ \\mathrm{IQR} = Q_3 - Q_1 \\] where \\(Q_1\\) and \\(Q_3\\) denote the first and third quartiles, respectively.\n\n\n\n\n\n\nIn other words, the IQR is just the width of the box in a boxplot!"
  },
  {
    "objectID": "Pages/Lectures/Lecture02/Lec02.html#five-number-summary",
    "href": "Pages/Lectures/Lecture02/Lec02.html#five-number-summary",
    "title": "PSTAT 5A: Lecture 02",
    "section": "Five Number Summary",
    "text": "Five Number Summary\n\nSpeaking of boxplots, there is a set of numbers that occurs frequently when summarizing numerical data, collectively called the five number summary. The elements of the five number summary are:\n\nThe minimum\nThe first quartile\nThe median\nThe third quartile\nThe maximum"
  },
  {
    "objectID": "Pages/Lectures/Lecture02/Lec02.html#time-for-an-exercise-2",
    "href": "Pages/Lectures/Lecture02/Lec02.html#time-for-an-exercise-2",
    "title": "PSTAT 5A: Lecture 02",
    "section": "Time for an Exercise!",
    "text": "Time for an Exercise!\n\n\n\n\n\n\nExercise 4\n\n\n\nConsider a dataset \\(X\\) that has boxplot given by:\n\n\n\n\n\nProvide the five number summary, along with the IQR. Discuss with your Neighbors!"
  },
  {
    "objectID": "Pages/Lectures/Lecture02/Lec02.html#summary",
    "href": "Pages/Lectures/Lecture02/Lec02.html#summary",
    "title": "PSTAT 5A: Lecture 02",
    "section": "Summary",
    "text": "Summary\n\nWe started off by finishing our discussion of data visualizing, identifying ways to visualize the relationship between two variables.\n\nSuch visualizations included: scatterplots and side-by-side boxplots.\nWe also discussed notions of trend.\n\nNext, we discussed various numerical summaries of data.\n\nThese included measures of central tendency (like the mean or the median), along with measures of spread (like the variance, standard deviation, or IQR).\nWe were also introduced to the five number summary, which is closely related to boxplots.\n\nNext time we’ll begin our discussion on Probability, which, as we will see, provides a rigorous way of quantifying uncertainty."
  },
  {
    "objectID": "Pages/Lectures/Lecture05/Lec05.html#leadup",
    "href": "Pages/Lectures/Lecture05/Lec05.html#leadup",
    "title": "PSTAT 5A: Lecture 05",
    "section": "Leadup",
    "text": "Leadup\n\nRemember how, back in Week 1, we discussed ways to compare two variables?\nAt the time, we only considered comparing two numerical variables and comparing one numerical and one categorical variable.\nWhat about comparing two categorical variables?\nAs a concrete example, let’s return to…"
  },
  {
    "objectID": "Pages/Lectures/Lecture05/Lec05.html#penguins-revisited",
    "href": "Pages/Lectures/Lecture05/Lec05.html#penguins-revisited",
    "title": "PSTAT 5A: Lecture 05",
    "section": "Penguins, Revisited",
    "text": "Penguins, Revisited\n\n\n   species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n 1 Adelie  Torgersen           39.1          18.7               181        3750\n 2 Adelie  Torgersen           39.5          17.4               186        3800\n 3 Adelie  Torgersen           40.3          18                 195        3250\n 4 Adelie  Torgersen           NA            NA                  NA          NA\n 5 Adelie  Torgersen           36.7          19.3               193        3450\n 6 Adelie  Torgersen           39.3          20.6               190        3650\n 7 Adelie  Torgersen           38.9          17.8               181        3625\n 8 Adelie  Torgersen           39.2          19.6               195        4675\n 9 Adelie  Torgersen           34.1          18.1               193        3475\n10 Adelie  Torgersen           42            20.2               190        4250\n# ℹ 334 more rows\n# ℹ 2 more variables: sex <fct>, year <int>"
  },
  {
    "objectID": "Pages/Lectures/Lecture05/Lec05.html#penguins-subsetted",
    "href": "Pages/Lectures/Lecture05/Lec05.html#penguins-subsetted",
    "title": "PSTAT 5A: Lecture 05",
    "section": "Penguins, Subsetted",
    "text": "Penguins, Subsetted\n\n\n   species island   \n 1 Adelie  Torgersen\n 2 Adelie  Torgersen\n 3 Adelie  Torgersen\n 4 Adelie  Torgersen\n 5 Adelie  Torgersen\n 6 Adelie  Torgersen\n 7 Adelie  Torgersen\n 8 Adelie  Torgersen\n 9 Adelie  Torgersen\n10 Adelie  Torgersen\n# ℹ 334 more rows"
  },
  {
    "objectID": "Pages/Lectures/Lecture05/Lec05.html#some-questions",
    "href": "Pages/Lectures/Lecture05/Lec05.html#some-questions",
    "title": "PSTAT 5A: Lecture 05",
    "section": "Some Questions",
    "text": "Some Questions\n\nHere are some questions we could ask:\n\nHow many Adelie penguins were found on Biscoe island?\nWere any Gentoo penguins found on Torgersen island?\nWhat proportion of Chinstrap penguins were found on Dream island?\n\nThese sorts of questions are very nicely answered by way of what is known as a contingency table:\n\n\n\n\n           \n            Biscoe Dream Torgersen\n  Adelie        44    56        52\n  Chinstrap      0    68         0\n  Gentoo       124     0         0\n\n\n\n\nThus, the answers to the questions above are: “44”, “no”, and “100%”, respectively."
  },
  {
    "objectID": "Pages/Lectures/Lecture05/Lec05.html#why-bring-this-up-now",
    "href": "Pages/Lectures/Lecture05/Lec05.html#why-bring-this-up-now",
    "title": "PSTAT 5A: Lecture 05",
    "section": "Why Bring This Up Now?",
    "text": "Why Bring This Up Now?\n\nYou may be asking yourselves: “why bring this up now? Weren’t we talking about probability?”\nLet’s re-examine the third question we asked on the previous slide: What proportion of Chinstrap penguins were found on Dream island?\nWhat we really did when we answered this was to first restrict ourselves to the row of the contingency table corresponding to Chinstrap penguins, tally up the entries in that row, and then divided the number of penguins that were both Chinstrap and found on Dream Island by the row total."
  },
  {
    "objectID": "Pages/Lectures/Lecture05/Lec05.html#conditional-probability",
    "href": "Pages/Lectures/Lecture05/Lec05.html#conditional-probability",
    "title": "PSTAT 5A: Lecture 05",
    "section": "Conditional Probability",
    "text": "Conditional Probability\n\nThis leads us to the main topic of today’s lecture: conditional probabilities.\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nIf \\(E\\) and \\(F\\) are two events with \\(\\mathbb{P}(E) \\neq 0\\), then we define the probability of \\(E\\) given \\(F\\), notated \\(\\mathbb{P}(E \\mid F)\\), to be \\[ \\mathbb{P}(E \\mid F) = \\frac{\\mathbb{P}(E \\cap F)}{\\mathbb{P}(F)} \\] If \\(\\mathbb{P}(F) = 0\\), then \\(\\mathbb{P}(E \\mid F)\\) is not defined."
  },
  {
    "objectID": "Pages/Lectures/Lecture05/Lec05.html#interpretation",
    "href": "Pages/Lectures/Lecture05/Lec05.html#interpretation",
    "title": "PSTAT 5A: Lecture 05",
    "section": "Interpretation",
    "text": "Interpretation\n\n\\(\\mathbb{P}(E \\mid F)\\) essentially gives us the proportion of \\(F\\) that is explained by \\(E\\).\n\nAs such, another way to think about conditional probabilities is as an “if-then” statement: if \\(F\\) has occurred, what is the probability that \\(E\\) also occurs?\n\nIf we adopt the classical approach to probability, we have \\[\\begin{align*}\n\\mathbb{P}(E \\mid F)    & = \\frac{\\mathbb{P}(E \\cap F)}{\\mathbb{P}(F)}    \\\\\n  & = \\frac{\\left( \\frac{\\#(E \\cap F)}{\\#(\\Omega)} \\right)}{\\left( \\frac{\\#(F)}{\\#(\\Omega)} \\right)} = \\frac{\\#(E \\cap F)}{\\#(F)}\n\\end{align*}\\]\nThis is also why contingency tables are so useful in the context of probability- the numerator above will be an entry in the table, and the denominator will be either a row-sum or a column-sum (depending on how the table was constructed)."
  },
  {
    "objectID": "Pages/Lectures/Lecture05/Lec05.html#worked-out-example",
    "href": "Pages/Lectures/Lecture05/Lec05.html#worked-out-example",
    "title": "PSTAT 5A: Lecture 05",
    "section": "Worked-Out Example",
    "text": "Worked-Out Example\n\n\n\n\n\n\nWorked-Out Exercise 1\n\n\n\n75 UCSB students were surveyed about whether they like pineapple on pizza or not. In addition to their pineapple preference, their standing was also recorded.\n\n\n         Standing\nPineapple Freshman Junior Senior Sophomore\n      No        15      6      1        18\n      Yes       10      7      5        13\n\n\nA student is to be randomly selected. If the student is a Freshman, what is the probability that they like pineapple on pizza?\n\n\n\n\n\nAs always, we begin by defining events and notation. Let \\(P =\\) “the student likes pineapple on pizza” and \\(F =\\) “the student is a freshman”. We then seek \\(\\mathbb{P}(P \\mid F)\\)."
  },
  {
    "objectID": "Pages/Lectures/Lecture05/Lec05.html#multiplication-rule",
    "href": "Pages/Lectures/Lecture05/Lec05.html#multiplication-rule",
    "title": "PSTAT 5A: Lecture 05",
    "section": "Multiplication Rule",
    "text": "Multiplication Rule\n\nRecall that. provided \\(\\mathbb{P}(F) \\neq 0\\) \\[ \\mathbb{P}(E \\mid F) = \\frac{\\mathbb{P}(E \\cap F)}{\\mathbb{P}(F)} \\]\nWe can multiply both sides of this equation by \\(\\mathbb{P}(F)\\) to obtain the so-called multiplication rule:\n\n\n\n\n\n\n\n\nThe Multiplication Rule\n\n\n\n\\(\\mathbb{P}(E \\cap F) = \\mathbb{P}(E \\mid F) \\cdot \\mathbb{P}(F)\\), for any events \\(E\\) and \\(F\\) with \\(\\mathbb{P}(F) \\neq 0\\)."
  },
  {
    "objectID": "Pages/Lectures/Lecture05/Lec05.html#leadup-1",
    "href": "Pages/Lectures/Lecture05/Lec05.html#leadup-1",
    "title": "PSTAT 5A: Lecture 05",
    "section": "Leadup",
    "text": "Leadup\n\nNote that “\\(E\\) and \\(F\\)” is the same as “\\(F\\) and \\(E\\)”.\nThat is: \\(\\mathbb{P}(E \\cap F) = \\mathbb{P}(F \\cap E)\\).\nSo, if we interchange the place of \\(E\\) and \\(F\\) in the multiplication rule, we obtain \\[ \\mathbb{P}(E \\cap F) = \\mathbb{P}(F \\cap E) = \\mathbb{P}(F \\mid E) \\cdot \\mathbb{P}(E) \\]\nThat is to say, we have \\[\\begin{align*}\n\\mathbb{P}(E \\cap F)    & = \\mathbb{P}(E \\mid F) \\cdot \\mathbb{P}(F) = \\mathbb{P}(F \\mid E) \\cdot \\mathbb{P}(E)\n\\end{align*}\\]\nDividing the last equation by \\(\\mathbb{P}(F)\\) yields an important result:"
  },
  {
    "objectID": "Pages/Lectures/Lecture05/Lec05.html#bayes-rule",
    "href": "Pages/Lectures/Lecture05/Lec05.html#bayes-rule",
    "title": "PSTAT 5A: Lecture 05",
    "section": "Bayes’ Rule",
    "text": "Bayes’ Rule\n\n\n\n\n\n\n\nBaeys’ Rule\n\n\n\n\\[ \\mathbb{P}(E \\mid F) = \\frac{\\mathbb{P}(F \\mid E) \\cdot \\mathbb{P}(E)}{\\mathbb{P}(F)} \\] for events \\(E\\) and \\(F\\) with \\(\\mathbb{P}(E) \\neq 0\\) and \\(\\mathbb{P}(F) \\neq 0\\).\n\n\n\n\n\n\nIn a sense, Bayes’ Rule gives us a way to “reverse the order of a conditional”"
  },
  {
    "objectID": "Pages/Lectures/Lecture05/Lec05.html#worked-out-example-1",
    "href": "Pages/Lectures/Lecture05/Lec05.html#worked-out-example-1",
    "title": "PSTAT 5A: Lecture 05",
    "section": "Worked-Out Example",
    "text": "Worked-Out Example\n\nAs an illustration, let’s return to our pineapple-on-pizza contingency table:\n\n\n\n\n         Standing\nPineapple Freshman Junior Senior Sophomore\n      No        15      6      1        18\n      Yes       10      7      5        13\n\n\n\n\nLetting \\(P\\) and \\(F\\) be defined as before, let’s compute \\(\\mathbb{P}(P \\mid F)\\) using Bayes’ Rule.\nWe need to first compute \\(\\mathbb{P}(F \\mid P)\\), which we see to be \\[ \\mathbb{P}(F \\mid P) = \\frac{10}{10 + 7 + 5 + 13} = \\frac{10}{35} \\]"
  },
  {
    "objectID": "Pages/Lectures/Lecture05/Lec05.html#hang-in-there",
    "href": "Pages/Lectures/Lecture05/Lec05.html#hang-in-there",
    "title": "PSTAT 5A: Lecture 05",
    "section": "Hang In There!",
    "text": "Hang In There!\n\nAt the moment, it may not seem obvious why Bayes’ Rule is helpful.\n\nIt seems like it just makes more work!\n\nBut, rest assured, we will see a very practical application of Bayes’ Rule in a few slides.\nBefore we do, there’s just one more concept we need to discuss."
  },
  {
    "objectID": "Pages/Lectures/Lecture05/Lec05.html#leadup-2",
    "href": "Pages/Lectures/Lecture05/Lec05.html#leadup-2",
    "title": "PSTAT 5A: Lecture 05",
    "section": "Leadup",
    "text": "Leadup\n\nConsider an event \\(F\\), and another event \\(E\\).\nIf \\(F\\) happened, it could have happened along with \\(E\\) or it could have happened along with not-\\(E\\).\nThat is, \\[ F = (F \\cap E) \\cup (F \\cap E^\\complement)\\]\nNow, let’s take the probability of both sides. Since the events on the RHS are disjoint, the probability on the RHS just becomes a sum of probabilities: \\[ \\mathbb{P}(F) = \\mathbb{P}(F \\cap E) + \\mathbb{P}(F \\cap E^\\complement) \\]\nFinally, we apply the Multiplication Rule to the probabilities on the RHS to obtain \\[ \\mathbb{P}(F) = \\mathbb{P}(F \\mid E) \\cdot \\mathbb{P}(E) + \\mathbb{P}(F \\mid E^\\complement) \\cdot \\mathbb{P}(E^\\complement) \\]"
  },
  {
    "objectID": "Pages/Lectures/Lecture05/Lec05.html#law-of-total-probability",
    "href": "Pages/Lectures/Lecture05/Lec05.html#law-of-total-probability",
    "title": "PSTAT 5A: Lecture 05",
    "section": "Law of Total Probability",
    "text": "Law of Total Probability\n\n\n\n\n\n\n\nThe Law of Total Probability\n\n\n\nGiven two events \\(E\\) and \\(F\\) with \\(\\mathbb{P}(E) \\neq 0\\) and \\(\\mathbb{P}(F) \\neq 0\\), we have \\[ \\mathbb{P}(F) = \\mathbb{P}(F \\mid E) \\cdot \\mathbb{P}(E) + \\mathbb{P}(F \\mid E^\\complement) \\cdot \\mathbb{P}(E^\\complement) \\]\n\n\n\n\n\n\nThis is often useful in the context of a Bayes’ Rule problem."
  },
  {
    "objectID": "Pages/Lectures/Lecture05/Lec05.html#worked-out-example-2",
    "href": "Pages/Lectures/Lecture05/Lec05.html#worked-out-example-2",
    "title": "PSTAT 5A: Lecture 05",
    "section": "Worked-Out Example",
    "text": "Worked-Out Example\n\nAlright, let’s get down to business and tackle a slightly more real-world problem.\n\n\n\n\n\n\n\n\nWorked-Out Exercise 1\n\n\n\nIt is known that a particular disease affects 5% of the population. There exists a test for this disease, but it is not perfect: there is a 10% chance it will return a “negative” result for a person who is actually infected, and there is a 8% chance it will return a “positive” result for a person who is actually healthy.\n\nArasha has taken a test for the disease, and it has indicated a “positive” result. What is the probability that Arasha actually has the disease?"
  },
  {
    "objectID": "Pages/Lectures/Lecture05/Lec05.html#step-1-define-events",
    "href": "Pages/Lectures/Lecture05/Lec05.html#step-1-define-events",
    "title": "PSTAT 5A: Lecture 05",
    "section": "Step 1: Define Events",
    "text": "Step 1: Define Events\n\nAs always, we start by defining events.\nLet + denote “the test returns a positive result” and let \\(D\\) denote “Arasha actually has the disease.”\nFirst of all, note that we are not interested in simply finding \\(\\mathbb{P}(D)\\); rather, we are interested in finding \\(\\mathbb{P}(D \\mid +)\\).\n\nThis is because Arasha has already been tested and received a positive result; this is information we need to incorporate into our beliefs!"
  },
  {
    "objectID": "Pages/Lectures/Lecture05/Lec05.html#step-2-translate-the-information",
    "href": "Pages/Lectures/Lecture05/Lec05.html#step-2-translate-the-information",
    "title": "PSTAT 5A: Lecture 05",
    "section": "Step 2: Translate the Information",
    "text": "Step 2: Translate the Information\n\nWith our events from Step 1, we now turn our attention to translating the information provided in the problem.\nSince there is a \\(10\\%\\) chance that the test returns a negative result given that a person actually has the disease, we have \\[ \\mathbb{P}(+^\\complement \\mid D) = 0.1 \\]\nAdditionally, we are told that there is an \\(8\\%\\) chance that the test returns a positive result given that a person does not have disease, we have \\[ \\mathbb{P}(+ \\mid D^\\complement) = 0.08 \\]\nFinally, we are told that 5% of the population has the disease; hence, \\[ \\mathbb{P}(D) = 0.05 \\]"
  },
  {
    "objectID": "Pages/Lectures/Lecture05/Lec05.html#step-3-translate-the-information",
    "href": "Pages/Lectures/Lecture05/Lec05.html#step-3-translate-the-information",
    "title": "PSTAT 5A: Lecture 05",
    "section": "Step 3: Translate the Information",
    "text": "Step 3: Translate the Information\n\nBut wait- there’s more!\nGiven that a person has the disease, they will either test positive or test negative.\n\nWhat that means is that \\[ \\mathbb{P}(+ \\mid D) = 1 - \\mathbb{P}(+^\\complement \\mid D) = 1 - 0.1 = 0.9 \\]\nThink of this as a modified complement rule\n\nSimilarly, \\[ \\mathbb{P}(+^\\complement \\mid D^\\complement) = 1 - \\mathbb{P}(+ \\mid D^\\complement) = 1 - 0.08 = 0.92 \\]\nAdditionally, \\[ \\mathbb{P}(D^\\complement) =  1 - \\mathbb{P}(D) = 1 - 0.05 = 0.95 \\]"
  },
  {
    "objectID": "Pages/Lectures/Lecture05/Lec05.html#step-2-translate-the-information-1",
    "href": "Pages/Lectures/Lecture05/Lec05.html#step-2-translate-the-information-1",
    "title": "PSTAT 5A: Lecture 05",
    "section": "Step 2: Translate the Information",
    "text": "Step 2: Translate the Information\n\nSo, here’s a summary of everything we know, just from the problem statement: \\[\\begin{align*}\n\\mathbb{P}(+ \\mid D) = 0.9    & \\hspace{15mm} \\mathbb{P}(+^\\complement \\mid D) = 0.1    \\\\\n\\mathbb{P}(+ \\mid D^\\complement) = 0.08   & \\hspace{15mm}  \\mathbb{P}(P^\\complement \\mid D^\\complement) = 0.92   \\\\\n\\mathbb{P}(D) = 0.05    & \\hspace{15mm}  \\mathbb{P}(D^\\complement) = 0.95\n\\end{align*}\\]"
  },
  {
    "objectID": "Pages/Lectures/Lecture05/Lec05.html#step-3-solve-the-problem",
    "href": "Pages/Lectures/Lecture05/Lec05.html#step-3-solve-the-problem",
    "title": "PSTAT 5A: Lecture 05",
    "section": "Step 3: Solve the Problem",
    "text": "Step 3: Solve the Problem\n\nNow we are in a position to begin solving the problem.\nRecall that we seek \\(\\mathbb{P}(D \\mid +)\\).\nBut, we only have information on \\(\\mathbb{P}(+ \\mid D)\\).\nAny ideas what rule/tool we should use?\n\nThat’s right; Bayes’ Rule!\n\nWe use Bayes’ Rule to write \\[ \\mathbb{P}(D \\mid +) = \\frac{\\mathbb{P}(+ \\mid D) \\cdot \\mathbb{P}(D)}{\\mathbb{P}(+)} \\]"
  },
  {
    "objectID": "Pages/Lectures/Lecture05/Lec05.html#step-3-solve-the-problem-1",
    "href": "Pages/Lectures/Lecture05/Lec05.html#step-3-solve-the-problem-1",
    "title": "PSTAT 5A: Lecture 05",
    "section": "Step 3: Solve the Problem",
    "text": "Step 3: Solve the Problem\n\nDo we have \\(\\mathbb{P}(+)?\\)\n\nNo…\nBut how can we get it?\nYup- Law of Total Probability!\n\nWe use the Law of Total Probability to write\n\n\n\\[\\begin{align*}\n  \\mathbb{P}(+)   & = \\mathbb{P}(+ \\mid D) \\cdot \\mathbb{P}(D) + \\mathbb{P}(+ \\mid D^\\complement) \\cdot \\mathbb{P}(D^\\complement)    \\\\\n    & = (0.9) \\cdot (0.05) + (0.08) \\cdot (0.95) = 0.121\n\\end{align*}\\]"
  },
  {
    "objectID": "Pages/Lectures/Lecture05/Lec05.html#step-3-solve-the-problem-2",
    "href": "Pages/Lectures/Lecture05/Lec05.html#step-3-solve-the-problem-2",
    "title": "PSTAT 5A: Lecture 05",
    "section": "Step 3: Solve the Problem",
    "text": "Step 3: Solve the Problem\n\nFinally, putting everything together:\n\n\n\\[\\begin{align*}\n  \\mathbb{P}(D \\mid +)    & = \\frac{\\mathbb{P}(+ \\mid D) \\cdot \\mathbb{P}(D)}{\\mathbb{P}(+)}   \\\\\n    & = \\frac{(0.9) \\cdot (0.05)}{0.121} \\boxed{\\approx 37.19\\%}\n\\end{align*}\\]\n\n\nIf that seems low… you’re right! But, it is actually in line with the problem- the test for the disease is pretty bad, considering how often it gets things wrong. This is why this probability is low- because the test is so bad, we cannot be confident that Arasha actually has the disease, even though she tested positive!"
  },
  {
    "objectID": "Pages/Lectures/Lecture05/Lec05.html#some-terminology",
    "href": "Pages/Lectures/Lecture05/Lec05.html#some-terminology",
    "title": "PSTAT 5A: Lecture 05",
    "section": "Some Terminology",
    "text": "Some Terminology\n\nBy the way, there’s some terminology I’d like to quickly introduce to make our lives easier going forward.\nThe False Positive Rate of a test is the proportion of times it returns a “positive” result, when the truth is actually “negative”.\n\nSo, in the context of epidemiology, the false positive rate of a test is the proportion of times it says someone has a disease when they do not actually have the disease.\n\nAnalogously, the False Negative Rate of a test is the proportion of times it returns a “negative” result, when the truth is actually “positive”.\n\nSo, in the context of epidemiology, the false negative rate of a test is the proportion of times it says someone does not have a disease when they do actually have the disease."
  },
  {
    "objectID": "Pages/Lectures/Lecture05/Lec05.html#a-preview-of-hw",
    "href": "Pages/Lectures/Lecture05/Lec05.html#a-preview-of-hw",
    "title": "PSTAT 5A: Lecture 05",
    "section": "A Preview of HW",
    "text": "A Preview of HW\n\nThere is one very important topic which I decided to put on your homework, so as to not make today’s lecture denser than it already is.\n\nIt is called “Independence”, and is a crucial part of probability!\n\nSpeaking of the next homework- please remember that there will be a Homework 3 released tomorrow (Wednesday 4/19) and will be due MONDAY by 11:59pm.\n\nIt will contain some review problems as well!"
  },
  {
    "objectID": "Pages/Lectures/Lecture05/Lec05.html#some-problems-to-think-on",
    "href": "Pages/Lectures/Lecture05/Lec05.html#some-problems-to-think-on",
    "title": "PSTAT 5A: Lecture 05",
    "section": "Some Problems To Think On:",
    "text": "Some Problems To Think On:\n\n\n\n\n\n\nExercise 1\n\n\n\n\nA recent survey interviewed several UCSB students about their pets. The following data was collected:\n\n\n             Animal\nAdopted       Bunny Cat Dog Hamster\n  Adopted         3   5   8       4\n  Not Adopted     1   5   7       7\n\n\n\nIf a pet is to be selected at random, what is the probability that it is either a cat or adopted?\nA pet is selected at random: what is the probability that it is an adopted dog?\nA pet is selected at random: if it is a dog, what is the probability that it was adopted?"
  },
  {
    "objectID": "Pages/Lectures/Lecture00/Lec00.html#course-staff",
    "href": "Pages/Lectures/Lecture00/Lec00.html#course-staff",
    "title": "PSTAT 5A: Lecture 00",
    "section": "Course Staff",
    "text": "Course Staff\n\n\n\n\nInstructor:\n\nEthan (He/Him)\nepmarzban@pstat.ucsb.edu\nOH: HW Clinic: Tuesdays, 4:30 - 5:30pm in ELLSN 2626  OH: Fridays, 12 - 1pm in SH 5607F\n\n\n\n\n\n\n\n\n\n\n\n\nWhat is a HW Clinic?\n\nBasically, it will be like a regular office hours but with a focus on Homework (along with a possible short review at the start)."
  },
  {
    "objectID": "Pages/Lectures/Lecture00/Lec00.html#course-staff-1",
    "href": "Pages/Lectures/Lecture00/Lec00.html#course-staff-1",
    "title": "PSTAT 5A: Lecture 00",
    "section": "Course Staff",
    "text": "Course Staff\n\n\nTeaching Assistants:\n\n\n\n\nNickolas Thiessen\nnickolas@ucsb.edu\nOH: F, 9 - 11am in B434 Rm 113\n\n\n\n\n\nJason Teng\njteng@ucsb.edu\nOH: Th, 10 - 11am in SH 5421\n\n\n\n\n\n\nYuan Zhou\nyuan_zhou@ucsb.edu\nOH: T, 11am - 12pm in SH 5421"
  },
  {
    "objectID": "Pages/Lectures/Lecture00/Lec00.html#course-staff-2",
    "href": "Pages/Lectures/Lecture00/Lec00.html#course-staff-2",
    "title": "PSTAT 5A: Lecture 00",
    "section": "Course Staff",
    "text": "Course Staff\nUndergraduate Learning Assistant:\n\n\nCatherine Li\ncatherine_li@ucsb.edu\nOH: T, 2 - 4pm and Th, 9 - 11am (over Zoom)\nStudy Groups:\n\nT 3:30 - 4:30pm (location TBD)\nTh 3:30 - 5:30pm (location TBD)\n\n\n\n\n\nCatherine’s Help Hours will begin Next Week"
  },
  {
    "objectID": "Pages/Lectures/Lecture00/Lec00.html#course-resources",
    "href": "Pages/Lectures/Lecture00/Lec00.html#course-resources",
    "title": "PSTAT 5A: Lecture 00",
    "section": "Course Resources",
    "text": "Course Resources\n\nCanvas: for grades and quizzes\nGradescope: for homeworks and exams\nCourse Website: https://pstat5a.github.io\n\nAll relevant course material will be posted to the website!\nOne exception: quizzes, which will be randomized across students and administered over Canvas.\n\nPlease read the syllabus fully and carefully!\n\nEspecially when it comes to switching Sections!"
  },
  {
    "objectID": "Pages/Lectures/Lecture00/Lec00.html#discord",
    "href": "Pages/Lectures/Lecture00/Lec00.html#discord",
    "title": "PSTAT 5A: Lecture 00",
    "section": "Discord",
    "text": "Discord\n\n\n\n\n\n\n\n\n\n\nbit.ly/sp235adisc"
  },
  {
    "objectID": "Pages/Lectures/Lecture00/Lec00.html#bit.lysp235adisc",
    "href": "Pages/Lectures/Lecture00/Lec00.html#bit.lysp235adisc",
    "title": "PSTAT 5A: Lecture 00",
    "section": "bit.ly/sp235adisc",
    "text": "bit.ly/sp235adisc"
  },
  {
    "objectID": "Pages/Lectures/Lecture00/Lec00.html#what-is-data-science-1",
    "href": "Pages/Lectures/Lecture00/Lec00.html#what-is-data-science-1",
    "title": "PSTAT 5A: Lecture 00",
    "section": "What is Data Science?",
    "text": "What is Data Science?\n\nNot a bad definition!\nThough, there isn’t a single agreed-upon definition of what data science is.\nMost people agree that Data science is cross-disciplinary, drawing experience and expertise from a wide variety of different fields.\n\nPerhaps the two main fields from which Data Science draws are Statistics and Computer Science\n\nLike ChatGPT suggested, computation is an integral part of Data Science.\n\nAs we will soon see, the data that is being analyzed these days is huge; certainly too large to be able to do anything with it on pen and paper."
  },
  {
    "objectID": "Pages/Lectures/Lecture00/Lec00.html#the-path-forward",
    "href": "Pages/Lectures/Lecture00/Lec00.html#the-path-forward",
    "title": "PSTAT 5A: Lecture 00",
    "section": "The Path Forward",
    "text": "The Path Forward\n\nSo, how does this course factor into things?\nFrom the course description:\n\n\n\nIntroduction to data science. Concepts of statistical thinking. Topics include random variables, sampling distributions, hypothesis testing, correlation and regression. Visualizing, analyzing and interpreting real world data using Python. Computing labs required.\n\n\n\nSo this course is designed to be an introduction to data science."
  },
  {
    "objectID": "Pages/Lectures/Lecture09/Lec09.html#last-time",
    "href": "Pages/Lectures/Lecture09/Lec09.html#last-time",
    "title": "PSTAT 5A: Lecture 09",
    "section": "Last Time",
    "text": "Last Time\n\nLast lecture we started talking about random variables.\nA random variable is a numeric outcome of some random process or experiment.\n\nFor example, “number of heads observed in \\(5\\) independent tosses of a fair coin”\n\nThe state space of a random variable \\(X\\) is the set \\(S_X\\) of possible values the random variable could attain.\n\nIf \\(S_X\\) has jumps, we say \\(X\\) is a “discrete random variable”\nOtherwise, we say \\(X\\) is a “continuous random variable.”\n\nToday we’ll talk about continuous random variables."
  },
  {
    "objectID": "Pages/Lectures/Lecture09/Lec09.html#continuous-random-variables",
    "href": "Pages/Lectures/Lecture09/Lec09.html#continuous-random-variables",
    "title": "PSTAT 5A: Lecture 09",
    "section": "Continuous Random Variables",
    "text": "Continuous Random Variables\n\nContinuous random variables are described by their so-called probability density function (or p.d.f. for short).\n\nThe graph of a p.d.f. is called the density curve.\n\nThe p.d.f. is such that probabilities are found as areas underneath the density curve.\nFor example, if the random variable \\(X\\) has the following density curve…"
  },
  {
    "objectID": "Pages/Lectures/Lecture09/Lec09.html#two-properties",
    "href": "Pages/Lectures/Lecture09/Lec09.html#two-properties",
    "title": "PSTAT 5A: Lecture 09",
    "section": "Two Properties",
    "text": "Two Properties\n\nSince probabilities are areas underneath the density curve, we arrive at the following two properties (which themselves follow from the Axioms of Probability):\n\n\n\n\n\n\n\n\nProperties of a P.D.F.\n\n\n\n\nDensity curves must always be nonnegative; i.e. the corresponding p.d.f. \\(f_X(x)\\) must obey \\(f_X(x) \\geq 0\\) for every \\(x\\).\nThe area underneath a density curve must be \\(1\\).\n\n\n\n\n\n\n\nIn this lecture, we will examine two continuous distributions: the uniform distribution, and the normal distribution.\n\nWe will see that the density curves/p.d.f.’s of these two distributions will satisfy the above two properties."
  },
  {
    "objectID": "Pages/Lectures/Lecture09/Lec09.html#uniform-distribution-1",
    "href": "Pages/Lectures/Lecture09/Lec09.html#uniform-distribution-1",
    "title": "PSTAT 5A: Lecture 09",
    "section": "Uniform Distribution",
    "text": "Uniform Distribution\n\nThe uniform distribution takes two parameters: \\(a\\) and \\(b\\), with \\(a < b\\).\n\nWe denote the fact that a random variable \\(X\\) follows the uniform distribution with parameters \\(a\\) and \\(b\\) using the notation \\[ X \\sim \\mathrm{Unif}(a, \\ b) \\]\n\nThe \\(\\mathrm{Unif}(a, \\ b)\\) distribution has the following p.d.f.: \\[ f_X(x) = \\begin{cases} \\displaystyle \\frac{1}{b - a} & \\text{if } a \\leq x \\leq b \\\\[3mm] 0 & \\text{otherwise} \\\\ \\end{cases} \\] which corresponds to a rectangular density curve:"
  },
  {
    "objectID": "Pages/Lectures/Lecture09/Lec09.html#uniform-density-curves",
    "href": "Pages/Lectures/Lecture09/Lec09.html#uniform-density-curves",
    "title": "PSTAT 5A: Lecture 09",
    "section": "Uniform Density Curves",
    "text": "Uniform Density Curves\n\nOftentimes, we will be a bit lazy with our density curve and omit the open/closed circles. For example, we might sketch the density curve of the \\(\\mathrm{Unif}(1, \\ 2.15)\\) distribution as"
  },
  {
    "objectID": "Pages/Lectures/Lecture09/Lec09.html#effect-of-changing-a-and-b",
    "href": "Pages/Lectures/Lecture09/Lec09.html#effect-of-changing-a-and-b",
    "title": "PSTAT 5A: Lecture 09",
    "section": "Effect of Changing \\(a\\) and \\(b\\)",
    "text": "Effect of Changing \\(a\\) and \\(b\\)\n\nviewof a = Inputs.range(\n  [-3, 3], \n  {value: 0, step: 0.1, label: \"a=\"}\n)\n\nviewof b = Inputs.range(\n  [-3, 3], \n  {value: 1, step: 0.1, label: \"b=\"}\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmargin2 = ({top: 20, right: 30, bottom: 30, left: 40})\n\nheight2 = 400\n\nx_values2 = d32.scaleLinear()\n.domain(d32.extent(data2, d => d.x))\n.range([margin2.left, width - margin2.right])\n\ny_values2 = d32.scaleLinear()\n.domain([Math.min(d32.min(data2, d => d.y),0), Math.max(1,d32.max(data2, d => d.y))]).nice()\n.range([height2 - margin2.bottom, margin2.top])\n\nline2 = d32.line()\n.x(d => x_values2(d.x))\n.y(d => y_values2(d.y))\n\nxAxis2 = g => g\n.attr(\"transform\", `translate(0,${height2 - margin2.bottom})`)\n.call(d32.axisBottom(x_values2)\n      .ticks(width / 80)\n      .tickSizeOuter(0))\n\nyAxis2 = g => g\n.attr(\"transform\", `translate(${margin2.left},0)`)\n.call(d32.axisLeft(y_values2)\n      .tickValues(d32.scaleLinear().domain(y_values2.domain()).ticks()))\n\nfunction unif_pdf (input_value, mu, sigsq) {\nif(input_value < a){\n  return 0\n} else if(input_value > b){\n  return 0\n} else{\n  return 1 / (b - a)\n}\n}\n\nabs_x2=6\n\ndata2 = {\n  let values = [];\n  for (let x = -abs_x2; x < abs_x2; x=x+0.01) values.push({\"x\":x,\"y\":unif_pdf(x, µ, sigsquared)});\n  return values;\n}\n\nd32 = require(\"https://d3js.org/d3.v5.min.js\")\n\nchart2 = {\n  const svg = d32.select(DOM.svg(width, height2));\n  \n  svg.append(\"g\")\n  .call(xAxis2);\n  \n  svg.append(\"g\")\n  .call(yAxis2);\n  \n  svg.append(\"path\")\n  .datum(data2)\n  .attr(\"fill\", \"none\")\n  .attr(\"stroke\", \"steelblue\")\n  .attr(\"stroke-width\", 4)\n  .attr(\"stroke-linejoin\", \"round\")\n  .attr(\"stroke-linecap\", \"round\")\n  .attr(\"d\", line);\n  \n  return svg.node();\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCredit to https://observablehq.com/@dswalter/normal-distribution for the base of the applet code"
  },
  {
    "objectID": "Pages/Lectures/Lecture09/Lec09.html#uniform-probabilities",
    "href": "Pages/Lectures/Lecture09/Lec09.html#uniform-probabilities",
    "title": "PSTAT 5A: Lecture 09",
    "section": "Uniform Probabilities",
    "text": "Uniform Probabilities\n\nRecall, from our initial discussion on continuous random variables, that probabilities are found as areas underneath the density curve.\nDue to the rectangular shape of the Uniform density curves, finding probabilities under the Uniform distribution ends up being relatively straightforward (so long as we remember how to find the area of a rectangle!)\nLet’s work through an example together.\n\n\n\n\n\n\n\n\nWorked-Out Example 1\n\n\n\n\nIf \\(X \\sim \\mathrm{Unif}(-1, \\ 1)\\), compute \\(\\mathbb{P}(X \\leq 0.57)\\)."
  },
  {
    "objectID": "Pages/Lectures/Lecture09/Lec09.html#solution",
    "href": "Pages/Lectures/Lecture09/Lec09.html#solution",
    "title": "PSTAT 5A: Lecture 09",
    "section": "Solution",
    "text": "Solution\n\nWhen working through probability problems involving continuous distributions, sketching a picture is always a good first step.\n\nSometimes, we will explicitly make that the first step of a problem, meaning failure to sketch a relevant picture may result in less-than-full marks!\n\nThe density curve of the \\(\\mathrm{Unif}(-1, \\ 1)\\) distribution is given by"
  },
  {
    "objectID": "Pages/Lectures/Lecture09/Lec09.html#solution-1",
    "href": "Pages/Lectures/Lecture09/Lec09.html#solution-1",
    "title": "PSTAT 5A: Lecture 09",
    "section": "Solution",
    "text": "Solution\n\nThe desired probability is thus\n\n\n\n\n\n\n\n\n\n\n\n\n\nThis is a rectangle with base \\((0.57 - (-1)) = 1.57\\) and height \\(1 / (1 - (-1)) = 1/2\\). Therefore, the area of this rectangle - and, also, the desired probability - is \\[ (1.57) \\times \\frac{1}{2} = \\boxed{0.785 = 78.5\\%} \\]"
  },
  {
    "objectID": "Pages/Lectures/Lecture09/Lec09.html#another-example",
    "href": "Pages/Lectures/Lecture09/Lec09.html#another-example",
    "title": "PSTAT 5A: Lecture 09",
    "section": "Another Example",
    "text": "Another Example\n\n\n\n\n\n\n\nWorked-Out Example 2\n\n\n\n\nIf \\(X \\sim \\mathrm{Unif}(0, 1)\\), compute \\(\\mathbb{P}(0.25 \\leq X \\leq 0.75)\\).\n\n\n\n\n\n\n\nWe are going to solve this problem in two different ways.\nAgain, we always begin with a sketch of the desired probability as an area underneath the density curve:"
  },
  {
    "objectID": "Pages/Lectures/Lecture09/Lec09.html#tail-probabilities",
    "href": "Pages/Lectures/Lecture09/Lec09.html#tail-probabilities",
    "title": "PSTAT 5A: Lecture 09",
    "section": "Tail Probabilities",
    "text": "Tail Probabilities\n\nThis is not a coincidence!\nFor a more arbitrary distribution:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncan be decomposed as\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\[ \\huge - \\]"
  },
  {
    "objectID": "Pages/Lectures/Lecture09/Lec09.html#tail-probabilities-1",
    "href": "Pages/Lectures/Lecture09/Lec09.html#tail-probabilities-1",
    "title": "PSTAT 5A: Lecture 09",
    "section": "Tail Probabilities",
    "text": "Tail Probabilities\n\nIn math, what we have found is:\n\n\n\n\n\n\n\n\nImportant\n\n\n\n\\[ \\mathbb{P}(x_1 \\leq X \\leq x_2)  = \\mathbb{P}(X \\leq x_2) - \\mathbb{P}(X \\leq x_1) \\]\n\n\n\n\n\n\nThe quantity \\(\\mathbb{P}(X \\leq x)\\), where we view \\(x\\) as an arbitrary input (and hence the quantity \\(\\mathbb{P}(X \\leq x)\\) as a function of \\(x\\)) is called the cumulative distribution function (or c.d.f. for short) of \\(X\\)."
  },
  {
    "objectID": "Pages/Lectures/Lecture09/Lec09.html#your-turn",
    "href": "Pages/Lectures/Lecture09/Lec09.html#your-turn",
    "title": "PSTAT 5A: Lecture 09",
    "section": "Your Turn!",
    "text": "Your Turn!\n\n\n\n\n\n\n\nExercise 1\n\n\n\n\nThe time (in minutes) spent waiting in line at Starbucks is found to vary uniformly between 5mins and 15mins.\n\nDefine the random variable of interest, and call it \\(X\\).\nIf a person is selected at random from the line at Starbucks, what is the probability that they spend between 3 and 7 minutes waiting in line?\nWhat is the c.d.f. of wait times? (I.e., find the probability that a randomly selected person spends less than \\(x\\) minutes waiting in line, for an arbitrary value \\(x\\). Yes, your final answer will depend on \\(x\\); that’s why the c.d.f. is a function!)"
  },
  {
    "objectID": "Pages/Lectures/Lecture09/Lec09.html#probability-of-attaining-an-exact-value",
    "href": "Pages/Lectures/Lecture09/Lec09.html#probability-of-attaining-an-exact-value",
    "title": "PSTAT 5A: Lecture 09",
    "section": "Probability of Attaining an Exact Value",
    "text": "Probability of Attaining an Exact Value\n\nIf \\(X \\sim \\mathrm{Unif}[0, 1]\\), what is the probability that \\(X\\) equals, say \\(0.5\\)?\n\nThe area this corresponds to is a rectangle of height \\(1 / (1 - 0) = 1\\), but with width \\(0\\).\nTherefore, the probability is zero.\n\nThis is not unique to the Uniform distribution!\n\n\n\n\n\n\n\n\nProbability of Attaining an Exact Value\n\n\n\nIf \\(X\\) is a continuous random variable, \\(\\mathbb{P}(X = x) = 0\\) for any value \\(x\\)."
  },
  {
    "objectID": "Pages/Lectures/Lecture09/Lec09.html#mean-and-variance-of-the-uniform-distribution",
    "href": "Pages/Lectures/Lecture09/Lec09.html#mean-and-variance-of-the-uniform-distribution",
    "title": "PSTAT 5A: Lecture 09",
    "section": "Mean and Variance of the Uniform Distribution",
    "text": "Mean and Variance of the Uniform Distribution\n\nIf \\(X \\sim \\mathrm{Unif}[a, b]\\), we have the following results:\n\n\\(\\displaystyle \\mathbb{E}[X] = \\frac{a + b}{2}\\)\n\\(\\displaystyle \\mathrm{Var}(X) = \\frac{1}{12}(b - a)^2\\)\n\n\n\n\n\n\n\n\n\nExercise 2\n\n\n\n\nConsider again the setup of Exerise 1: the time (in minutes) spent waiting in line at Starbucks is found to vary uniformly on between 5mins and 15mins.\n\nIf we select a person at random, what is the expected amount of time (in minutes) they will spend waiting in line? What about the variance and standard deviation of the time (in minutes) they will spend waiting in line?"
  },
  {
    "objectID": "Pages/Lectures/Lecture09/Lec09.html#normal-distribution-1",
    "href": "Pages/Lectures/Lecture09/Lec09.html#normal-distribution-1",
    "title": "PSTAT 5A: Lecture 09",
    "section": "Normal Distribution",
    "text": "Normal Distribution\n\nThe normal distribution takes two parameters \\(\\mu\\) and \\(\\sigma\\). We use the notation \\(X \\sim \\mathcal{N}(\\mu, \\ \\sigma)\\) to denote “\\(X\\) follows the normal distribution with parameters \\(\\mu\\) and \\(\\sigma\\).”\nThe normal distribution has distribution function given by \\[ f(x) = \\frac{1}{\\sigma \\cdot \\sqrt{2 \\pi}} \\cdot \\exp\\left\\{ - \\frac{1}{2} \\cdot \\left( \\frac{x - \\mu}{\\sigma} \\right)^2 \\right\\} \\]\nLet’s determine how the parameters affect the shape of the density curve."
  },
  {
    "objectID": "Pages/Lectures/Lecture09/Lec09.html#changing-mu-and-sigma",
    "href": "Pages/Lectures/Lecture09/Lec09.html#changing-mu-and-sigma",
    "title": "PSTAT 5A: Lecture 09",
    "section": "Changing \\(\\mu\\) and \\(\\sigma\\)",
    "text": "Changing \\(\\mu\\) and \\(\\sigma\\)\n\nviewof µ = Inputs.range(\n  [-3, 3], \n  {value: 0, step: 0.1, label: \"µ:\"}\n)\n\nviewof σ = Inputs.range(\n  [0.2, 3.1], \n  {value: 1, step: 0.01, label: \"σ:\"}\n)\n\nsigsquared = σ**2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmargin = ({top: 20, right: 30, bottom: 30, left: 40})\n\nheight = 400\n\nx_values = d3.scaleLinear()\n    .domain(d3.extent(data, d => d.x))\n    .range([margin.left, width - margin.right])\n\ny_values = d3.scaleLinear()\n    .domain([Math.min(d3.min(data, d => d.y),0), Math.max(1,d3.max(data, d => d.y))]).nice()\n    .range([height - margin.bottom, margin.top])\n    \nline = d3.line()\n    .x(d => x_values(d.x))\n    .y(d => y_values(d.y))\n\nxAxis = g => g\n  .attr(\"transform\", `translate(0,${height - margin.bottom})`)\n  .call(d3.axisBottom(x_values)\n      .ticks(width / 80)\n      .tickSizeOuter(0))\n\nyAxis = g => g\n  .attr(\"transform\", `translate(${margin.left},0)`)\n  .call(d3.axisLeft(y_values)\n      .tickValues(d3.scaleLinear().domain(y_values.domain()).ticks()))\n    \nfunction normal_pdf (input_value, mu, sigsq) {\n  let left_chunk = 1/(Math.sqrt(2*Math.PI*sigsq))\n  let right_top = -((input_value-mu)**2)\n  let right_bottom = 2*sigsq\n  return left_chunk * Math.exp(right_top/right_bottom)\n}\n\nabs_x=6\n\ndata = {\n  let values = [];\n  for (let x = -abs_x; x < abs_x; x=x+0.01) values.push({\"x\":x,\"y\":normal_pdf(x, µ, sigsquared)});\n  return values;\n}\n\nd3 = require(\"https://d3js.org/d3.v5.min.js\")\n\nchart = {\n  const svg = d3.select(DOM.svg(width, height));\n\n  svg.append(\"g\")\n      .call(xAxis);\n\n  svg.append(\"g\")\n      .call(yAxis);\n  \n  svg.append(\"path\")\n      .datum(data)\n      .attr(\"fill\", \"none\")\n      .attr(\"stroke\", \"steelblue\")\n      .attr(\"stroke-width\", 4)\n      .attr(\"stroke-linejoin\", \"round\")\n      .attr(\"stroke-linecap\", \"round\")\n      .attr(\"d\", line);\n  \n  return svg.node();\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCredit to https://observablehq.com/@dswalter/normal-distribution for the majority of the applet code"
  },
  {
    "objectID": "Pages/Lectures/Lecture09/Lec09.html#changing-mu",
    "href": "Pages/Lectures/Lecture09/Lec09.html#changing-mu",
    "title": "PSTAT 5A: Lecture 09",
    "section": "Changing \\(\\mu\\)",
    "text": "Changing \\(\\mu\\)\nHolding \\(\\sigma = 1\\) fixed and varying \\(\\mu\\), we find:"
  },
  {
    "objectID": "Pages/Lectures/Lecture09/Lec09.html#changing-sigma",
    "href": "Pages/Lectures/Lecture09/Lec09.html#changing-sigma",
    "title": "PSTAT 5A: Lecture 09",
    "section": "Changing \\(\\sigma\\)",
    "text": "Changing \\(\\sigma\\)\nHolding \\(\\mu = 0\\) fixed and varying \\(\\sigma\\), we find:"
  },
  {
    "objectID": "Pages/Lectures/Lecture09/Lec09.html#standard-normal-distribution",
    "href": "Pages/Lectures/Lecture09/Lec09.html#standard-normal-distribution",
    "title": "PSTAT 5A: Lecture 09",
    "section": "Standard Normal Distribution",
    "text": "Standard Normal Distribution\n\n\n\n\n\n\n\nDefinition\n\n\n\nThe standard normal distribution is the normal distribution with \\(\\mu = 0\\) and \\(\\sigma = 1\\); i.e. \\(\\mathcal{N}(0, 1)\\)."
  },
  {
    "objectID": "Pages/Lectures/Lecture09/Lec09.html#normal-probabilities",
    "href": "Pages/Lectures/Lecture09/Lec09.html#normal-probabilities",
    "title": "PSTAT 5A: Lecture 09",
    "section": "Normal Probabilities",
    "text": "Normal Probabilities\n\nRecall that for continuous variables, probabilities are found as areas underneath the density curve. For example, if \\(X \\sim \\mathcal{N}(0, 1)\\), then \\(\\mathbb{P}(X \\leq -1)\\) is found by computing the area below:"
  },
  {
    "objectID": "Pages/Lectures/Lecture09/Lec09.html#normal-probabilities-1",
    "href": "Pages/Lectures/Lecture09/Lec09.html#normal-probabilities-1",
    "title": "PSTAT 5A: Lecture 09",
    "section": "Normal Probabilities",
    "text": "Normal Probabilities\n\nNow, unlike with the Uniform density curve, we don’t have a simple closed-form formula for areas under the Normal curve.\nFor instance, how would you get a numerical value for the area shaded on the previous slide?\nThe answer is by way of what is known as a normal table, or z-table.\nTo illustrate how to read a normal table, let’s work through an example:\n\n\n\n\n\n\n\n\nWorked-Out Example 3\n\n\n\n\nIf \\(Z \\sim \\mathcal{N}(0, 1)\\), compute \\(\\mathbb{P}(Z \\leq 0.83)\\)."
  },
  {
    "objectID": "Pages/Lectures/Lecture09/Lec09.html#normal-table",
    "href": "Pages/Lectures/Lecture09/Lec09.html#normal-table",
    "title": "PSTAT 5A: Lecture 09",
    "section": "Normal Table",
    "text": "Normal Table"
  },
  {
    "objectID": "Pages/Lectures/Lecture09/Lec09.html#reading-the-normal-table",
    "href": "Pages/Lectures/Lecture09/Lec09.html#reading-the-normal-table",
    "title": "PSTAT 5A: Lecture 09",
    "section": "Reading the Normal Table",
    "text": "Reading the Normal Table\n\nTo find \\(\\mathbb{P}(Z \\leq 0.83)\\), we break up \\(0.83\\) as \\[ 0.83 = 0.8 + 0.03 \\]\nThis tells us to find the desired probability in the intersection of the \\(0.8\\) row and the \\(0.03\\) column:"
  },
  {
    "objectID": "Pages/Lectures/Lecture09/Lec09.html#another-example-1",
    "href": "Pages/Lectures/Lecture09/Lec09.html#another-example-1",
    "title": "PSTAT 5A: Lecture 09",
    "section": "Another Example",
    "text": "Another Example\n\n\n\n\n\n\n\n\n\nWorked-Out Example 4\n\n\n\n\nIf \\(Z \\sim \\mathcal{N}(0, 1)\\), find\n\n\\(\\mathbb{P}(Z \\leq -1.01)\\)\n\\(\\mathbb{P}(Z \\leq -2.25)\\)\n\\(\\mathbb{P}(-2.25 \\leq Z \\leq -1.01)\\)\n\\(\\mathbb{P}(X \\geq -0.7)\\)"
  },
  {
    "objectID": "Pages/Lectures/Lecture09/Lec09.html#standardization",
    "href": "Pages/Lectures/Lecture09/Lec09.html#standardization",
    "title": "PSTAT 5A: Lecture 09",
    "section": "Standardization",
    "text": "Standardization\n\nNow, all of our considerations above were in the case of the standard normal distribution. How do we find areas under nonstandard normal density curves?\nThe answer: we use a process called standardization.\n\n\n\n\n\n\n\n\nStandardization\n\n\n\nIf \\(X \\sim \\mathcal{N}(\\mu, \\ \\sigma)\\), then \\[ \\left( \\frac{X - \\mu}{\\sigma} \\right) \\sim \\mathcal{N}(0, 1) \\] That is, if we take a normally distributed random variable, subtract off its mean, and divide by its standard deviation, we obtain a random variable whose distribution is the standard normal distribution."
  },
  {
    "objectID": "Pages/Lectures/Lecture09/Lec09.html#normal-probabilities-general-case",
    "href": "Pages/Lectures/Lecture09/Lec09.html#normal-probabilities-general-case",
    "title": "PSTAT 5A: Lecture 09",
    "section": "Normal Probabilities; General Case",
    "text": "Normal Probabilities; General Case\n\nThus, if \\(X \\sim \\mathcal{N}(\\mu, \\ \\sigma)\\), here are the steps we use to compute \\(\\mathbb{P}(X \\leq x)\\):\n\nCompute the \\(z-\\)score \\(z = \\frac{x - \\mu}{\\sigma}\\), rounded to two decimal places.\nLook up the corresponding entry in a standard normal table."
  },
  {
    "objectID": "Pages/Lectures/Lecture09/Lec09.html#your-turn-1",
    "href": "Pages/Lectures/Lecture09/Lec09.html#your-turn-1",
    "title": "PSTAT 5A: Lecture 09",
    "section": "Your Turn!",
    "text": "Your Turn!\n\n\n\n\n\n\n\nExercise 3\n\n\n\n\nIt is found that the scores on a particular exam are normally distributed with a mean of 83 and a standard deviation of 5.\n\nDefine the random variable of interest, and call it \\(X\\).\nIf a student is selected at random, what is the probability that they scored 81 or lower?\nIf a student is selected at random, what is the probability that they scored 75 or higher?"
  },
  {
    "objectID": "Pages/Lectures/Lecture09/Lec09.html#mean-and-variance-of-the-normal-distribution",
    "href": "Pages/Lectures/Lecture09/Lec09.html#mean-and-variance-of-the-normal-distribution",
    "title": "PSTAT 5A: Lecture 09",
    "section": "Mean and Variance of the Normal Distribution",
    "text": "Mean and Variance of the Normal Distribution\n\nIf \\(X \\sim \\mathcal{N}(\\mu, \\ \\sigma)\\), we have the following results:\n\n\\(\\displaystyle \\mathbb{E}[X] = \\mu\\)\n\\(\\displaystyle \\mathrm{Var}(X) = \\sigma^2\\)\n\nSo, the two parameters we use to describe the normal distribution are the mean and the variance.\nWe’ll talk more about parameters in the next lecture."
  },
  {
    "objectID": "Pages/Lectures/Lecture08/Lec08.html#recap-of-probability",
    "href": "Pages/Lectures/Lecture08/Lec08.html#recap-of-probability",
    "title": "PSTAT 5A: Lecture 08",
    "section": "Recap of Probability",
    "text": "Recap of Probability\n\nRecall the basic ingredients of probability we have discussed so far:\n\nExperiment: any procedure we can repeat an infinite number of times, where on each reptition there is a fixed set of things (called outcomes) that can happen.\nOutcome space (\\(\\boldsymbol{\\Omega}\\)): the set of all outcomes associated with a particular experiment\nEvent: a subset of the outcome space\nProbability: a function that maps events to a number; specifically, one that quantifies our beliefs about a particular event"
  },
  {
    "objectID": "Pages/Lectures/Lecture08/Lec08.html#an-experiment",
    "href": "Pages/Lectures/Lecture08/Lec08.html#an-experiment",
    "title": "PSTAT 5A: Lecture 08",
    "section": "An Experiment",
    "text": "An Experiment\n\nLet’s actually conduct an experiment together!\nSpecifically, suppose we toss a coin 3 times and record the outcomes.\n\n\n\nviewof toss = Inputs.button(\"Toss\")\n\n\n\n\n\n\n\ndummy = toss + 1\ncoin = [\"H\", \"T\"]\ns1 = coin[Math.floor(Math.random()*coin.length*dummy/dummy)];\ns2 = coin[Math.floor(Math.random()*coin.length*dummy/dummy)];\ns3 = coin[Math.floor(Math.random()*coin.length*dummy/dummy)];\ns4 = coin[Math.floor(Math.random()*coin.length*dummy/dummy)];\n[s1, s2, s3];\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAdditionally, let’s keep track of the number of heads we observe each time we run this experiment.\n\nIn fact, let’s do this on the chalkboard."
  },
  {
    "objectID": "Pages/Lectures/Lecture08/Lec08.html#an-experiment-1",
    "href": "Pages/Lectures/Lecture08/Lec08.html#an-experiment-1",
    "title": "PSTAT 5A: Lecture 08",
    "section": "An Experiment",
    "text": "An Experiment\n\n\nAlright, let’s make note of a few things.\n\n\n\nNote that each time we run this experiment, we (sure enough) get an element of the outcome space, which is\n\n\n\n\n\n\n\n\n\ntree_diagram\n\n  \n\nbase\n\no   \n\nH1\n\nH   \n\nbase->H1\n\n    \n\nT1\n\nT   \n\nbase->T1\n\n    \n\nH21\n\nH   \n\nH1->H21\n\n    \n\nT21\n\nT   \n\nH1->T21\n\n    \n\nH22\n\nH   \n\nT1->H22\n\n    \n\nT22\n\nT   \n\nT1->T22\n\n    \n\nH311\n\nH   \n\nH21->H311\n\n    \n\nT311\n\nT   \n\nH21->T311\n\n    \n\nH321\n\nH   \n\nT21->H321\n\n    \n\nT321\n\nT   \n\nT21->T321\n\n    \n\nH312\n\nH   \n\nH22->H312\n\n    \n\nT312\n\nT   \n\nH22->T312\n\n    \n\nH322\n\nH   \n\nT22->H322\n\n    \n\nT322\n\nT   \n\nT22->T322"
  },
  {
    "objectID": "Pages/Lectures/Lecture08/Lec08.html#an-experiment-2",
    "href": "Pages/Lectures/Lecture08/Lec08.html#an-experiment-2",
    "title": "PSTAT 5A: Lecture 08",
    "section": "An Experiment",
    "text": "An Experiment\n\n\nBut, also note that each time we run the experiment, the number of heads doesn’t necessarily remain fixed.\n\n\n\nIn fact, each outcome in the outcome space corresponds to a different number of heads:\n\n\n\n\n\nOutcome\nNumber of Heads\n\n\n\n\n(H,  H,   H)\n3\n\n\n(H,   H,   T)\n2\n\n\n(H,   T,   H)\n2\n\n\n(T,   H,   H)\n2\n\n\n(H,   T,   T)\n1\n\n\n(T,   H,   T)\n1\n\n\n(T,   T,   H)\n1\n\n\n(T,   T,   T)\n0"
  },
  {
    "objectID": "Pages/Lectures/Lecture08/Lec08.html#random-variables",
    "href": "Pages/Lectures/Lecture08/Lec08.html#random-variables",
    "title": "PSTAT 5A: Lecture 08",
    "section": "Random Variables",
    "text": "Random Variables\n\nThis leads us to the notion of random variables.\nLoosely speaking, a random variable is a variable or process with a numerical outcome.\nWe denote random variables using capital letters; e.g. \\(X\\), \\(Y\\), \\(Z\\), \\(W\\), etc.\nSo, for example, \\(X =\\) “the number of heads in 3 tosses of a coin” is a random variable because (a) it is a numerical outcome of an experiment and (b) it is random (i.e. its value changes depending on the outcome of the experiment)."
  },
  {
    "objectID": "Pages/Lectures/Lecture08/Lec08.html#state-space",
    "href": "Pages/Lectures/Lecture08/Lec08.html#state-space",
    "title": "PSTAT 5A: Lecture 08",
    "section": "State Space",
    "text": "State Space\n\nA key part of the definition of random variables is that they must be numerical.\nWhat this means is we can always look at the set of values a random variable could take: this is what we call the state space of a random variable.\nFor example: if \\(X =\\) “number of heads in 3 tosses of a coin”, we see that \\(X\\) will only ever be \\(0\\), \\(1\\), \\(2\\), or \\(3\\).\n\nThis is because it is not possible to toss 3 coins and get, say, 5 heads, or a negative number of heads!\n\nWe often denote the state space of a random variable using the notation \\(S_{\\verb|<variable>|}\\); e.g. \\(S_X\\) to mean the state space of \\(X\\), \\(S_Y\\) to mean the state space of \\(Y\\), etc."
  },
  {
    "objectID": "Pages/Lectures/Lecture08/Lec08.html#classifying-random-variables",
    "href": "Pages/Lectures/Lecture08/Lec08.html#classifying-random-variables",
    "title": "PSTAT 5A: Lecture 08",
    "section": "Classifying Random Variables",
    "text": "Classifying Random Variables\n\nBecause random variables are numerical, their state spaces will always be numerical sets of values.\nThis means we can classify state spaces using our Variable Classification scheme from Week 1!\n\nSpecifically: the state space \\(S_X\\) of a random variable will either have “jumps”, or not.\n\nWe extend the same classification language to random variables:\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nGiven a random variable \\(X\\), we say that:\n\n\\(X\\) is a discrete random variable (or just “\\(X\\) is discrete) if \\(S_X\\) is has jumps\n\\(X\\) is a continuous random variable (or just “\\(X\\) is continuous) if \\(S_X\\) has no jumps"
  },
  {
    "objectID": "Pages/Lectures/Lecture08/Lec08.html#leadup",
    "href": "Pages/Lectures/Lecture08/Lec08.html#leadup",
    "title": "PSTAT 5A: Lecture 08",
    "section": "Leadup",
    "text": "Leadup\n\nLet’s return to our coin tossing example.\nWhat is the probability that we observe zero heads?\nWell, in the language of our random variable \\(X\\) (which counts the number of heads in these three tosses of our fair coin), we can translate “zero heads” to the event “\\(\\{X = 0\\}\\)’’, meaning we want to find \\(\\mathbb{P}(X = 0)\\).\nObserving zero heads is equivalent to observing all tails, meaning the event \\(\\{X = 0\\}\\) is equivalent to the event { (T,  T,  T) }.\nNow, up to this point I have been careful to avoid explicitly mentioning whether our coin is fair or not.\n\nFor the time being, let’s assume that the probability our coin lands ‘heads’ on any given toss is some fixed value \\(p\\)."
  },
  {
    "objectID": "Pages/Lectures/Lecture08/Lec08.html#probability-mass-function",
    "href": "Pages/Lectures/Lecture08/Lec08.html#probability-mass-function",
    "title": "PSTAT 5A: Lecture 08",
    "section": "Probability Mass Function",
    "text": "Probability Mass Function\n\nThe table on the previous slide is called a probability mass function, and is often abbreviated as p.m.f..\nIn general, the p.m.f. of an arbitrary random variable \\(X\\) is a table or formula that specifies all the possible values a random variable can take (i.e. the state space), along with the probability with which the random variable attains those values.\nWe use the term “function” to describe this because, in abstraction, we can notate the p.m.f. as \\[ p_X(k) := \\mathbb{P}(X = k) \\] where \\(k\\) can be any value in the state space of \\(X\\)."
  },
  {
    "objectID": "Pages/Lectures/Lecture08/Lec08.html#example",
    "href": "Pages/Lectures/Lecture08/Lec08.html#example",
    "title": "PSTAT 5A: Lecture 08",
    "section": "Example",
    "text": "Example\n\n\n\n\n\n\nWorked-Out Example 1\n\n\n\n\nSuppose we toss three fair coins independently, and let \\(X\\) denote the number of heads observed. Construct the p.m.f. (probability mass function) of \\(X\\).\n\n\n\n\n\n\nBy our work from above, the p.m.f. of \\(X\\) is given by \\[\\begin{array}{r|cccc}\n\\boldsymbol{k}    &     0   & 1   & 2   & 3   \\\\\n\\hline\n\\boldsymbol{\\mathbb{P}(X = k)}   & 1/8   & 3/8  & 3/8 &  1/8\n\\end{array}\\]\nBy the way, notice that the probabilities in the p.m.f. sum up to 1.\n\nThis is not a coincidence! Because the probabilities represent the probabilities of all values \\(X\\) can take, they must sum up to 1."
  },
  {
    "objectID": "Pages/Lectures/Lecture08/Lec08.html#properties-of-pmfs",
    "href": "Pages/Lectures/Lecture08/Lec08.html#properties-of-pmfs",
    "title": "PSTAT 5A: Lecture 08",
    "section": "Properties of PMF’s",
    "text": "Properties of PMF’s\n\nThis leads us to posit the following two properties of probability mass functions:\n\n\n\n\n\n\n\n\n\nProperties of a PMF\n\n\n\n\nThe values in a PMF must sum to 1\nThe values in a PMF must always be nonnegative\n\n\n\n\n\n\n\n\nAlso: we implicitly set probabilities not contained in the p.m.f. to be zero.\n\nFor instance: in our coin tossing example, \\(\\mathbb{P}(X = 1.5) = 0\\).\nThis makes sense! If \\(k \\notin S_X\\), then by definition of the state space it is impossible for \\(X\\) to attain the value \\(k\\), and so \\(\\mathbb{P}(X = k) = 0\\)."
  },
  {
    "objectID": "Pages/Lectures/Lecture08/Lec08.html#worked-out-example",
    "href": "Pages/Lectures/Lecture08/Lec08.html#worked-out-example",
    "title": "PSTAT 5A: Lecture 08",
    "section": "Worked-Out Example",
    "text": "Worked-Out Example\n\n\n\n\n\n\nWorked-Out Example 2\n\n\n\n\nA random variable \\(X\\) has the following p.m.f.: \\[\\begin{array}{r|cccc}\n  \\boldsymbol{k}    &     -1.4   & 0   & 3   & 4.15   \\\\\n  \\hline\n  \\boldsymbol{\\mathbb{P}(X = k)}   & 0.1 & 0.2 & \\boldsymbol{a} & 0.6\n\\end{array}\\] What must be the value of \\(\\boldsymbol{a}\\)?\n\n\n\n\n\n\nBecause the values in a p.m.f. must sum to 1, we must have \\[ 0.1 + 0.2 + a + 0.6 = 1 \\] which means \\[ a = 1 - (0.1 + 0.2 + 0.6) = \\boxed{0.1} \\]"
  },
  {
    "objectID": "Pages/Lectures/Lecture08/Lec08.html#worked-out-example-3",
    "href": "Pages/Lectures/Lecture08/Lec08.html#worked-out-example-3",
    "title": "PSTAT 5A: Lecture 08",
    "section": "Worked-Out Example",
    "text": "Worked-Out Example\n\n\n\n\n\n\nWorked-Out Example 3\n\n\n\n\nA random variable \\(X\\) has the following p.m.f.: \\[\\begin{array}{r|cccc}\n  \\boldsymbol{k}    &     -1.4   & 0   & 3   & 4.15   \\\\\n  \\hline\n  \\boldsymbol{\\mathbb{P}(X = k)}   & 0.1 & 0.2 & 0.1 & 0.6\n\\end{array}\\] Compute both \\(\\mathbb{P}(X = 0)\\) and \\(\\mathbb{P}(X \\leq 0)\\).\n\n\n\n\n\n\nFor \\(\\mathbb{P}(X = 0)\\), we can simply read off the corresponding element from the p.m.f.:"
  },
  {
    "objectID": "Pages/Lectures/Lecture08/Lec08.html#expected-value",
    "href": "Pages/Lectures/Lecture08/Lec08.html#expected-value",
    "title": "PSTAT 5A: Lecture 08",
    "section": "Expected Value",
    "text": "Expected Value\n\n\n\n\n\n\n\nDefinition\n\n\n\nThe expected value (or just expectation) of a discrete random variable \\(X\\) is \\[ \\mathbb{E}[X] = \\sum_{\\text{all $k$}} k \\cdot \\mathbb{P}(X = k) \\] where the sum ranges over all values of \\(k\\) in the state space.\n\n\n\n\n\n\nIn words: multiply each value in the state space by the corresponding probability, and then sum.\nThe expected value is a sort of ‘center’ of a random variable."
  },
  {
    "objectID": "Pages/Lectures/Lecture08/Lec08.html#worked-out-example-4",
    "href": "Pages/Lectures/Lecture08/Lec08.html#worked-out-example-4",
    "title": "PSTAT 5A: Lecture 08",
    "section": "Worked-Out Example",
    "text": "Worked-Out Example\n\n\n\n\n\n\nWorked-Out Example 4\n\n\n\n\nA random variable \\(X\\) has the following p.m.f.: \\[\\begin{array}{r|cccc}\n  \\boldsymbol{k}    &     -1.4   & 0   & 3   & 4.15   \\\\\n  \\hline\n  \\boldsymbol{\\mathbb{P}(X = k)}   & 0.1 & 0.2 & 0.1 & 0.6\n\\end{array}\\] Compute \\(\\mathbb{E}[X]\\).\n\n\n\n\n\n\nWe compute \\[\\begin{align*}\n\\mathbb{E}[X]   & = \\sum_{\\text{all $k$}} k \\cdot \\mathbb{P}(X = k)   \\\\[5mm]\n  & = (-1.4) \\cdot \\mathbb{P}(X = -1.4) + (0) \\cdot \\mathbb{P}(X = 0) + (3) \\cdot \\mathbb{P}(X = 3)   \\\\\n    & \\hspace{10mm} + (4.15) \\cdot \\mathbb{P}(X = 4.15)    \\\\[5mm]\n    & = (-1.4) \\cdot (0.1) + (0) \\cdot (0.2) + (3) \\cdot (0.1) + (4.15) \\cdot (0.6) = \\boxed{2.65}\n\\end{align*}\\]"
  },
  {
    "objectID": "Pages/Lectures/Lecture08/Lec08.html#variance-and-sd",
    "href": "Pages/Lectures/Lecture08/Lec08.html#variance-and-sd",
    "title": "PSTAT 5A: Lecture 08",
    "section": "Variance and SD",
    "text": "Variance and SD\n\n\n\n\n\n\n\nDefinition\n\n\n\nThe variance of a discrete random variable \\(X\\) is \\[ \\mathrm{Var}(X) = \\sum_{\\text{all $k$}} (k - \\mathbb{E}[X])^2 \\cdot \\mathbb{P}(X = k) \\] where the sum ranges over all values of \\(k\\) in the state space. The standard deviation is the square root of the variance: \\[ \\mathrm{SD}(X) = \\sqrt{\\mathrm{Var}(X)} \\]\n\n\n\n\n\n\n\n\n\n\n\n\nSecond Formula for Variance\n\n\n\n\\[ \\mathrm{Var}(X) = \\left( \\sum_{\\text{all $k$}} k^2 \\cdot \\mathbb{P}(X = k) \\right) - \\left( \\mathbb{E}[X] \\right)^2 \\]"
  },
  {
    "objectID": "Pages/Lectures/Lecture08/Lec08.html#worked-out-example-5",
    "href": "Pages/Lectures/Lecture08/Lec08.html#worked-out-example-5",
    "title": "PSTAT 5A: Lecture 08",
    "section": "Worked-Out Example",
    "text": "Worked-Out Example\n\n\n\n\n\n\nWorked-Out Example 5\n\n\n\n\nA random variable \\(X\\) has the following p.m.f.: \\[\\begin{array}{r|cccc}\n  \\boldsymbol{k}    &     -1.4   & 0   & 3   & 4.15   \\\\\n  \\hline\n  \\boldsymbol{\\mathbb{P}(X = k)}   & 0.1 & 0.2 & 0.1 & 0.6\n\\end{array}\\] Compute \\(\\mathrm{Var}(X)\\) and \\(\\mathrm{SD}(X)\\).\n\n\n\n\n\n\nWe previously found that \\(\\mathbb{E}[X] = 2.65\\).\nHence, we need only to find \\(\\sum_{k} k^2 \\cdot \\mathbb{P}(X = x)\\): \\[\\begin{align*}\n\\sum_{\\text{all $k$}} k^2 \\cdot \\mathbb{P}(X = k) & = (-1.4)^2 \\cdot \\mathbb{P}(X = -1.4) + (0)^2 \\cdot \\mathbb{P}(X = 0) + (3)^2 \\cdot \\mathbb{P}(X = 3)   \\\\\n    & \\hspace{10mm} + (4.15)^2 \\cdot \\mathbb{P}(X = 4.15)    \\\\[5mm]\n    & = (-1.4)^2 \\cdot (0.1) + (0)^2 \\cdot (0.2) + (3)^2 \\cdot (0.1) + (4.15)^2 \\cdot (0.6) = 11.4295\n\\end{align*}\\]"
  },
  {
    "objectID": "Pages/Lectures/Lecture08/Lec08.html#your-turn",
    "href": "Pages/Lectures/Lecture08/Lec08.html#your-turn",
    "title": "PSTAT 5A: Lecture 08",
    "section": "Your Turn!",
    "text": "Your Turn!\n\n\n\n\n\n\nExercise 1\n\n\n\n\nSuppose \\(X\\) is a random variable with p.m.f. (probability mass function) given by \\[\\begin{array}{r|cccc}\n  \\boldsymbol{k}    &     -1 & 0 & 1 & 2   \\\\\n  \\hline\n  \\boldsymbol{\\mathbb{P}(X = k)}   & 0.3 & 0.2 & 0.1 & \\boldsymbol{a}\n\\end{array}\\]\n\nFind the state space \\(S_X\\) of \\(X\\).\nFind the value of \\(\\boldsymbol{a}\\)\nFind \\(\\mathbb{P}(X = 0.5)\\)\nFind \\(\\mathbb{P}(X \\leq 1)\\)\nFind \\(\\mathbb{P}(X > 1)\\)\nFind \\(\\mathbb{E}[X]\\)\nFind \\(\\mathrm{Var}(X)\\) and \\(\\mathrm{SD}(X)\\)"
  },
  {
    "objectID": "Pages/Lectures/Lecture08/Lec08.html#your-turn-1",
    "href": "Pages/Lectures/Lecture08/Lec08.html#your-turn-1",
    "title": "PSTAT 5A: Lecture 08",
    "section": "Your Turn!",
    "text": "Your Turn!\n\n\n\n\n\n\nExercise 2\n\n\n\n\nConsider the following game: a fair six-sided die is rolled. If the number showing is 1 or 2, you win a dollar; if the number showing is 3, 4, or 5 you win 2 dollars; if the number showing is 6, you lose 1 dollar. Let \\(W\\) denote your net winnings after playing this game once.\n\nWrite down the state space \\(S_W\\) of \\(W\\).\nFind the p.m.f. of \\(W\\).\nWhat are your expected winnings after one round of the game?"
  },
  {
    "objectID": "Pages/Lectures/Lecture08/Lec08.html#back-to-coins",
    "href": "Pages/Lectures/Lecture08/Lec08.html#back-to-coins",
    "title": "PSTAT 5A: Lecture 08",
    "section": "Back to Coins",
    "text": "Back to Coins\n\nAlright, let’s close out this lecture by returning to our coin tossing example.\nAs a reminder: if we let \\(X\\) denote the number of heads in 3 tosses of a \\(p-\\)coin (i.e. a coin that lands ‘heads’ with probability \\(p\\)), the p.m.f. of \\(X\\) is given by\n\n\n\\[\\begin{array}{r|cccc}\n  \\boldsymbol{k}    &     0   & 1   & 2   & 3   \\\\\n  \\hline\n  \\boldsymbol{\\mathbb{P}(X = k)}   & (1 - p)^3   & 3  p (1 - p)^2  & 3  p^2 (1 - p) &  p^3\n\\end{array}\\]\n\n\nWhat if instead of tossing 3 coins, we had tossed 4? Or 5? Or 10?\nWe could go through the same steps we did before, when deriving the p.m.f. for three tosses, but let’s be a little smarter about this; let’s answer the following more general question:"
  },
  {
    "objectID": "Pages/Lectures/Lecture08/Lec08.html#binomial-distribution",
    "href": "Pages/Lectures/Lecture08/Lec08.html#binomial-distribution",
    "title": "PSTAT 5A: Lecture 08",
    "section": "Binomial Distribution",
    "text": "Binomial Distribution\n\n\n\n\n\n\nThe Binomial Distribution\n\n\n\n\nSuppose the probability of a single trial resulting in a ‘success’ is \\(p\\). Letting \\(X\\) denote the number of successes in \\(n\\) independent trials, then we say that \\(X\\) follows the Binomial Distribution with parameters \\(n\\) and \\(p\\). We use the notation \\(X \\sim \\mathrm{Bin}(n, p)\\) to denote this.\n\n\n\n\n\n\n\n\n\n\n\n\nFacts about the Binomial Distribution\n\n\n\n\nIf \\(X \\sim \\mathrm{Bin}(n, p)\\), then\n\n\\(\\displaystyle \\mathbb{P}(X = k) = \\binom{n}{k} \\cdot p^k \\cdot (1 - p)^{n - k}\\)\n\\(\\mathbb{E}[X] = np\\) and \\(\\mathrm{Var}(X) = np(1 - p)\\)"
  },
  {
    "objectID": "Pages/Lectures/Lecture08/Lec08.html#binomial-conditions",
    "href": "Pages/Lectures/Lecture08/Lec08.html#binomial-conditions",
    "title": "PSTAT 5A: Lecture 08",
    "section": "Binomial Conditions",
    "text": "Binomial Conditions\n\n\n\n\n\n\nFour Conditions to Check\n\n\n\n\nIf \\(X\\) counts the number of successes in \\(n\\) trials, there are four conditions that need to be satisfied in order for \\(X\\) to follow the Binomial Distribution:\n\nThe trials must be independent\nThe number of trials, \\(n\\), must be fixed\nThere should be a well-defined notion of “success” and “failure” on each trial\nThe probability of “success” must remain constant across trials.\n\n\n\n\n\n\n\nSo, remember: \\(X \\sim \\mathrm{Bin}(n, p)\\) just means “\\(X\\) counts the number of successes in \\(n\\) trials, where success occurs with probability \\(p\\) on any given trial, subject to the four conditions above being satisfied."
  },
  {
    "objectID": "Pages/Lectures/Lecture08/Lec08.html#worked-out-example-6",
    "href": "Pages/Lectures/Lecture08/Lec08.html#worked-out-example-6",
    "title": "PSTAT 5A: Lecture 08",
    "section": "Worked-Out Example",
    "text": "Worked-Out Example\n\n\n\n\n\n\nWorked-Out Example 6\n\n\n\n\n\nIf we roll a fair \\(6-\\)sided die \\(13\\) times (assume rolls are independent of each other) and let \\(X\\) denote the number of times we observe an even number, is \\(X\\) binomially distributed?\nIn a large population of \\(100\\) students, of which \\(70\\) own Android phones, we draw a random sample of 10 without replacement and let \\(Y\\) denote the number of students in this sample that have Android phones. Is \\(Y\\) binomially distributed?\nConsider the same setup as in part (b) above, except this time suppose students are selected with replacement. Is \\(Y\\) binomially distributed?"
  },
  {
    "objectID": "Pages/Lectures/Lecture08/Lec08.html#part-a",
    "href": "Pages/Lectures/Lecture08/Lec08.html#part-a",
    "title": "PSTAT 5A: Lecture 08",
    "section": "Part (a)",
    "text": "Part (a)\n\nWe check the Binomial Conditions.\n\nIndependent trials? Yup!\nFixed number of trials? Yup! (\\(n = 13\\))\nWell-defined notion of success? Yup! (“success” = “rolling an even number” and “failure” = “rolling an odd number”)\nFixed probability of success? Yup! (\\(p = 1/2\\)).\n\nSince all 4 conditions are satisfied, \\(X\\) binomially distributed: specifically, \\[ X \\sim \\mathrm{Bin}(13, \\ 1/2) \\]"
  },
  {
    "objectID": "Pages/Lectures/Lecture08/Lec08.html#part-b",
    "href": "Pages/Lectures/Lecture08/Lec08.html#part-b",
    "title": "PSTAT 5A: Lecture 08",
    "section": "Part (b)",
    "text": "Part (b)\n\nWe check the Binomial Conditions.\n\nIndependent trials? ; because sampling is done without replacement, trials are no longer independent (i.e. the result of our second trial is very much dependent on the result of our first).\n\nSince at least one condition is violated, \\(Y\\) does follow the binomial distribution."
  },
  {
    "objectID": "Pages/Lectures/Lecture08/Lec08.html#part-c",
    "href": "Pages/Lectures/Lecture08/Lec08.html#part-c",
    "title": "PSTAT 5A: Lecture 08",
    "section": "Part (c)",
    "text": "Part (c)\n\nWe check the Binomial Conditions.\n\nIndependent trials? Yup!\nFixed number of trials? Yup! (\\(n = 10\\))\nWell-defined notion of success? Yup! (“success” = “owning an Android phone” and “failure” = “not owning an Android phone”)\nFixed probability of success? Yup! (\\(p = 7/10\\)).\n\nSince all 4 conditions are satisfied, \\(Y\\) binomially distributed: specifically, \\[ Y \\sim \\mathrm{Bin}(10, \\ 7/10) \\]"
  },
  {
    "objectID": "Pages/Lectures/Lecture08/Lec08.html#your-turn-2",
    "href": "Pages/Lectures/Lecture08/Lec08.html#your-turn-2",
    "title": "PSTAT 5A: Lecture 08",
    "section": "Your Turn!",
    "text": "Your Turn!\n\n\n\n\n\n\nExercise 3\n\n\n\n\nSuppose Jana toss \\(65\\) different \\(12-\\)sided dice, independently of each other; let \\(Z\\) denote the number of times a multiple of three results.\n\nVerify that \\(Z\\) follows the Binomial Distribution, and identify its parameters.\nWhat is the probability that Jana observes exactly 23 multiples of three?\nWhat is the expected number of multiples of three Jana will observe?\nWhat is the standard deviation of the number of multiples of three Jana will observe?"
  },
  {
    "objectID": "Pages/Lectures/Lecture01/Lec01_v2.html#what-is-data",
    "href": "Pages/Lectures/Lecture01/Lec01_v2.html#what-is-data",
    "title": "PSTAT 5A: Lecture 01",
    "section": "What is Data?",
    "text": "What is Data?"
  },
  {
    "objectID": "Pages/Lectures/Lecture01/Lec01_v2.html#what-is-data-1",
    "href": "Pages/Lectures/Lecture01/Lec01_v2.html#what-is-data-1",
    "title": "PSTAT 5A: Lecture 01",
    "section": "What is Data?",
    "text": "What is Data?\n\nAccording to Merriam-Webster (source), there are three definitions for data:\n\n\nfactual information (such as measurements or statistics) used as a basis for reasoning, discussion, or calculation\ninformation in digital form that can be transmitted or processed\ninformation output by a sensing device or organ that includes both useful and irrelevant or redundant information and must be processed to be meaningful"
  },
  {
    "objectID": "Pages/Lectures/Lecture01/Lec01_v2.html#example-of-data",
    "href": "Pages/Lectures/Lecture01/Lec01_v2.html#example-of-data",
    "title": "PSTAT 5A: Lecture 01",
    "section": "Example of Data",
    "text": "Example of Data\n\nAs a concrete example of a dataset, let’s explore the so-called palmerpenguins dataset.\nCollected by Dr. Kristen Gorman at the Palmer Station in Antarctica, this dataset contains various measurements of 344 different penguins Dr. Gorman encountered."
  },
  {
    "objectID": "Pages/Lectures/Lecture01/Lec01_v2.html#the-data-matrix",
    "href": "Pages/Lectures/Lecture01/Lec01_v2.html#the-data-matrix",
    "title": "PSTAT 5A: Lecture 01",
    "section": "The Data Matrix",
    "text": "The Data Matrix\n\nEach row of the data matrix above corresponds to an individual penguin.\n\nIn general, we refer to a given row of the data matrix as an observational unit, or case.\n\nFor each penguin, we can see that there are observations on several different characteristics; specifically, for each penguin she encountered, Dr. Gorman measured and recorded the penguin’s species, island, bill length (in mm), bill depth (in mm), flipper length (in mm), body mass (in grams), sex, and year of observation.\n\nNotice that these are the column names in our data matrix above. In general, the columns of the data matrix are referred to as variables."
  },
  {
    "objectID": "Pages/Lectures/Lecture01/Lec01_v2.html#numerical-vs.-categorical",
    "href": "Pages/Lectures/Lecture01/Lec01_v2.html#numerical-vs.-categorical",
    "title": "PSTAT 5A: Lecture 01",
    "section": "Numerical vs. Categorical",
    "text": "Numerical vs. Categorical\n\nNumerical variables are variables whose observations consist of numbers.\n\nExamples: heights, temperatures, number of free throws, etc.\n\nNot all variables are numerical. For example, I could take a poll asking people’s opinions on the movie Avatar: The Way of Water- the observations of this variable will most certainly not be numerical.\n\nRather, the observations of this variable will fall into one of a series of fixed categories (e.g. “Enjoyed the movie”, “Neutral about the movie”, and “Hated the movie”).\nAs such, we describe non-numerical variables as categorical variables."
  },
  {
    "objectID": "Pages/Lectures/Lecture01/Lec01_v2.html#a-note-on-language",
    "href": "Pages/Lectures/Lecture01/Lec01_v2.html#a-note-on-language",
    "title": "PSTAT 5A: Lecture 01",
    "section": "A Note on Language",
    "text": "A Note on Language\n\nQuestion: can we say that data is numerical? Or, can we say we have “categorical data”?\nSure- if our data consists of just a single variable!\nThat is to say- the classification terms we learned (and will learn) can be used to describe data, provided our data contains only one variable.\nThe definition of data we are using (i.e. in the context of the data matrix) is that data is comprised of several variables. As such, we cannot simply take the classification of variables and apply that to the entire dataset (unless our dataset consists of only one variable).\n\nThis may seem like a subtle point… and it is! I’m just pointing it out so you are aware of it."
  },
  {
    "objectID": "Pages/Lectures/Lecture01/Lec01_v2.html#continuous-vs.-discrete-variables",
    "href": "Pages/Lectures/Lecture01/Lec01_v2.html#continuous-vs.-discrete-variables",
    "title": "PSTAT 5A: Lecture 01",
    "section": "Continuous vs. Discrete Variables",
    "text": "Continuous vs. Discrete Variables\n\nThere is a way we can further subdivide numerical variables.\nAs an example, let us consider two different variables, both of which are numerical: heights, and number of accidents on a stretch of highway.\n\nIt is perfectly conceivable to observe a height of 5.15 feet, or 5.1302 feet, or 5.02391829 feet. In other words, there are an infinite number of possible heights between, say, 5 feet and 6 feet.\nOn the other hand, it doesn’t make sense to talk about “1.5 accidents” occurring on a stretch of highway; the number of accidents needs to be an integer."
  },
  {
    "objectID": "Pages/Lectures/Lecture01/Lec01_v2.html#ordinal-vs.-nominal-variables",
    "href": "Pages/Lectures/Lecture01/Lec01_v2.html#ordinal-vs.-nominal-variables",
    "title": "PSTAT 5A: Lecture 01",
    "section": "Ordinal vs. Nominal Variables",
    "text": "Ordinal vs. Nominal Variables\n\nJust as there was a way to subdivide numerical variables, there is a way to further subdivide categorical variables as well.\nAs an example, consider the following two categorical variables: color, and letter grades (i.e. A, B+, etc.)\n\nFirstly, I hope you can see that both of these variables are indeed categorical: there are only a fixed set of values that “color” and “letter grade” can take, with nothing in between.\nNow, clearly letter grades can be ordered: that is, an A is better than a B, which is better than a C, and so on and so forth.\nIn contrast, “green” isnt inherently better than “red”, which isn’t inherently better than “grey”, and so on and so forth."
  },
  {
    "objectID": "Pages/Lectures/Lecture01/Lec01_v2.html#full-classification-scheme",
    "href": "Pages/Lectures/Lecture01/Lec01_v2.html#full-classification-scheme",
    "title": "PSTAT 5A: Lecture 01",
    "section": "Full Classification Scheme",
    "text": "Full Classification Scheme\n\n\nHere is a diagram of the full classification scheme:\n\n\n\n\n\n\n\n\n\ndata_classification\n\n \n\ncluster_main\n\n  \n\ncluster_0\n\n  \n\ncluster_1\n\n  \n\ncluster_2\n\n  \n\ncluster_3\n\n   \n\nData\n\n Variable   \n\nnumerical\n\n Numerical   \n\nData->numerical\n\n    \n\ncategorical\n\n Categorical   \n\nData->categorical\n\n    \n\ncontinuous\n\n Continuous   \n\nnumerical->continuous\n\n    \n\ndiscrete\n\n Discrete   \n\nnumerical->discrete\n\n    \n\nnominal\n\n Nominal   \n\ncategorical->nominal\n\n    \n\nordinal\n\n Ordinal   \n\ncategorical->ordinal"
  },
  {
    "objectID": "Pages/Lectures/Lecture01/Lec01_v2.html#time-for-an-exercise",
    "href": "Pages/Lectures/Lecture01/Lec01_v2.html#time-for-an-exercise",
    "title": "PSTAT 5A: Lecture 01",
    "section": "Time for an Exercise!",
    "text": "Time for an Exercise!\n\n\n\n\n\n\nExercise 1\n\n\n\nClassify each of the following variables as either discrete, continuous, ordinal, or nominal.\n\n\nThe number of times a computer program returns an error\nThe time it takes an experienced swimmer to complete 4 laps of a pool\nThe favorite flavor of donut of a randomly selected person\nThe months of the year, as written in MM format (e.g. “01” for “January”, “02” for “February”, etc.)\n\n\nDiscuss with your neighbors!"
  },
  {
    "objectID": "Pages/Lectures/Lecture01/Lec01_v2.html#important-note",
    "href": "Pages/Lectures/Lecture01/Lec01_v2.html#important-note",
    "title": "PSTAT 5A: Lecture 01",
    "section": "Important Note",
    "text": "Important Note\n\nIt is important to note that categorical data can be encoded using numbers (as we saw in the previous slide).\n\nIndeed, this is a fairly common practice as computers are more adept at dealing with numbers than things like words or symbols.\nAs such, when classifying data, it is not always enough to just check whether the data consists of numbers or not- it is important to think critically about what the data itself represents.\nAs a quick rule-of-thumb: check whether adding two numbers in your dataset makes interpretive sense. 12in \\(+\\) 13in is 15in, whereas blue + gold does not equal anything, regardless of whether blue is being encoded as 0 and gold is being encoded as 1."
  },
  {
    "objectID": "Pages/Lectures/Lecture01/Lec01_v2.html#real-world-data-set",
    "href": "Pages/Lectures/Lecture01/Lec01_v2.html#real-world-data-set",
    "title": "PSTAT 5A: Lecture 01",
    "section": "Real-World Data Set",
    "text": "Real-World Data Set\n\nLet’s return to the palmerpenguins dataset.\nSpecifically, let’s examine the species variable:\n\n\n\n\n  [1] Adelie    Adelie    Adelie    Adelie    Adelie    Adelie    Adelie   \n  [8] Adelie    Adelie    Adelie    Adelie    Adelie    Adelie    Adelie   \n [15] Adelie    Adelie    Adelie    Adelie    Adelie    Adelie    Adelie   \n [22] Adelie    Adelie    Adelie    Adelie    Adelie    Adelie    Adelie   \n [29] Adelie    Adelie    Adelie    Adelie    Adelie    Adelie    Adelie   \n [36] Adelie    Adelie    Adelie    Adelie    Adelie    Adelie    Adelie   \n [43] Adelie    Adelie    Adelie    Adelie    Adelie    Adelie    Adelie   \n [50] Adelie    Adelie    Adelie    Adelie    Adelie    Adelie    Adelie   \n [57] Adelie    Adelie    Adelie    Adelie    Adelie    Adelie    Adelie   \n [64] Adelie    Adelie    Adelie    Adelie    Adelie    Adelie    Adelie   \n [71] Adelie    Adelie    Adelie    Adelie    Adelie    Adelie    Adelie   \n [78] Adelie    Adelie    Adelie    Adelie    Adelie    Adelie    Adelie   \n [85] Adelie    Adelie    Adelie    Adelie    Adelie    Adelie    Adelie   \n [92] Adelie    Adelie    Adelie    Adelie    Adelie    Adelie    Adelie   \n [99] Adelie    Adelie    Adelie    Adelie    Adelie    Adelie    Adelie   \n[106] Adelie    Adelie    Adelie    Adelie    Adelie    Adelie    Adelie   \n[113] Adelie    Adelie    Adelie    Adelie    Adelie    Adelie    Adelie   \n[120] Adelie    Adelie    Adelie    Adelie    Adelie    Adelie    Adelie   \n[127] Adelie    Adelie    Adelie    Adelie    Adelie    Adelie    Adelie   \n[134] Adelie    Adelie    Adelie    Adelie    Adelie    Adelie    Adelie   \n[141] Adelie    Adelie    Adelie    Adelie    Adelie    Adelie    Adelie   \n[148] Adelie    Adelie    Adelie    Adelie    Adelie    Gentoo    Gentoo   \n[155] Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo   \n[162] Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo   \n[169] Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo   \n[176] Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo   \n[183] Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo   \n[190] Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo   \n[197] Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo   \n[204] Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo   \n[211] Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo   \n[218] Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo   \n[225] Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo   \n[232] Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo   \n[239] Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo   \n[246] Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo   \n[253] Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo   \n[260] Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo   \n[267] Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo   \n[274] Gentoo    Gentoo    Gentoo    Chinstrap Chinstrap Chinstrap Chinstrap\n[281] Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap\n[288] Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap\n[295] Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap\n[302] Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap\n[309] Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap\n[316] Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap\n[323] Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap\n[330] Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap\n[337] Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap\n[344] Chinstrap\nLevels: Adelie Chinstrap Gentoo"
  },
  {
    "objectID": "Pages/Lectures/Lecture01/Lec01_v2.html#descriptive-statistics",
    "href": "Pages/Lectures/Lecture01/Lec01_v2.html#descriptive-statistics",
    "title": "PSTAT 5A: Lecture 01",
    "section": "Descriptive Statistics",
    "text": "Descriptive Statistics\n\n\nThis is the goal of Descriptive Statistics- to find different summarizing techniques to desribe the data.\n\n\n\nThere are two ways we can seek to summarize data: numerically (using numbers), and graphically.\nLet’s start with the latter- that is, let’s discuss how we might summarize our data using graphs."
  },
  {
    "objectID": "Pages/Lectures/Lecture01/Lec01_v2.html#back-to-penguins",
    "href": "Pages/Lectures/Lecture01/Lec01_v2.html#back-to-penguins",
    "title": "PSTAT 5A: Lecture 01",
    "section": "Back To Penguins",
    "text": "Back To Penguins\n\nHere is the species variable one more time:\n\n\n\n\n  [1] Adelie    Adelie    Adelie    Adelie    Adelie    Adelie    Adelie   \n  [8] Adelie    Adelie    Adelie    Adelie    Adelie    Adelie    Adelie   \n [15] Adelie    Adelie    Adelie    Adelie    Adelie    Adelie    Adelie   \n [22] Adelie    Adelie    Adelie    Adelie    Adelie    Adelie    Adelie   \n [29] Adelie    Adelie    Adelie    Adelie    Adelie    Adelie    Adelie   \n [36] Adelie    Adelie    Adelie    Adelie    Adelie    Adelie    Adelie   \n [43] Adelie    Adelie    Adelie    Adelie    Adelie    Adelie    Adelie   \n [50] Adelie    Adelie    Adelie    Adelie    Adelie    Adelie    Adelie   \n [57] Adelie    Adelie    Adelie    Adelie    Adelie    Adelie    Adelie   \n [64] Adelie    Adelie    Adelie    Adelie    Adelie    Adelie    Adelie   \n [71] Adelie    Adelie    Adelie    Adelie    Adelie    Adelie    Adelie   \n [78] Adelie    Adelie    Adelie    Adelie    Adelie    Adelie    Adelie   \n [85] Adelie    Adelie    Adelie    Adelie    Adelie    Adelie    Adelie   \n [92] Adelie    Adelie    Adelie    Adelie    Adelie    Adelie    Adelie   \n [99] Adelie    Adelie    Adelie    Adelie    Adelie    Adelie    Adelie   \n[106] Adelie    Adelie    Adelie    Adelie    Adelie    Adelie    Adelie   \n[113] Adelie    Adelie    Adelie    Adelie    Adelie    Adelie    Adelie   \n[120] Adelie    Adelie    Adelie    Adelie    Adelie    Adelie    Adelie   \n[127] Adelie    Adelie    Adelie    Adelie    Adelie    Adelie    Adelie   \n[134] Adelie    Adelie    Adelie    Adelie    Adelie    Adelie    Adelie   \n[141] Adelie    Adelie    Adelie    Adelie    Adelie    Adelie    Adelie   \n[148] Adelie    Adelie    Adelie    Adelie    Adelie    Gentoo    Gentoo   \n[155] Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo   \n[162] Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo   \n[169] Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo   \n[176] Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo   \n[183] Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo   \n[190] Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo   \n[197] Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo   \n[204] Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo   \n[211] Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo   \n[218] Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo   \n[225] Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo   \n[232] Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo   \n[239] Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo   \n[246] Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo   \n[253] Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo   \n[260] Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo   \n[267] Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo   \n[274] Gentoo    Gentoo    Gentoo    Chinstrap Chinstrap Chinstrap Chinstrap\n[281] Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap\n[288] Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap\n[295] Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap\n[302] Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap\n[309] Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap\n[316] Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap\n[323] Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap\n[330] Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap\n[337] Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap\n[344] Chinstrap\nLevels: Adelie Chinstrap Gentoo"
  },
  {
    "objectID": "Pages/Lectures/Lecture01/Lec01_v2.html#bargraphsbarplots",
    "href": "Pages/Lectures/Lecture01/Lec01_v2.html#bargraphsbarplots",
    "title": "PSTAT 5A: Lecture 01",
    "section": "Bargraphs/Barplots",
    "text": "Bargraphs/Barplots\n\n\nThis is an example of what is known as a bargraph or barplot.\n\n\n\n\n\n\n\n\nResult\n\n\n\nA bargraph is the best type of visualization for categorical data.\n\n\n\n\n\nIn general, if you have \\(k\\) categories, then you will have \\(k\\) bars in your bargraph, each with height propotional to the number of observations within the corresponding category.\nAs you can see, computing software is very useful when it comes to data visualization! In a few weeks, you will explore how to generate visualizations of your own in Python during Lab."
  },
  {
    "objectID": "Pages/Lectures/Lecture01/Lec01_v2.html#time-for-another-exercise",
    "href": "Pages/Lectures/Lecture01/Lec01_v2.html#time-for-another-exercise",
    "title": "PSTAT 5A: Lecture 01",
    "section": "Time For Another Exercise!",
    "text": "Time For Another Exercise!\n\n\n\n\n\n\nExercise 2\n\n\n\nA recent survey asked 120 different PSTAT students what their favorite color is. The bargraph of the results is displayed below:\n\n\n\n\n\nApproximately what proportion of the students in the sample reported either blue or gold as their favorite color? Discuss with your neighbor!"
  },
  {
    "objectID": "Pages/Lectures/Lecture01/Lec01_v2.html#leadup",
    "href": "Pages/Lectures/Lecture01/Lec01_v2.html#leadup",
    "title": "PSTAT 5A: Lecture 01",
    "section": "Leadup",
    "text": "Leadup\n\n\nAll of our discussions above were related to categorical variables.\n\n\n\nAs we discussed at the beginning of this lecture, not all variables are categorical- how do we visualize numerical variables?\nAgain, I find it useful to consider a concrete example: this time, let’s use the bill_length_mm variable from the palmerpenguins dataset."
  },
  {
    "objectID": "Pages/Lectures/Lecture01/Lec01_v2.html#discretizationbinning",
    "href": "Pages/Lectures/Lecture01/Lec01_v2.html#discretizationbinning",
    "title": "PSTAT 5A: Lecture 01",
    "section": "Discretization/Binning",
    "text": "Discretization/Binning\n\n\nThis is what is known as discretizing or binning our variable.\n\n\n\nIn other words, when we discretize our data, we carve it up into a bunch of chunks of equal width and see how many observations fall in each chunk.\n\nThe width of each chunk is what we call the binwidth. For example, if my categories are “between 30 and 35”, “between 35 and 40”, etc., then the binwidth is 5mm as each category spans a width of 5mm."
  },
  {
    "objectID": "Pages/Lectures/Lecture01/Lec01_v2.html#the-importance-of-binwidth",
    "href": "Pages/Lectures/Lecture01/Lec01_v2.html#the-importance-of-binwidth",
    "title": "PSTAT 5A: Lecture 01",
    "section": "The Importance of Binwidth",
    "text": "The Importance of Binwidth\n\nNotice that our notion of a histogram is intimately tied with our choice of binwidth.\nDifferent binwidths can produce wildly different histograms!\nHere is a demo\nIn practice, it is a good idea to play around with different binwidths to find one that results in a histogram that displays a moderate amount of detail without becoming so detailed as to lose sight of the bigger picture."
  },
  {
    "objectID": "Pages/Lectures/Lecture01/Lec01_v2.html#boxplots",
    "href": "Pages/Lectures/Lecture01/Lec01_v2.html#boxplots",
    "title": "PSTAT 5A: Lecture 01",
    "section": "Boxplots",
    "text": "Boxplots\n\nIt turns out there is another way to summarize numerical data visually: using what is known as a boxplot.\nBoxplots can be a seem a bit peculiar at first, so let’s take a look at one together. Before diving back into the palmerpenguins dataset, let’s look at a slightly different dataset.\n\nThis dataset contains only one variable, which records the scores (out of 100 points) of 140 different students on a final exam.\n\n\n\n\n\n  [1] 88.236 77.348 81.050 74.431 75.083 79.569 74.998 80.099 74.264 83.850\n [11] 89.857 81.427 79.439 84.260 78.565 77.570 78.224 73.780 88.085 79.341\n [21] 80.554 77.317 81.155 83.842 87.051 78.362 81.528 72.148 74.131 78.927\n [31] 75.446 79.791 78.199 90.769 85.640 78.420 83.484 79.045 97.909 86.736\n [41] 73.723 76.973 81.320 79.238 85.803 86.621 85.781 81.844 82.896 80.478\n [51] 75.903 84.565 76.302 83.432 85.448 69.695 81.049 85.575 84.791 82.525\n [61] 78.361 77.803 86.542 84.171 86.103 72.772 78.730 76.189 75.187 79.194\n [71] 77.159 82.048 82.661 84.021 76.008 79.474 79.015 86.992 72.524 76.094\n [81] 78.765 80.623 82.497 75.776 70.614 79.677 81.182 77.943 76.863 85.561\n [91] 89.569 96.695 73.680 77.770 81.584 81.965 78.373 76.295 73.212 79.229\n[101] 87.273 87.364 82.706 83.843 75.864 82.791 82.637 78.685 72.626 69.302\n[111] 93.408 73.189 83.764 77.832 82.803 80.278 94.962 79.616 85.667 82.710\n[121] 86.823 76.656 74.623 71.508 91.131 78.318 81.058 86.239 76.585 85.652\n[131] 77.122 86.036 83.127 83.234 80.746 83.878 75.544 73.780 81.106 85.523"
  },
  {
    "objectID": "Pages/Lectures/Lecture01/Lec01_v2.html#anatomy-of-a-boxplot",
    "href": "Pages/Lectures/Lecture01/Lec01_v2.html#anatomy-of-a-boxplot",
    "title": "PSTAT 5A: Lecture 01",
    "section": "Anatomy of a Boxplot",
    "text": "Anatomy of a Boxplot"
  },
  {
    "objectID": "Pages/Lectures/Lecture01/Lec01_v2.html#understanding-boxplots",
    "href": "Pages/Lectures/Lecture01/Lec01_v2.html#understanding-boxplots",
    "title": "PSTAT 5A: Lecture 01",
    "section": "Understanding Boxplots",
    "text": "Understanding Boxplots\n\nLet’s discuss each of the quantities represented on the boxplot separately.\nBefore we do, there’s a bit of math we need to cover.\nThe first quantity we will define is a term you may have heard before- percentile.\nLet’s return to our histogram of scores (since we’re a bit more comfortable with reading histograms than boxplots, at this point)"
  },
  {
    "objectID": "Pages/Lectures/Lecture01/Lec01_v2.html#percentiles",
    "href": "Pages/Lectures/Lecture01/Lec01_v2.html#percentiles",
    "title": "PSTAT 5A: Lecture 01",
    "section": "Percentiles",
    "text": "Percentiles\n\n\n\n\n\n\n\nDefinition\n\n\n\nThe pth percentile of a set of observations \\(X\\) is the value \\(\\pi_{x, \\ p}\\) such that p% of observations lie to the left of (i.e. are less than) \\(\\pi_{x, \\ p}\\).\n\n\n\n\n\n\nMaybe now you can see why I switched over to this data of scores- I think percentiles are sometimes easier to interpret in the context of exam scores, since they are very commonly reported with standardized testing scores (e.g. SAT, GRE, etc.)\n\nIn the context of scores: someone who scored at the pth percentile performed better than p% of all test-takers."
  },
  {
    "objectID": "Pages/Lectures/Lecture01/Lec01_v2.html#quartiles",
    "href": "Pages/Lectures/Lecture01/Lec01_v2.html#quartiles",
    "title": "PSTAT 5A: Lecture 01",
    "section": "Quartiles",
    "text": "Quartiles\n\nWe give a special name to the 25th and 75th percentiles of a set of observations- we call these the first quartile and third quartile, respectively, and use the notation \\(Q_1\\) and \\(Q_3\\) to denote them, respectively.\n\nSo, \\(Q_1\\) is the value such that 25% of observations are less than \\(Q_1\\), and \\(Q_3\\) is the value such that 75% of observations are less than \\(Q_3\\)\n\nThe second quartile (i.e. the 50th percentile) is called the median.\n\nAs such, the median is the value that “splits the data in half”.\nWe’ll talk more about the median in the next lecture."
  },
  {
    "objectID": "Pages/Lectures/Lecture01/Lec01_v2.html#small-caveat",
    "href": "Pages/Lectures/Lecture01/Lec01_v2.html#small-caveat",
    "title": "PSTAT 5A: Lecture 01",
    "section": "Small Caveat",
    "text": "Small Caveat\n\nI should quickly mention one small caveat- computing softwares often use a different procedure for computing quartiles.\nThis procedure is quite long and complicated, and is based off an entire paper written back in the 90’s.\nFor example, if we consider the set \\(S = \\{1, 2, 3, 4, 5, 6\\}\\), we would (based on the definition from the previous slide) call the first quartile \\(2\\), whereas most softwares would return a value of \\(2.25\\).\n\nI’ll show you on the chalkboard why the first quartile is \\(2\\).\n\nDon’t worry about why this is- whenever we talk about quartiles in this class, you can just think of the definition I posed on the previous slide."
  },
  {
    "objectID": "Pages/Lectures/Lecture01/Lec01_v2.html#whiskers",
    "href": "Pages/Lectures/Lecture01/Lec01_v2.html#whiskers",
    "title": "PSTAT 5A: Lecture 01",
    "section": "Whiskers",
    "text": "Whiskers\n\nFinally, we discuss the role of the whiskers on the boxplot.\nThere are several different conventions for how far the whiskers extend. In some conventions, the whiskers extend to the minimum and maximum values of the data.\nThe convention we will use is the following: the whiskers will never reach farther than \\(\\boldsymbol{1.5 \\times (Q_3 - Q_1)}\\).\n\nWhat this means is that there may be points in our dataset that lie beyond the reach of the whiskers. These points are what we call outliers."
  },
  {
    "objectID": "Pages/Lectures/Lecture01/Lec01_v2.html#whiskers-1",
    "href": "Pages/Lectures/Lecture01/Lec01_v2.html#whiskers-1",
    "title": "PSTAT 5A: Lecture 01",
    "section": "Whiskers",
    "text": "Whiskers\n\n\nThe rationale for constructing the whiskers in this way is to try and highlight any points that are unusually distant from the rest of the data.\n\n\n\nFor example, returning to our dataset of scores, we can see that though the median score was around 80.3% there was one person who scored a 97.9%. Because this score is unusually large, we would label it an outlier."
  },
  {
    "objectID": "Pages/Lectures/Lecture01/Lec01_v2.html#time-for-an-exercise-1",
    "href": "Pages/Lectures/Lecture01/Lec01_v2.html#time-for-an-exercise-1",
    "title": "PSTAT 5A: Lecture 01",
    "section": "Time for an Exercise!",
    "text": "Time for an Exercise!\n\n\n\n\n\n\nExercise 4\n\n\n\nHere is a boxplot of the bill_length_mm variable from the palmerpenguins dataset:\n\n\n\n\n\n\n\n\nWhat is the median bill length?\nApproximately what percent of penguins had bills shorter than 37mm in length?\nAre there any outliers?"
  },
  {
    "objectID": "Pages/Lectures/Lecture01/Lec01_v2.html#summary",
    "href": "Pages/Lectures/Lecture01/Lec01_v2.html#summary",
    "title": "PSTAT 5A: Lecture 01",
    "section": "Summary",
    "text": "Summary\n\nWe started off by talking about the structure of data, and the data matrix.\nWe then discussed how to classify variables.\nNext, we explored graphical methods for summarizing data.\n\nBargraphs are best-suited for categorical data\nHistograms and boxplots are best-suited for numerical data\n\nWe also introduced the notions of percentiles, the median, and outliers.\nNext time we’ll discuss how to visualize the relationship between two variables.\nWe’ll also discuss some numerical summaries for data, including the mean, median, standard deviation, and IQR."
  },
  {
    "objectID": "Pages/schedule.html",
    "href": "Pages/schedule.html",
    "title": "PSTAT 5A: Understanding Data",
    "section": "",
    "text": "Disclaimer\n\n\n\nThis schedule is tentative, and is subject to change. Please check back regularly for updates!\n\n\nLast Updated: Thursday, May 4, 2023\n\nAs a reminder: Monday sections are Discussion Sections and Wednesday sections are Lab Sections. There will not be a discussion section in week 1 (as, if there were one, it would take place before the first lecture!)\n\n\n\n\n\n\n\n\n\n\n\nWeek\nLectures\nDiscussion Worksheet\nLab\n\n\n\n\n1\n(4/03 - 4/09)\n\n00: Introduction \n01: Descriptive Statistics \n02: More Descriptive Statistics \n\nNo Discussion Section\nLab 01  (Introduction to Python, and Basic Data Types)\nSolns \n\n\n2\n(4/10 - 4/16)\n\n03: Intro to Probability \n04: Counting \n\nDiscussion Worksheet 01 \nSolns \nLab 02  (Data Classes)\nSolns \n\n\n3\n(4/17 - 4/23)\n\n05: Conditional Probabilities \n06: Review \n\nExam Information/Polices \n\nList of Topics \n\nPractice Problems \n\nPractice Problems Solns \n\nMT1 Coverpage \n\n\nDiscussion Worksheet 02 \nSolns \nLab 03 (Conditionals, Comparisons, and Functions)\nSolns \n\n\n4\n(4/24 - 4/30)\n\n07: Midterm Exam 1\n08: Discrete Random Variables \n\nDiscussion Worksheet 03 (Midterm 1 Review)\nLab 04 (Descriptive Statistics)\nSolns  \n\n\n5\n(5/01 - 5/07)\n\n09: Continuous Random Variables \n\nNormal Table\n\n10: Intro to Inferential Statistics\n\nDiscussion Worksheet 04 \nSolns \nLab 05  Random Number Generation, and Simulations\nSolns \n\n\n\n6\n(5/08 - 5/14)\n\n11: Inference on the Mean\n12: Confidence Intervals\n\nDiscussion Worksheet 05\nLab 06: Sampling Distributions\n\n\n7\n(5/15 - 5/21)\n\n13: Hypothesis Testing\n14: Review\n\nDiscussion Worksheet 06\nLab 07: Confidence Intervals\n\n\n8\n(5/22 - 5/28)\n\n15: Midterm Exam 2\n16: More Hypothesis Testing\n\nDiscussion Worksheet 07 (Midterm 2 Review)\nLab 08: Testing Distributional Fits\n\n\n9\n(5/29 - 6/4)\n\n17: Hypothesis Testing in Multiple Samples\n18: Regression\n\nDiscussion Worksheet 08\nLab 09: Reading In Data, EDA, and Drawing Conclusions\n\n\n10\n(6/05 - 6/11)\n\n19: More Regression\n20: Review\n\nDiscussion Worksheet 09\nLab 10: Regression\n\n\nFINAL EXAM\nTuesday, June 13 from 4-7pm"
  },
  {
    "objectID": "Pages/calendar.html",
    "href": "Pages/calendar.html",
    "title": "PSTAT 5A: Understanding Data",
    "section": "",
    "text": "TA\n\n\nEmail\n\n\nSection Time\n\n\nLocation\n\n\n\n\n\n\nYuan Zhou\n\n\nyuan_zhou@pstat.ucsb.edu\n\n\n10 - 10:50am\n\n\nPsychology East 1805\n\n\n\n\nJason Teng\n\n\njteng@pstat.ucsb.edu\n\n\n11 - 11:50am\n\n\nPhelps 1525\n\n\n\n\nNickolas Thiessen\n\n\nnickolas@ucsb.edu\n\n\n12 - 12:50pm\n\n\nPhelps 1513\n\n\n\n1 - 1:50pm\n\n\nPhelps 1529"
  },
  {
    "objectID": "Pages/calendar.html#visual-weekly-schedule",
    "href": "Pages/calendar.html#visual-weekly-schedule",
    "title": "PSTAT 5A: Understanding Data",
    "section": "Visual Weekly Schedule",
    "text": "Visual Weekly Schedule"
  }
]